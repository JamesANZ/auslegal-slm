Compac Technologies Limited v MAF Agrobotic [2025] APO 37 (29 October 2025)
IP AUSTRALIA
PATENT OFFICE
Compac Technologies Limited v MAF Agrobotic
Patent Application: 2018226589
Title: Fruit or vegetable optical analysis method and device and automatic
sorting device
Patent Applicant: MAF Agrobotic
Opponent: Compac
Technologies Limited
Delegate: Dr V. Z. Kolev
Decision Date: 29
October 2025
Hearing Date: 29 November 2024 via video conference; additional written
submissions filed on 16 January 2025, 14 February 2025, and
Catchwords:
– section 59 – opposition to grant of
a patent – best method – clarity – novelty – inventive
step – clear enough and complete enough disclosure – support –
utility under s 60(3) – optical analysis of
fruits and vegetables –
imaging in visible and infrared – colour CMOS camera without infrared
cut-off filter used for
both visible and infrared – the camera having
buffer memory – surface portion(s) of the fruit or vegetable imaged
nature and content of a figure of the specification – no evidence
from the applicant about the figure – applicant’s
submissions
specification’s wording and evidence regarding the figure
– best method not disclosed in the specification – additional
grounds not decided – possible claim interpretations – observations
on the additional grounds – s 60(3) not invoked
– opposition
successful – application refused – costs awarded
Representation: Counsel for the Applicant: Andrew Fox SC
Patent attorney for the Applicant: Chris Atichian and Mattia Pagani of
Halfords IP
Patent attorney for the Opponent: Ian Finch and James Rowland of James &
IP AUSTRALIA
AUSTRALIAN PATENT OFFICE
Application: 2018226589
Title: Fruit or vegetable optical analysis method and device and automatic
sorting device
Patent Applicant: MAF Agrobotic
Decision: 29 October 2025
The opposition is successful. The complete
specification does not disclose the best method known to the applicant of
performing the
invention. This finding cannot be overcome by an allowable
I refuse the application.
I award costs according to the amounts specified in Schedule 8 against MAF
REASONS FOR DECISION
this decision, unless explicitly stated otherwise, any reference to
”, or to a specific section or subsection, refers to
Patents Act
, and any reference to “the
Regulations
”, or to a specific regulation or subregulation, refers to
Patents Regulations
. In addition, any reference to
Commissioner
” refers to the Commissioner of Patents as
per the Act.
matter relates to patent application 2018226589 (the
Application
name of MAF Agrobotic (the
). The Application was filed on 30
January 2018 under the
Patent Cooperation Treaty
as international application
PCT/FR2018/050212, published as WO2018/158514. The earliest claimed priority
date is 1 March 2017.
acceptance of the Application was advertised on 16 March 2023. A notice of
opposition to grant was filed on 15 June 2023 by Compac
Technologies Limited
original statement of grounds and particulars (the
Original SGP
) was filed on 15 September 2023, together with most of the documents
mentioned in the OSGP. On 18 September 2023, a Delegate of
the Commissioner
directed that “the documents that accompanied the Statement of Grounds and
Particulars are treated as evidence
in support of the opposition”.
rest of the evidence in support was filed on 15 December 2023, the evidence in
answer was filed on 15 March 2024, and the evidence
in reply was filed on 20 May
2 August 2024, the Opponent filed a request to amend the Original SGP, which was
ultimately refused on 26 September 2024. On 2
October 2024, the Opponent filed
a second request to amend the Original SGP. This second request to amend the
Original SGP was allowed
on 21 October 2024, thus resulting in what I will refer
Amended SGP
15 November 2024, the Opponent filed a 93-page document titled
“Submissions of the Opponent” (the
Opponent’s Summary
), together with another document titled “Bundle of
Authorities”. On 22 November 2024, the Applicant filed a 47-page
titled “Applicant’s Written Submissions in Answer” (the
Applicant’s Summary
Relevantly,
the present opposition is with respect to the Application as accepted and is
based on the Amended SGP.
opposition was heard on 29 November 2024 via video conference. At the beginning
of the hearing, I presented a set of questions
to both parties. I also noted
that, given the nature of these questions and their importance for my decision,
I was prepared to
send a formal letter to the parties inviting further written
submissions in answer to my questions. This letter was issued on 16
2024, and contained four questions which, while based on my original questions,
also took into account the oral submissions
of the parties presented during the
hearing. I will reproduce these questions later in the corresponding related
parts of this decision.
In my letter, I further noted that:
“It is my understanding that the parties have agreed on a
page limit; however, I must emphasise that the comprehensiveness of
submissions is more important to me than their length, hence I am not inclined
to impose any strict page limits.
I also note that the parties have agreed on a 7-day period for filing the
submissions. Nonetheless, due to the nature of my questions
and the approaching
festive season, I hereby give the parties
1 (one) month
date of this correspondence to file their submissions, noting that the
submissions can be filed at any time during this
period.” (original
underlining and bold)
response to my invitation, on 16 January 2025, the Opponent filed a brief 6-page
document titled “Response to Delegate’s
Questions” (the
Opponent’s Post-Hearing Submissions
). On the same
day, the Applicant filed an even briefer 3-page document titled
“Applicant’s Response to Hearing Officer’s
Applicant’s Post-Hearing Submissions
Unexpectedly,
on 14 February 2025, the Opponent filed another document titled “Relevance
of Figure 3” (the
Opponent’s Final Submissions
), in which they provided some observations with respect to the part
of the Applicant’s Post-Hearing Submissions dealing with
my question about
Figure 3 of the specification of the Application (the
Specification
28 February 2025, I issued another letter to the parties, in which I noted that:
“Regrettably, on 14 February 2025, the Opponent filed a
letter containing further, uninvited submissions [i.e., the OFS]. This
despite the Opponent having a clear and correct understanding that ‘there
was no formal right of reply’ (the first
sentence of paragraph [1] of the
I have now reviewed the Opponent’s uninvited submissions. In light of
the relevant materials already on file, I DO NOT consider
that these uninvited
submissions, in their entirety, have the potential to alter the outcome of the
opposition. Nonetheless, in the
interest of procedural fairness, I am prepared
to provide the Applicant with an opportunity to file submissions in reply, if
Applicant wishes to do so. Any such submissions in reply must be filed
14 (fourteen) days
of the date of this letter.”
(original underlining and bold)
response, on 11 March 2025, the Applicant filed a document titled
“Applicant’s Response to Hearing Officer’s
Invitation”
Applicant’s Final Submissions
Applicable law and onus
15 April 2013, important provisions of the
Intellectual Property Laws
Amendment (Raising the Bar) Act
) commenced which
resulted in significant amendments to the Act and Regulations affecting,
, the standard of proof required for an opposition to succeed.
For patent applications filed on or after the above commencement date,
subsection 60(3A) applies:
“If the Commissioner is satisfied,
on the balance of probabilities
, that a ground of opposition to the grant
of the standard patent exists, the Commissioner may refuse the
application.” (underlining
Application was filed on 30 January 2018, hence subsection 60(3A) applies to the
instant opposition. In addition, the filing
date of the Application being after
15 April 2013 also means that the Application was examined under the amended
provisions of the
Act and Regulations following the RTB Act and the same are
also applicable to the present opposition proceedings.
is well settled that the Opponent has the onus of establishing the facts
supporting the grounds of opposition, and this applies
even though the standard
of proof is “the balance of probabilities”.
Grounds of opposition and evidence
Grounds of opposition
grounds of opposition as per the Amended SGP are as follows:
the claimed
invention is not novel (ss 18(1)(b)(i) and 7(1));
the claimed
invention does not involve an inventive step (ss 18(1)(b)(ii) and 7(2)-(3));
the claims are
not supported
by matter disclosed in the
Specification (s 40(3)).
Specification does not disclose the invention in a manner which is clear enough
and complete enough for the invention to be performed
by a person skilled in the
relevant art (s 40(2)(a));
Specification does not disclose the best method known to the Applicant of
performing the invention (s 40(2)(aa)); and
the claims are
not clear (s 40(3)).
Additionally,
in paragraph [16] of the Opponent’s Summary, the Opponent
“respectfully invites the Delegate to also consider
that the alleged
invention does not comply with s 18(1)(c) of the Act for lack of utility and
therefore is not valid under s 59(b)”,
and notes that “[u]nder s
60(3) of the Act, ‘
the Commissioner may, in deciding a case, take into
account any ground on which the grant of a standard patent may be opposed,
relied upon by the opponent or not
’” (original italic).
Accordingly, the Opponent’s Summary also includes submissions with respect
to this ground
of opposition (OS in [144]-[155]).
the beginning of the hearing, I confirmed that, in the present circumstances,
the ground of utility could only be considered under
the provisions of
subsection 60(3). Having regard to the public interest in not having a granted
patent with existing valid grounds
of opposition, whether relied on by the
Opponent or not, at the hearing I gave the Opponent an opportunity to make
submissions with
respect to utility. However, I made it clear that these must
be submissions explaining why I should exercise my powers under subsection
60(3). I also invited, at the hearing, submissions from the Applicant (if they
wished to provide any) explaining why I should not
exercise my powers under
subsection 60(3). Furthermore, I stated that if I decide to exercise my powers
and to take into account
the ground of utility, I will invite specific
submissions from the Applicant on this issue, and I will consider both
submissions before deciding on this ground. I further noted
that, since utility is not a ground relied on by the Opponent (as it
the ASGP), this would be reflected in any award of costs, should this ground be
ultimately successful.
Evidence on file
evidence filed in the opposition consists of the following documents:
Evidence in
support consisting of:
documents that accompanied the Original SGP (as per the above-mentioned
direction);
declaration by Dr Vincent Andrew McGlone (
) dated 15 December
2023 with exhibits VM-1 to VM-18;
declaration by Mr David Richard Berry (
) dated 11 December 2023
with exhibits DB-1 to DB-9; and
declaration by Ms Hayleigh Katherine Hine Nui Barrett (
December 2023 with exhibits HB-1 to HB-8.
Evidence in
answer consisting of:
declaration by Professor Kerry Brian Walsh (
) dated 15 March 2024
with exhibits KW-1 to KW-18; and
declaration by Dr Marlon Martins dos Reis (
) dated 15 March 2024 with
exhibits MR-1 to MR-3.
Evidence in
reply consisting of:
second declaration by Dr Vincent Andrew McGlone (
) dated 7 May
second declaration by Mr David Richard Berry (
) dated 20 May 2024.
The Specification
The invention as described
should be noted that the following is not intended to be a comprehensive
discussion of the described invention and all of its embodiments.
Instead, it
is limited to the concepts necessary to understand the claimed invention. To
the extent it proves necessary, I will
provide a more detailed analysis of some
parts of the body of the Specification later in this decision.
body of the Specification includes 27 pages of description and 6 pages of
drawings containing Figure 1 to Figure 8. The description
begins by noting that
“[t]he invention relates to a method and a device for
analysing fruit or vegetables
for the purpose of automatically sorting
them” (page 1, lines 3-4, underlining added here and in all other quoted
the description throughout this decision). It is then explained that:
“... the optical analysis of fruit or vegetables
imaging in a wavelength band typically between 250 nm and 1000 nm
permits contactless measurement of different parameters, in particular
dimensions (size), sugar level, acidity, maturity, firmness,
presence of
external or internal defects, colour... However, in order to do so
necessary to multiply the illumination devices and/or imaging devices
order to activate, for each parameter to be measured, an optical analysis in a
wavelength range suitable for measuring this parameter.
Furthermore, the
measurement of a single parameter can necessitate a
number of illumination
wavelength ranges
number of imaging wavelength ranges
a number of different images for a single illumination and/or imaging wavelength
range, e.g. a reflection image and a transmission
image.” (page 1, lines
respect to the prior art systems, the description notes that:
At least one monochrome camera is used for imaging in the
ultraviolet and infrared ranges. For imaging in the visible range at least
colour camera is generally used
, i.e. a trichromic camera comprising at
least one CMOS or CCD sensor or the like.
Thus, in practice, each optical analysis station of an automatic sorting
device for fruit or vegetables
has thus far comprised a plurality of cameras,
at least one camera per imaging wavelength range
, i.e. classically between
four and eight cameras per line for imaging each portion of the external surface
of each object.”
(page 2, lines 13-20)
sensitivity spectra (i.e., relative sensitivity
wavelength in
nanometres) of the cameras used in the prior art systems are illustrated on
Figure 1 (for a monochrome camera) and
Figure 2 (for a colour camera having
blue, green, and red colour channels, labelled respectively “B”,
and “R”). Both of these figures are reproduced
shortcomings of the known imaging techniques are outlined as follows:
“These different devices [e.g., cameras] are
particularly
expensive, delicate, large and bulky and require regular and expensive
maintenance
. In this regard it should be noted in particular that
are subjected to relatively harsh environmental conditions
dirty), as found in the processing and sorting of fruit or vegetables.
Furthermore,
the use of filters to select the wavelengths is particularly
expensive, such filters being difficult to purchase and degrading rapidly
In addition,
the transmission
to an automated machine, formed of a
computer system,
of the different images
supplied by the different
cameras and
the processing thereof
by this computer system, in particular
for the purpose of automatically sorting the objects,
necessitate a period of
time which, although brief as an absolute value, is not inconsiderable in the
context of the most modern automatic
sorting devices
which can operate at a
very high rate, typically at more than ten - in particular up to about fifty or
even more - fruits or vegetables
per second and per conveying line. Thus
transmission and processing time in the known optical analysis methods and
devices is likely to constitute a restraint on increasing
the rates of certain
automatic sorting devices for fruit or vegetables
.” (page 2, line 21
– page 3, line 8)
the above, it appears that the identified problems with the prior art systems
relate to the large number of expensive equipment
(such as cameras and filters)
operating in a harsh environment as well as the time taken to transmit the
images from cameras to the
processing equipment (i.e., computing devices) and to
process the images.
described the prior art problems, the description states that “[i]t is an
object of at least preferred embodiments of
the present invention to address
at least some
of the aforementioned disadvantages. An additional
alternative object is to at least provide the public with a useful
” (page 3, lines 9-11). More specifically, “[t]he
disclosure aims to propose”:
and device for optically analysing fruit or vegetables by imaging in a plurality
of wavelength ranges, which are
considerably simplified and less expensive to
install, use and maintain
method and such a device for optical analysis which
can be without
for the selection of imaging wavelength ranges”;
method and device for optical analysis which are
more compatible with the
environmental conditions
of the automatic sorting of fruit or vegetables,
permit different parameters to be measured at a very high rate and at
. It aims in particular to propose an optical analysis of fruit or
vegetables by imaging, which is compatible with automatic sorting
at a very high
rate, i.e. which
does not itself constitute a limit on increasing the
automatic sorting rate
“permit[ting]
optical analysis of
all the sorting criteria, other than weight
fruit or vegetables
exclusively by imaging
in different wavelength
for automatically sorting objects such as fruit or vegetables, which have the
same advantages”. (page 3, lines
definitions are provided for “light radiation”, “wavelength
range”, “visible range”,
“infrared range”
(importantly, defined as “between 700 nm and 1000 nm”), and
“ultraviolet range”
(page 4, lines 1-10). These are followed by a
text that appears to be resembling consistory statements reflective of the
independent
claims (page 4, line 11 – page 7, line 13).
description then presents what, in my view, is a pivotal statement:
“The inventor has actually unexpectedly discovered that
is possible to use a single colour camera sensitive to light radiation in the
visible range and to light radiation in the infrared
range to produce a
plurality of images in different imaging wavelength ranges
, including at
least one image in a visible range and at least one image in an infrared range.
It will in fact suffice on the one
choose a colour camera which is
sensitive to infrared
(and in particular
without an infrared cut-off
), and, if necessary, to adjust the settings of this colour camera in
order to produce each image in an infrared range according to
the sensitivity of
each colour of the camera in the infrared range in question.
By virtue of the invention,
all the images necessary for the optical
analysis of the objects in the visible and infrared ranges can be produced with
multispectral camera controlled in synchronism with a suitable
illumination sequence
. This results in a
considerable saving in equipment
and a great simplification of each optical analysis station
.” (page 7,
lines 14-27)
in different wavelengths (or wavelength ranges) are produced by using light
sources emitting, sequentially, light in different
wavelengths (or wavelength
ranges) as required. It is further explained that:
illumination sequence is formed of a
succession of illumination periods
some ... light sources being activated during each illumination period,
group of said light sources being chosen to illuminate each object in one of
said illumination wavelength ranges
. Furthermore, the illumination
wavelength ranges of two successive illumination periods are preferably distinct
from one another.”
(page 12, lines 17-21),
light sources comprise at least one ultrafast control
[i.e., light emitting diode]. In particular, said light sources
comprise at least one visible white light illumination LED, at least
ultraviolet light radiation illumination LED - in particular an ultraviolet
illumination LED with a wavelength between 250 nm
and 380 nm, e.g. 365 nm - and
at least one infrared illumination LED - in particular an infrared illumination
LED with a wavelength
between 720 and 780 nm, e.g. 740 nm; an infrared
illumination LED with a wavelength between 800 nm and 850 nm, e.g. 810 nm; and
infrared illumination LED with a wavelength between 900 nm and 1000 nm, e.g.
940 nm. Other examples are possible.” (page 14,
lines 8-16, bold added)
other words, using a single multispectral camera, sensitive to visible and
infrared light, a series of images in different wavelengths
(or wavelength
ranges) can be produced by sequentially illuminating the fruits or vegetables in
different wavelengths (or wavelength
ranges). This is achieved by activating
different illumination sources consisting of LEDs emitting light in different
wavelengths
(or wavelength ranges). The description notes that:
“Each multispectral camera is a colour camera, i.e. a
trichromic camera having sensors respectively sensitive to one of the
primary colours, red, green and blue.
Any colour camera which is also
sensitive to infrared, i.e. in particular without an infrared cut-off filter,
can be used as a multispectral
camera in a device and method for optical
analysis in accordance with the invention
. In particular, each multispectral
camera can be chosen in the group of cameras comprising a CMOS sensor (with a
matrix of colour
such as a Bayer matrix
); and cameras comprising
three CMOS sensors (one CMOS sensor for each primary colour). However,
is nothing to prevent the use of a camera with a CCD sensor or sensors or the
.” (page 8, lines 15-24)
3 (reproduced below) is “an example of a spectrum of sensitivity of a
colour camera sensitive to infrared and which can
be used as a multispectral
camera in a method an [
] device for optical analysis in accordance
with the invention” (page 16, lines 14-16).
respect to the multispectral camera’s performance for infrared imaging, it
is also explained that:
“In fact, it has been discovered that
the sensitivity of each group of photosensitive elements of a colour camera
for an infrared wavelength varies according to the detection
colour of this
group of photosensitive elements
. If said infrared range comprises a single
infrared wavelength,
the white balance is adjusted according to the
sensitivity of each colour of the multispectral camera for this infrared
. If said infrared range comprises an infrared wavelength band,
the white balance can be adjusted according to the sensitivity of
each colour of
the multispectral camera for a characteristic wavelength, in particular
central wavelength, of said infrared wavelength band
However, it should be noted that
there is nothing to prevent the
provision, as a variation, of the production of infrared images without
adjustment of the white balance
.” (page 9, lines 12-23)
the transmission and processing time for the images, the description notes that:
“... each multispectral camera is
fitted with a buffer
memory for storing images
. Thus the different images produced during each
illumination sequence
can be produced at very high speed
, at the maximum
speed of image acquisition by each multispectral camera,
and stored in a
buffer memory of each multispectral camera before they are transmitted to an
automated machine (computer system) for
processing these images
, which can
carry out image processing at a much slower speed. Consequently, in particular,
the bandwidth of the connection
between each multispectral camera (which
is typically a USB3 connection) and the automated machine
constitutes a limit on the increase in the rates
of automatic sorting of the
fruit or vegetables.” (page 8, lines 5-14)
4 and 5 (reproduced below) illustrate the system of the present invention.
4 represents “a schematic elevation view of an optical analysis station of
an automatic sorting device in accordance
with one embodiment of the
invention” (page 16, lines 17-18), whereas Figure 5 is “a schematic,
transverse cross-sectional
view along line V-V in figure 4” (page 16,
lines 19-20). It is emphasised that “[t]his optical analysis device
constitutes
an optical analysis station of an automatic sorting device
general characteristics which are well known in themselves
(cf. e.g. US
5626238) and
which can form the object of very many embodiment variations,
the invention being applicable to all these embodiment variations, without
” (page 17, lines 17-21).
reference numbers on Figures 4 and 5 correspond to the following elements (page
17, line 16 – page 23, line 7):
– an optical chamber
having a reflective internal surface;
– an optical analysis
device in accordance with the invention;
colour cameras sensitive to infrared;
– objects to be imaged
(i.e., fruits or vegetables);
– illumination devices,
each comprising a plurality of light sources formed of LEDs;
conveying line for the objects;
– supports for the objects,
preferably rotating supports such as rollers which are driven not only in
longitudinal translation
but also in rotation on themselves about transverse
axes of rotation, making it possible to rotate the objects on themselves as they
are passing through the optical analysis device;
– a computer
system for controlling the switching on and off of each light source in a
predetermined illumination sequence
to permit the production of each series of
images, for analysing the images acquired by the cameras, and for controlling
the automatic
sorting device.
view of the previous discussions, I consider that Figures 4 and 5 are somewhat
self-explanatory despite the presence of some extra
details without reference
numbers. These extra details appear unnecessary as they do not facilitate the
illustration of the working
of the device for the purpose of describing the
present invention.
rest of the description contains further details of the invention, including,
e.g., some specific examples for the number of images
in a series, the number of
series per object, the resolution of the camera(s), the set of different
illumination wavelengths, the
illumination and exposure periods, the timing
arrangements for the illumination sequences, etc. I do not consider it
essential to
discuss these details here. As I already noted, to the extent
necessary, I will provide a more detailed analysis of some parts of
the body of
the Specification later in this decision.
The claimed invention
Specification ends with 14 claims. Claims 1 and 7 are independent and
reproduced below. To assist readability and claim construction,
I have made
slight formatting changes to the text. In addition, I have underlined three
expressions and labelled them in square
brackets as “E1”,
“E2”, and “E3”. The reason for this will become
apparent later in the decision.
It should also be noted that, throughout this
decision whenever I considered necessary, I have added underlining to quoted
of the claims to emphasise specific parts of the wording.
“Method of optically analysing objects
belonging to the fruit and vegetable group
images representative of the objects
are produced in different imaging wavelength ranges, and
are analysed to determine sorting criteria,
the objects being moved on a conveyor,
each object being selectively discharged in a discharging region
selected in accordance with the predetermined sorting criteria,
- a plurality of light sources
formed of light-emitting diodes
are arranged to be able each to apply light radiation to at least
external surface portion of at least one object,
named illuminated object
the different light sources being adapted to be able to apply light radiation
in different illumination wavelength ranges selectively
to each illuminated object,
- the light radiation
from at least one light source
is applied to the whole of a visible face of the external surface of each
illuminated by this light source,
- the light sources are controlled
according to a predetermined illumination sequence
for each illuminated object
in succession
according to said different illumination wavelength ranges,
- images are produced
by at least one colour camera
sensitive to light radiation in the visible range and to light radiation in
the infrared range,
named multispectral camera,
said at least one multispectral camera being orientated towards
external surface portion of at least one illuminated object
corresponding to the whole visible face of the external surface of the
object on the optical axis of the multispectral camera
the exposure of said at least one multispectral camera
being controlled in synchronism with said illumination sequence so as to
with this same multispectral camera,
a plurality of images
in different imaging wavelength ranges
said external surface portion of at least one illuminated object
said plurality of images including at least one image in a visible range and
at least one image in an infrared range,
- each multispectral camera is chosen from the group of
cameras comprising a CMOS sensor with a matrix of colour filters without an
infrared cut-off filter; and
cameras comprising three CMOS sensors, one CMOS sensor for each primary
colour, without an infrared cut-off filter,
- wherein at least one multispectral camera is fitted with a buffer memory
the different images of said plurality of images of said external surface
produced by a single multispectral camera
are recorded in real time in the buffer memory of this multispectral
“Device for optically analysing objects
belonging to the fruit and vegetable group,
for producing images of the objects in different wavelength ranges, and
for analysing said images to determine sorting criteria,
the objects being moved on a conveyor,
each object being selectively discharged in a discharging region
selected in accordance with the predetermined sorting criteria,
wherein it comprises:
- an illumination device
comprising a plurality of light sources
formed of light-emitting diodes
arranged to be able each to apply light radiation to at least an external
surface portion of at least one object,
named illuminated object,
the different light sources being adapted to be able to apply light radiation
in different illumination wavelength ranges selectively
to each illuminated object,
- the illumination device
being adapted to be able to apply light radiation
from at least one light source
to the whole of a visible face of the external surface of each object
illuminated by this light source,
- a control device
adapted to be able to control these light sources
according to a predetermined sequence of illumination
of each illuminated object
in succession
according to the different illumination wavelength ranges,
- at least one colour camera
sensitive to light radiation in the visible range and to light radiation in
the infrared range,
named multispectral camera,
orientated towards an external surface portion of at least one illuminated
corresponding to the whole visible face of the external surface of the object
on the optical axis of the multispectral camera,
- each multispectral camera being chosen from the group of
cameras comprising a CMOS sensor with a matrix of colour filters without an
infrared cut-off filter; and
cameras comprising three CMOS sensors, one CMOS sensor for each primary
colour, without an infrared cut-off filter, and
wherein said control device is adapted to control the exposure of each
multispectral camera
in synchronism with said illumination sequence so as to produce,
with this same multispectral camera,
a plurality of images
in different imaging wavelength ranges
of said external surface portion of at least one illuminated object,
said plurality of images including at least one image in a visible range and
at least one image in an infrared range,
wherein at least one multispectral camera is fitted with a buffer memory and
the different images of said plurality of images of said external surface
produced by a single multispectral camera
are recorded in real time in the buffer memory of this multispectral
the independent claims, it appears to me that, apart from the inevitable
language variances reflecting the fact that claim
1 defines a method whereas
claim 7 defines a device, no material differences can be identified. Curiously,
while the images of claim
1 are “representative of the objects”, the
images of claim 7 are “of the objects”; however, given the other
features in the claims, I do not consider that this difference translates into
any meaningful difference in scope. In deciding the
opposition, I will focus my
attention primarily on claim 1, and I will discuss the rest of the claims only
to the extent such discussion
could affect the outcome of my decision.
The person skilled in the art, the experts, and the common
general knowledge
hypothetical person skilled in the art (the
) is a well-established
legal concept. Expert witnesses providing evidence to the Court or the
Commissioner are not persons skilled
in the art as no such real person exists.
As explained by French CJ in paragraph [23] of
AstraZeneca AB v Apotex
[2015] HCA 30:
“The notional person
avatar for expert witnesses
whose testimony is accepted by the court. It is
a pale shadow of a real person — a
tool of analysis
which guides
the court in determining, by reference to expert and other evidence, whether an
invention as claimed does not involve
an inventive step.” (underlining
common general knowledge (the
) at the priority date is another
long-established legal concept, and it is closely related to the PSA. In
Lockwood Security Products Pty Ltd v Doric Products Pty Ltd (No 2)
, the High Court noted that:
“50. Although the
threshold of inventiveness has been raised as explained by the legislative
changes referred to above [i.e.,
the introduction of the Act as compared to the
pre-1990 law],
case law developed previously continues to be relevant
not least because the legislation employs many familiar terms, such as
‘common general knowledge’. ...
55. ‘Common general knowledge’ was well understood as being
part of the mental equipment of those concerned in the art under
consideration
Minnesota Mining
had confirmed that what
was ‘known or used’ in Australia was confined to common general
knowledge, which was explained
the background knowledge and experience which is available to all
in the trade in considering the making of new products, or the making
improvements in old
56. Whether a patent is obvious under the Act is still to be determined by
reference to the
hypothetical non-inventive worker in the field (now a
‘person skilled in the relevant art
’ (ss 7(2) and 7(3))
equipped with common general knowledge
, as stated by Aickin J in
Minnesota Mining
and followed since. ...” (underlining added,
reference(s) omitted)
the applicable legal principles are not in dispute, I do not consider it
necessary to discuss the relevant Authorities in any
further detail.
Nonetheless, it is perhaps worth noting that the concept of the PSA is not
limited to a single hypothetical person
of a particular description, but also
extends to a hypothetical team of hypothetical persons, each with their own
areas of expertise.
The person skilled in the art
Opponent submits that:
“28. In the Amended SGP,
[i.e., the Opponent] identified the PSA as being a person who is one or more of:
28.1 An electrical engineer;
28.2 A mechanical engineer;
28.3 A computer vision engineer;
28.4 A software engineer;
28.5 A mechatronics engineer;
28.6 A data analyst with experience in methods of image processing,
spectroscopy and multivariate analysis;
28.7 A food scientist/technologist;
28.8 A chemist or
who understands the different
spectroscopic analysis methods available across different wavelengths and how to
interpret the data
obtained from those methods; and
28.9 A camera optics engineer.” (OS, underlining and bold added,
reference(s) omitted)
Applicant does not appear to disagree with the above descriptions, with the only
exception of “
the newly added definition
[that] was added in the
recent amendment to the SOGAP [statement of grounds and particulars] on 2
October 2024 [where] the new para
2.3.8 was added to the SOGAP to include
a physicist
’” (AS in [14], underlining added).
Strangely, “[t]he applicant reiterates its objection” (AS in [14])
this amendment to the Original SGP despite the fact that it has already been
formally allowed. While the possible motivation for
this objection will become
apparent later, for the benefit of the Applicant, I must emphasise that the
content of a statement of
ground and particulars (whether original or amended),
while useful, is not determinative for identifying the PSA. In addition, it
also interesting to note that the Applicant’s own expert, Dr Reis,
states that:
“25. The individuals comprising the team will
typically come from a range of backgrounds and will include:
who understand the different spectroscopic analysis methods
available across different wavelengths and how to interpret the data
from those methods;
who understand the operation of the optical device used to obtain the
spectroscopic data;
electrical,
mechanical, and or software engineers with experience in working with electronic
systems, robotics and coding of the same;
scientists with an understanding of the optical properties of fruit and
vegetables and how these change depending on fruit /
vegetable firmness, sugar
and/or water content, and the presence of disease, pests and/or
blemishes.” (Reis, underlining added)
Opponent submits that “[t]he identity of the PSA does not appear to be in
contention. In particular, the expert evidence
filed on behalf of
[i.e., the Applicant] by Dr Walsh and Dr Reis is consistent with the above
definitions” (OS in [30], bold added, reference(s)
omitted). Professor
Walsh’s description of a hypothetical team is reproduced below:
“31. As at March 2017 (and even now), the development of
different sensor systems in the field of fruit and vegetable analysis
very much team based
. The underlying technology used in fruit and vegetable
analysis is largely based on developments in other fields, for other purposes,
e.g., for medical and military instrumentation. The team would assess how the
technological advances could be applied to the field
of fruit and vegetable
assessment. ...
33. ... I consider that the team as at March 2017 would have involved:
particularly those with electrical and mechanical backgrounds and
qualifications. These individuals would be
responsible for selecting and
purchasing the relevant hardware
(i.e. industrial cameras, sensors, light
sources) and
adapting developments in those hardware to use in fruit and
vegetable optical analysis
analysts to develop the relevant machine learning models for assessment of
different attributes;
engineers for data transfer, e.g., using ethernet, from the detecting device
(i.e. the camera) to the computer which applies the
machine learning model;
Horticulturalists
and chemists with an understanding of fruit and vegetables, the attributes of
importance, and how those attributes
can be assessed non-invasively.”
(Walsh, underlining added)
consider that, for the purposes of my decision, the above quoted descriptions by
the Opponent, Dr Reis, and Professor Walsh provide
a reasonable account for the
background of the hypothetical persons who may be part of the hypothetical team.
In particular, given
the nature of the Specification and the evidence of Dr
Reis, I cannot see any reason why a physicist should necessarily be excluded
from such a team; however, I do not consider this to be critically important.
As per Professor Walsh’s description, it is
quite possible that a person
with a different description or background (e.g., an engineer) could acquire
through study and work
experience sufficient knowledge in the specific area of
physics relevant to the present invention. This is also confirmed by Dr
who observes that “individuals within the team may have graduated with a
particular degree, for example, Chemical Engineering,
but during their career
have gained experience more typical of other, related expertise, for example, as
a mechanical or electrical
engineer” (Reis in [26]). In that regard, I
consider that the knowledge and experience of the hypothetical persons in the
hypothetical team is more important than their formal description based, e.g.,
on their education.
The experts
respect to the experts’ suitability, the Opponent explicitly states that
does not contest the qualification of Dr Walsh and Dr Reis
to give expert evidence on MAF’s behalf” (OS in [24], underlining
added). On the other hand, the Applicant provides
a rather academic and, in my
view, half-hearted objection with respect to Dr McGlone’s
suitability, by submitting that “McGlone
1 at para 4 lists his
qualifications as a Bachelor of Science in Physics and mathematics, and a Ph.D
in nuclear physics” and,
hence, “[i]t appears that McGlone
a person skilled in the art
within the meaning of the SOGAP as originally
filed” (AS in [14], underlining added). That is, the Applicant’s
is based upon the fact that, as I discussed, “a physicist”
was not listed in the Original SGP as one of the descriptions.
proposition is completely untenable on the basis of the above analysis and
Dr McGlone’s work experience as described
in paragraphs [7]-[12] of
considered their respective educational backgrounds and work experiences, I have
no reasons to conclude that any one of the
experts is not qualified to give
evidence in this opposition. Nonetheless, it is worth noting that different
experts have different
expertise based on the different roles they may have
played in teams working on relevant projects. Importantly, Professor Walsh
My role in the team would be the individual
who has an appreciation for different fruit qualities and how those qualities
using different non-invasive scanning technologies
. I consider
myself technology agnostic, i.e.,
I search for the best technology for the
particular application
. For example, the internal tissue of a fruit is not
homogenous. It varies within the fruit and that will affect how defects are
as the fruit moves along the pack line. There also needs to be an
understanding of fruit physiology, in terms of what predisposes
the fruit to
certain problems, and what will exacerbate those problems in the system. An
understanding of the optical properties
of fruit is also necessary. There is the
fruit skin, flesh, seeds, and/or cavities within the fruit. Thought needs to be
how light is propagated through the fruit in the detection of a defect,
and the position of that defect, relative to the fruit’s
normal optical
properties. ...
451. ... As
a non-camera or electronics person
, I understand this, as
I experience similar in use of my consumer grade camera in capturing burst
images in action photography.”
(Walsh, underlining added)
above makes it clear that, while Professor Walsh “search[es] for the best
technology for the particular application”,
he would not be the
hypothetical team member who would be “responsible for selecting and
purchasing the relevant hardware (i.e.
industrial cameras, sensors, light
sources) and adapting developments in those hardware to use in fruit and
vegetable optical analysis”
(Walsh in [33a] quoted above). This means
that his expertise in the area of the commercially available cameras would be
limited in comparison to that of Mr Berry who “ha[s] worked
extensively as a New Zealand agent for machine vision
camera hardware
manufacturers
, namely Cognex Corp and Basler, and [is] very familiar with
their product ranges and how they compare to competitor product offerings”
(Berry-1 in [10.2], underlining added). Therefore, Professor Walsh’s
evidence with respect to the characteristics of the cameras
that were available
for purchase at the priority date, should be treated with caution to the extent
that his evidence may contradict
that of Mr Berry.
The common general knowledge
into account the apparent importance placed during the hearing on the cameras
and, more specifically, the characteristics of
their sensors, my post-hearing
correspondence included an invitation for clear submissions on the following
“In your submissions, would the notional person
skilled in the art have knowledge and experience in designing industrial cameras
and/or camera sensors that would be applicable to the practical implementation
of the invention, or would the knowledge and experience
of the person skilled in
the art be limited to selecting and using commercially available industrial
response, the Opponent refers to the Specification on page 5 line 10, page 6
line 16, page 7 line 18, page 8 line 20, and page
20 line 26 (OPHS in [19]
– footnote 9); McGlone-1 in paragraphs [24] and [45] (OPHS in 20 –
footnote 10); Walsh in paragraph
[33a] (OPHS in [21] – footnote 11); and
Reis in paragraph [28] (OPHS in [22] – footnote 12), and concludes that:
“23. Mr Berry is precisely the sort of person who would
either be a member of the team responsible for selecting relevant hardware
from whom the team would purchase the optical equipment and from whom the team
would take specialist advice if there was an information
24. Based on the expert evidence, particularly of Mr Berry, the skilled
person would include an optics expert who had knowledge and
experience in
selecting and using cameras suited to the task of optical analysis of produce at
very high speeds, and also adapting
/ modifying cameras to make them fit for
purpose (e.g. by specifying lenses and adding or removing filters),
would not extend to the actual design and manufacture of cameras
(OPHS, underlining added)
their response, the Applicant submits that:
specification is not concerned with the design of cameras or camera sensors, if
by ‘design’ is meant the
application of scientific principles to
develop a product meeting predefined criteria. Designing a camera or camera
sensor would
require detailed knowledge of the internal operation of these
devices. No such knowledge is required to construe the specification
the invention into practice.
The required knowledge is knowledge of the performance characteristics (e.g.
shutter speed, wavelength sensitivity) a camera would
need to be suitable for
optical analysis of fruit and vegetables on a conveyor. Such knowledge does not
go beyond a black-box conception
of a camera. There is no need to understand the
camera’s internal operation or how the camera was designed.
The specification does require the removal of a camera’s infrared
cut-off filter, but this is generally a simple procedure,
capable of being
performed by the typical user who is not a camera designer, as indicated by the
opponent’s own expert (see
Berry 1, at [36]).
it would be sufficient for the person skilled in the art to
know how to select and use commercially available cameras
.” (APHS on
pages 2-3, underlining added)
agree with the parties. Relatedly, the areas of expertise of the PSA are stated
by the Opponent, by reference to the ASGP in [2.4]-[2.7]
(OS in [29] –
footnote 11), as follows:
“29. Compac further pleaded that:
29.1 The electrical, mechanical and/or mechatronics engineer would have
knowledge of, and experience in, machine scanning and sorting
including in relation to conveyor systems and light chambers for imaging and
sorting fruits and vegetables, which knowledge
would include means for such
systems to rotate an object for imaging the entire object for analytical
29.2 The computer vision and/or camera optics engineer would have knowledge
of, and experience in, the design and functionality of
digital cameras suitable
for use in machine scanning and sorting apparatus, including
knowledge as to
their field of operation in multiple spectra and the effect of applying or
removing filters
, their speed of operation, and the use of white balance
adjustment and buffer memories;
29.3 The computer vision and/or camera optics engineer would also have
knowledge of, and experience in, optoelectronic devices and
illumination systems
for use in machine scanning and sorting apparatus utilising LED lighting for
visible and infrared sources and
their control; and
29.4 The food scientist will have an understanding of the optical properties
of fruit and vegetables and how these change depending
on fruit / vegetable
firmness, sugar and/or water content, and the presence of disease, pests and/or
blemishes.” (OS, underlining
added, reference(s) omitted)
specific statements of what the Opponent asserts is CGK are found in paragraph
[177] (including subparagraphs [177.1]-[177.17])
of the OS. These appear to be
broadly corresponding to the statements in [2.8.1]-[2.8.17] of the Amended SGP.
Finally, by reference
to the evidence of Professor Walsh, the Opponent concludes
that “the CGK does not appear to be in dispute” (OS in [178]).
Importantly,
however, the Applicant disagrees (AS in [71]-[78]) with a number of these
statements in the Amended SGP. I note that,
while the section title before
paragraph [71] of the AS purports that the Applicant disputes statements in the
Original SGP, the
paragraph numbers referred to (AS in [71]-[77]) correspond to
those of the Amended SGP (for example, [2.8.9], [2.8.10], and [2.8.14]
exist in the OSGP). In particular, referring to Reis in paragraphs [40],
[43]-[44], and [80] for support, the Applicant:
disagrees with
ASGP in [2.5], stating that the Applicant “
does not accept that
omission of a filter, particularly an infrared cut-off filter, would have been
at the priority date in the field of optically analysing fruit and
vegetables”, and further stating that “a person skilled
was directed in the contrary sense, to use several separate cameras and
] filters” (AS in [72], original italic,
underlining added);
disagrees with
ASGP in [2.6], stating that “at the priority date,
colour imaging and
infrared imaging was typically performed using separate cameras
that “[c]olour imaging was typically performed using colour cameras (hence
the provision of the infrared cut-out
filter), while infrared imaging was
typically performed using specialized infrared cameras” (AS in [74],
underlining added);
disagrees with
ASGP in [2.8.9], stating that “[m]ultispectral cameras allow images to be
taken within specific wavelength ranges,
but a single multispectral camera does
not necessarily take images across both the visible and infrared spectrums ... a
multispectral camera is generally limited to take images across the visible
spectrum or across the infrared spectrum, but not across
[75], underlining added);
disagrees, in
paragraph [76] of AS, with the statement in the ASGP that “industrial
digital cameras for use in optical analysis
system are capable of operating in
multiple spectra, including the visible colour range and the near-infrared
range, especially when
an infrared filter (
) is not fitted / is
removed and that these cameras are capable of being operated when the IR filter
is removed” (ASGP in [2.8.10],
original bold); and
disagrees with
the statement in the ASGP that “CMOS sensors are preferable to CCD sensors
due to their ability to operate in
multiple spectra, including the visible
colour range and the near-infrared range” (ASGP in [2.8.14]), and argues
instead that
“CMOS sensors are generally known for their fast data
transmission and low power consumption, not for their infrared detection
capabilities” (AS in [77]).
Applicant concludes that:
“78. In summarising the
applicant’s position on the CGK at the priority date, it is submitted
that, to the contrary of
the opponent’s assertions from the amended SOGAP,
in practice
the CGK teaches away from the use of a single CMOS colour camera
of the type claimed, without an infrared filter
, because at the priority
date it was considered important to use such a filter to improve the quality of
the RGB (colour) image,
by limiting variation in light intensities (see Reis,
para 43). For this reason, the bulk of those engaged in the field of fresh
produce optical analysis would have considered the use of the IR filter to be
important to the process, and the filtering out of
IR wavelengths would have
been addressed by using a separate camera to capture images in the IR
wavelengths.” (AS, underlining
Applicant’s submissions on the CGK end with the Applicant’s repeated
objection to the already allowed amendment to
the Original SGP, this time
because of the included new items of alleged CGK:
applicant submits that the opponent should not be allowed to add new CGK matters
in this way. To the extent
the opponent says that these new matters arise
from its evidence in reply
, then it is apparent that the opponent ought to
have in fact led such evidence in its evidence in chief. The applicant says
it is unfairly prejudiced
by the opponent seeking to introduce assertions
as to CGK in this manner at this very late stage.
These amendments to the
SOGAP should not be allowed
.” (AS, underlining added)
the benefit of the Applicant, I need to explain that a mere assertion (in a
statement of grounds and particulars or in submissions)
that a particular item
is part of the CGK does not automatically make this particular item part of the
CGK. The relevant content
of the CGK is to be determined by the evidence. As
to the Opponent possibly “say[ing] that these new matters arise from its
evidence in reply” and the Applicant being “unfairly
prejudiced”, I note that the Applicant has never objected
to any part of
the evidence in reply as not being properly in reply. This is despite the fact
that the Applicant has been specifically
asked whether they intend to do so in
the Commissioner’s correspondence issued on 21 May 2024, to which they
replied on 18
June 2024 that “[t]he applicant does not intend to challenge
the evidence in reply at this time”.
part of their submissions on inventive step, the Applicant reiterates most of
the matters stated in paragraphs [71]-[78] of AS
(as discussed in the dot-points
above); however, they also include the additional statement in paragraph [131]
of AS that the Applicant:
disagrees with
the ASGP in [2.8.11], which states that “it is well known in the industry
that the sensors of industrial digital
cameras without an IR filter are
sensitive to infra-red light.”
Applicant does not appear to provide any reference to the evidence in support of
their disagreement expressed in this additional
statement, and I was not able to
find any such support as discussed below.
McGlone states that:
“53. ... The sensitivity of silicon
sensors generally peaks in the 600 to 800 nm range
but the sensors continued
, admittedly at reducing sensitivity,
up to around 1000 nm
... Specialist
[i.e., near infrared] sensors are needed to capture
wavelengths beyond 1,000nm. All of this was common general knowledge within the
field by 2017. ...
88. However, the fact that
colour cameras could be made to acquire
near-infrared light, by removing the IR filter, was very well known by 2017
As I had already said in my evidence on common general knowledge above, I
understood, and I believe the skilled team would understand
as well, that a
typical silicon sensor of digital cameras used for optical analysis of fruits
and vegetables had sensitivity throughout
the near-infrared spectrum until about
1000nm. ...
106.1. The fact that a
single colour camera
could operate in
the visible spectrum and near-infrared spectrum
was already well known prior
to the Relevant Date” (McGlone-1, underlining and bold added)
respect to the clear statements that a colour camera could be sensitive in the
infrared, made in the above-quoted paragraphs
[88] and [106.1], it is fair to
note that Dr McGlone made these statements only after reviewing the Application.
before reviewing the Application, Mr Berry explains that:
“28. This is not to say there is no overlap between a visible
spectrum sensor and a NIR sensor.
The sensor in a visible spectrum camera
(colour or mono) is capable of operating in the NIR band of the spectrum as long
cut-off filter is not used
. A dedicated NIR sensor will simply
provide betters results. In most cases manufacturers supply colour cameras with
NIR cut-off filters,
most manufacturers also provide instructions on how
to remove the NIR cut-off filter from the camera
32. The fact that these
visible spectrum cameras could operate in the NIR
band was readily understood by customers and suppliers prior to the Relevant
. In fact the Basler data sheets for the above two cameras
that the NIR cut-off filter could be removed to allow the cameras to do so
and Basler had a removal procedure document to show users how to do so.”
(Berry-1, underlining added)
evidence from Professor Walsh, before reviewing the Application, is also
“75. As at the Relevant Date, CMOS camera technology
had replaced CCD technology in use in packhouses. ...
81. As I note above, the
[i.e., red, green, blue] filters are
intended to mimic what the human eye perceives. However, silicon detectors are
in fact more
sensitive than the human eye and can capture wavelengths beyond the
visible and into the NIR region to approx. 1050 to 1100 nm.
wavelengths in the NIR region being captured, it was commonplace as at the
Relevant Date to fit an NIR short-pass filter
to an RGB camera to block out all
wavelengths longer than 750 nm.
It was also possible to fit a long-pass
filter to an RGB camera to block visible wavelengths. Doing so resulted in a
camera capable
of capturing images in the NIR (750-1100 nm) region
Grader manufacturers could therefore make use of different filters to achieve
cameras operating in the UV, visible, and NIR regions
of the electromagnetic
spectrum”. (Walsh, underlining, italic, and bold added)
reviewed the Application, Professor Walsh re-iterates his views:
As at March 2017 it was known that a colour camera
is sensitive to light radiation in the infrared range
. This was why NIR
cut-off filters were and are used.” (Walsh, underlining added)
Reis was never shown the Application (Reis in [8]), and he clearly explains
“43. The sensitivity of
the RGB channels
light in both visible and IR wavelengths can be captured
, affecting
the quality of the final RGB image due to variation in light intensities. As at
1 March 2017,
this issue was typically overcome by introducing an IR filter
to block or reflect NIR wavelengths
while allowing the visible wavelengths
to pass through.
80. I have discussed common filters as at 1 March 2017 above at paragraphs 41
to 43. These included Bayer filters and IR filters.
As at 1 March 2017 common
sensors included CCD (Charge Coupled Device) sensors, and CMOS sensors.
CMOS image sensor was particularly common because they use less power and can
transmit data faster than a CCD sensor
.” (Reis, underlining added)
on the above-quoted pieces of evidence, I cannot agree with the Applicant.
Hence, I conclude that at the priority date it was
well known in the art that
the sensors of industrial colour cameras (even those with RGB filters) without
an infrared cut-off filter
are sensitive to infrared light. In view of the
outcome of my decision, I do not consider it necessary to decide conclusively,
on the evidence, on the rest of the disagreements between the parties with
respect to the CGK.
Claim interpretation
principles of claim interpretation (sometimes referred to as the rules of
construction) are well settled. A helpful summary is
provided by the Full Court
of the Federal Court in
Austal Ships Sales Pty Ltd v Stena Rederi
[2008] FCAFC 121
, citing with approval from an earlier decision:
Flexible Steel Lacing Company v Beltreco
[2000] FCA 890
(2000) 49 IPR 331
, Hely J considered at length the approach to
construction of a specification and, in particular,
the circumstances in
which uncertainty might lead to invalidity
. At [71]-[78] his Honour
identified the following principles:
The monopoly
must be defined in a way
that is not reasonably capable of being
misunderstood
In determining
the nature and extent of the monopoly claimed, the specification must be read as
a whole, but recognizing that
the parts have different functions
claims mark out the legal limits of monopoly. What is not claimed is disclaimed.
The specification describes how to carry out
the process and the best method
known to the patentee of doing so.
Although the
claims are construed in the context of the specification as a whole,
not legitimate to narrow or expand the boundaries of the monopoly as fixed by a
claim by adding glosses drawn from other parts
of the specification. If a claim
is clear, it is not to be varied, qualified or made obscure by statements found
elsewhere in the
It is legitimate
to refer to the rest of the specification to explain the background to the
to ascertain the meaning of technical terms
and resolve
ambiguities in the construction of the claims.
When the language of the
claims is obscure or doubtful such doubts may be resolved by reference to the
specification
necessary that the claims be construed without reference to the body of the
specification in order to see whether there
is any ambiguity. The document is
construed as a whole.
If the specification demonstrates an intention that
words used elsewhere have a particular meaning, effect should be given to such
‘dictionary
14. At [79]-[81] his Honour then
[81] Other principles of construction which may be of assistance in the
resolution of the present matter include:
specification
should be given a purposive construction rather than a purely
literal one
The hypothetical
addressee of the patent specification is the non-inventive person skilled in the
art before the priority date.
The words used in a specification are to be
given the meaning which the hypothetical addressee would attach to them
both in the light of his own general knowledge and in the light of what is
disclosed in the body of the specification.
There is a fine
line between, on the one hand,
reading down the words of a patent claim to
reflect how a person skilled in the art would understand it in a practical and
commonsense
, and, on the other hand,
impermissibly limiting the clear
words of a claim because a reader skilled in the art would be likely to apply
those wide words only
in a limited range of all the situations they
permissible for an invention to be described in a way which involves matters of
Lack of precise definition in claims is not fatal to their validity,
so long as they provide a workable standard suitable to the intended
The consideration is whether, on any reasonable view, the claim has meaning. In
determining this, the expressions in question must
be understood in a practical,
commonsense manner.
Absurd constructions should be avoided and mere
technicalities should not defeat the grant of protection
As a general
the terms of a specification should be accorded their ordinary English
Evidence can
be given by experts on the meaning which those skilled in the art would give to
technical or scientific terms and phrases
and on unusual or special meanings
given by such persons to words which might otherwise bear their ordinary
construction of the specification is for the court, not for the expert
. In so far as a view expressed by an expert depends upon a reading
of the patent, it cannot carry the day unless the court reads
the patent in the
Section 116 of
the 1990 Act provides that the court may, in interpreting a complete
specification, refer to the specification without
amendment. However, it is
neither useful nor legitimate to do so where the amended specification is
clear.” (underlining added)
High Court in
Interlego A.G. v Toltoys Pty. Ltd.
[1973] HCA 1
also stated (at p. 479) that:
“14. ... If
expression is not clear
it is then permissible to resort to the body of the
specification to define or clarify the meaning of words used in the claim
infringing the rule that
clear and unambiguous words in the claim
cannot be varied or qualified by reference to the body of the specification
...” (underlining added)
is important to note that the claims are to be interpreted purposively on the
basis of the actual wording chosen by the Applicant
as clarified, when
necessary, by the body of the Specification. Nonetheless, if the Specification
includes a “dictionary”,
this should be taken into account for the
purposes of claim construction.
The nature of the invention defined in claim 1
1 defines a “[m]ethod of optically analysing objects belonging to the
fruit and vegetable group in which images representative
of the objects are
produced ...”. It is worth noting that, while the claim defines the whole
process, including analysing
the images and selectively discharging the objects
on the basis of the analysis, the primary focus of the claim is on the imaging,
with the more detailed features of the claim related to the way in which the
images are produced:
“- images are produced
by at least one colour camera
sensitive to light radiation in the visible range
and to light radiation in the infrared range,
named multispectral camera,
said at least one multispectral camera being orientated towards an external
surface portion of at least one illuminated object
corresponding to the whole visible face of the external surface of the object
on the optical axis of the multispectral camera, and
the exposure of said at least one multispectral camera
being controlled in synchronism with said illumination sequence so as to
with this same multispectral camera,
a plurality of images
in different imaging wavelength ranges
of said external surface portion of at least one illuminated object,
said plurality of images including at least one image in a visible range and
at least one image in an infrared range”.
is clear that the claimed invention uses a colour camera that is
“sensitive to light radiation in the visible range and to
light radiation
in the infrared range, named multispectral camera”. The object to be
imaged is illuminated sequentially by
light in different wavelength ranges, and
the exposure of the camera is “controlled in synchronism” with the
illumination
in different wavelength ranges. In this way, “a plurality of
images in different imaging wavelength ranges” is produced.
It is defined
that the plurality of images are “of said external surface portion of at
least one illuminated object”.
The question of whether or not the
expression “said external surface portion” refers to the same
particular external
surface potion of the object is a controversial one in this
opposition, and I will provide a more detailed discussion on the issue
this decision.
respect to the type of “multispectral camera” to be used, claim 1
defines that:
multispectral camera is chosen from the group of
a CMOS sensor with a matrix of colour filters
without an infrared cut-off filter; and
three CMOS sensors, one CMOS sensor for each
primary colour, without an infrared cut-off filter”.
Does the scope of claim 1 encompass cameras with separate
infrared sensors?
the existence of multi-sensor cameras (as exemplified by the second group of
cameras above), in my post-hearing correspondence,
I invited the parties to
consider and provide additional submissions addressing the following question:
“The description states: ‘The term
“comprising” as used in this specification means “consisting
in part of”’ (page 5, lines 17-20).
If we consider, for example, a multispectral
colour camera ‘without an infrared cut-off filter’, which has one
sensor with a matrix of colour filters’ for colour imaging in
the visible range, and another sensor for monochrome imaging
in the infrared
range, will the use of such camera, in your submissions, be within the scope of
claim 1 and why?
The same question also appears relevant to an example multispectral colour
camera ‘without an infrared cut-off filter’,
which has ‘three
CMOS sensors, one CMOS sensor for each primary colour’, and a fourth
sensor for monochrome imaging in
the infrared range.”
their response, the Opponent agrees that “as defined by MAF within its
specification, the word ‘comprising’ means
claim 1 extends to a
camera with both a colour CMOS sensor and a monochrome sensor” (OPHS in
[10]). The Opponent also notes
that “[r]eading the claim in this way is
not inconsistent with the teaching of the specification” (OPHS in [11])
on some references to the body of the Specification which, in my opinion,
do not appear strongly supportive of this view. Nonetheless,
the Opponent
reaches the conclusion that “[t]here is no support for the claims so
interpreted in the specification which is
a further reason why the claims are
bad” (OPHS in [12]).
contrast, the Applicant submits that “[t]he camera posited in the question
within the scope of claim 1” (APHS on page 1, original
underlining). In the following, I will consider the Applicant’s
provided in support of this statement. Firstly, the Applicant argues that:
“The definition of ‘comprising’ on page 5 of the
specification says that additional features ‘
present’ (emphasis added), not that they must be present. In any case, the
Patent Manual of Practice and Procedure
], in §5.5.4.8,
makes clear that the meaning of ‘comprising’ depends on the context
of its use.
The context of claim 1 requires that at least one visible image and at least
one infrared image be produced by a camera with one of
the two alternative CMOS
sensor arrangements specified by claim 1 and without an infrared cut-off
filter.” (APHS on pages 1-2,
original underlining)
cannot see how the argument that “[t]he definition of
‘comprising’ ... says that additional features ‘
also be present’ (emphasis added), not that they must be present”
supports the Applicant’s view. The description
on page 5, lines 17-20,
clearly defines that “[t]he term ‘comprising’ as used in this
specification means ‘consisting
at least in part of’” and
further explains that “[w]hen interpreting each statement in this
specification that
includes the term ‘comprising’, features other
than that or those prefaced by the term may also be present”. When
discussing the law on claim interpretation, I emphasised that the presence of a
clear “dictionary” in the Specification
cannot be ignored. This
means that, in the presence of a “dictionary” for the word
“comprising”, the principle
“that the meaning of
‘comprising’ depends on the context of its use” is not really
applicable. In addition,
I do not consider that the “dictionary”
itself provides for any freedom of interpretation depending on the context.
other words, it is exactly because the “dictionary” defines that
additional features
be present regardless of the context, and the
relevant part of claim 1 can be re-written as:
multispectral camera is chosen from the group of
cameras [consisting at least in part of] a CMOS sensor with a matrix of
colour filters without an infrared cut-off filter; and
cameras [consisting at least in part of] three CMOS sensors, one CMOS sensor
for each primary colour, without an infrared cut-off
it follows that the use of a camera with the additional feature of a
monochrome infrared sensor would be within the scope of the claim.
the Applicant argues that:
“The purpose of omitting the
infrared cut-off filter is precisely to allow the CMOS sensor arrangements
specified in claim 1
to produce both visible and infrared images. It would not
make sense to omit the infrared cut-off filter if the camera had an additional
sensor dedicated to infrared imaging.
Therefore, from a purposive construction of claim 1, it follows that a camera
with an additional infrared sensor would not be within
the scope of claim
1.” (APHS on page 2)
am not sure that I can understand the Applicant’s argument. As best
understood, the Applicant appears to be suggesting that
if “an additional
sensor dedicated to infrared imaging” is present in the camera, then an
infrared cut-off filter must
also be present because “[i]t would not make
sense to omit the infrared cut-off filter”. Even if I accept that any
coating that reflects infrared light could be considered an infrared
cut-off filter, I believe that the light entering the camera
could easily be
separated into visible and infrared components without the use of such a
coating/filter.
Nevertheless,
to check the correctness of my views on the point, I conducted an Internet
having a colour CMOS sensor and
“an additional sensor dedicated to infrared imaging”. Below is a
reproduction of the
schematic diagram (and some accompanying text) of this
camera, i.e., FS-1600D-10GE manufactured by JAI Ltd. I extracted this from
27 of the User Manual for the camera, which can presently be downloaded, e.g.,
at <https://www.edmundoptics.com.au/document/download/541677>,
or from the
manufacturer’s web site after registration.
1 of the User Manual describes the camera as “
Progressive Scan
Color and NIR Camera
” (original italic,
underlining added). As it can be seen, the infrared component travels to Sensor
1, which is a near infrared
sensor, in a straight line, and no infrared cut-off
filter or coating is present. In fact, it could possibly be said that the
reflects (or cuts off) the visible components, and not the infrared
components, hence it could be called a visible light cut-off
addition, the colour CMOS sensor (i.e., Sensor 0) has a Bayer filter, which is a
matrix of RGB colour filters arranged
in a certain pattern.
consider that this example camera is a “colour camera sensitive to light
radiation in the visible range and to light radiation
in the infrared
range”, and, in view of the “dictionary” definition for
“comprising”, it clearly belongs
to “the group of cameras
comprising a CMOS sensor with a matrix of colour filters without an infrared
cut-off filter”.
I conclude that within the scope of claim 1, there are colour cameras with
separate infrared sensors and without infrared
cut-off filters, the
above-mentioned camera being a mere example simply demonstrating that such
cameras are not just an academic
hypothetical construct with no practical
utility. The relevance of this finding becomes clear when one considers whether
are supported by matter disclosed in the Specification.
Best method
Introduction
40(2) stipulates:
“A complete specification must:
(aa) disclose the best method known to the applicant of performing the
invention; ...”
does not appear to me that there are any material disagreements between the
parties about the law on best method. In addition,
I consider that the present
case is to be decided on the relevant facts themselves, rather than on the basis
of the application of
complex legal considerations to these facts. In light of
this, I do not think that I need to provide a comprehensive discussion
relevant case law
. Nonetheless, it is worth noting that in
Zoetis Services LLC v Boehringer Ingelheim Animal Health USA Inc
, the Full Court stated:
“14. Whilst the word
‘invention’ may bear various meanings in the Act, it is clear that
in s 40(2)(aa)
it refers to the embodiment which is described and around
which the claims are drawn
. For the purposes of determining whether the best
method of performing the invention has been disclosed, it is necessary to
both the description of the invention and the claims.
15. Section 40(2)(aa) requires disclosure of the best method known to the
patentee of performing the invention.
The nature and extent of the disclosure
required depends on the nature of the invention itself
Intellectual Property AB v Quarry Mining & Construction Equipment Pty
[2017] FCAFC 138
126 IPR 427
461 [115(c)] per Greenwood, Rares and Moshinsky JJ;
Les Laboratoires Servier
v Apotex Pty Ltd
[2016] FCAFC 27
’) at 88 [108] per Bennett, Besanko and Beach
JJ. The nature of the invention is to be discerned from the invention as
in the whole of the specification:
at 461 [115(d)];
at 91 [124]. The effect of s 40(2)(aa) is that
where a patent
applicant knows of a method which permits the invention to be more
satisfactorily performed, the patent applicant must
disclose that method in the
specification
at 78 [64]. ...” (underlining and
bold added)
Opponent discusses the law on best method in paragraphs [57]-[61] of the OS,
and, among the other references to the case law,
specifically refers to the
analysis adopted by Bennett J in
Expo-Net Danmark A/S v Buono-Net Australia
Pty Ltd (No 2)
[2011] FCA 710
“16. ... Justice Harms said that an applicant for revocation
must show that:
(a) the method which the patentee failed to disclose is a method of
performing the invention;
(b) the method is in fact a better method of performing the invention than
the method disclosed in the specification;
(c) the method was known to the patentee at the time when the application for
the patent was lodged at the Patent Office;
(d) the method is not disclosed in the specification; and
(e) the patentee knew that the method was better than the method(s) described
in the specification.
That analysis is, with respect, useful.”
Applicant also provides references to the case law as well as to the PMPP.
Where necessary, I have included some comments with
respect to the specific
references provided by the parties.
argument of whether the best method known to the Applicant is disclosed revolves
around the interpretation and the implications
of Figure 3. The main point of
contention is whether the spectral sensitivity shown on Figure 3 is that of a
real-world existing
camera or not.
The submissions of the parties
The Opponent’s
original submissions
respect to the nature and content of Figure 3, the Opponent asserts that
Figure 3 is a response curve from
a camera known to
” (OS, the section title before [63], original bold,
underlining added).
reach this conclusion, the Opponent firstly refers to the body of the
Specification and notes that “[t]he Application clearly
and unequivocally
states that it was ‘unexpectedly discovered’ that ‘
colour camera
without an infrared cut-off filter
is actually
particularly sensitive in the infrared range, as shown in figure 3
can be used equally well in the visible range and in the infrared range, making
it possible to simplify considerably the
optical analysis stations in the
devices for automatically sorting fruit or vegetables
[63], original bold and italic, reference(s) omitted)
the Opponent submits that:
“64. The expert witnesses all
agree that most CMOS cameras available in the market at the Relevant Date would
provide sufficient
sensitivity in the IR to allow imaging in the visible range
and the IR range if not equipped with an IR cut-off filter and/or once
filter had been removed.
65. However it is clear from the above passage that Figure 3 shows the
particular sensitivity in the infrared range of
colour camera
and is not generic or merely illustrative of the sensitivity of such cameras
more generally. Support for this conclusion
can be found in the evidence of both
Mr Berry and Dr McGlone who identified the sensitivity shown in Figure 3 as
being particularly
high, and not something readily able to be reproduced in
cameras of which they were aware at the Relevant Date. The Application later
specifically clarifies that Figure 3 shows MAF’s alleged unexpected
discovery ‘
that a colour camera without an infrared cut-off filter is
particularly sensitive
in the infrared range
that this is a camera which MAF had tested and recorded the results from as a
part of its research and ‘discovery’
process and one which showed
particular sensitivity.” (OS, original underlining, bold, and italic;
reference(s) omitted)
Opponent also refers to the evidence of Professor Walsh, and notes that:
“66. ... he states that, in contrast to the general
understanding that ‘RGB colour cameras often have low sensitivity
NIR range’, Figure 3 shows ‘the potential sensitivity of an RGB
colour camera’ and that he ‘expect[s]’
that ‘there will
be some models that have lower sensitivity in the NIR range and some models that
have high sensitivity in
the NIR range’ when compared to Figure 3.
appears to be speculation on Dr Walsh’s part
. Notably his expertise
and experience are not in cameras or imaging equipment, and his evidence
suggests he was unaware of the capabilities
of cameras in the NIR range
believing, prior to reading the Application, that NIR light passing R, G and B
pixel filters would be
strongly attenuated when optics experts such as Mr Berry
knew that not to be the case. This suggests he was unaware of and had not
reviewed the response curves of such cameras prior to providing this
evidence.” (OS, underlining added, reference(s) omitted)
the Opponent submits that:
“67. In any event, the question
could have been put to rest by consulting with MAF, or by MAF having led
on the provenance and significance of Figure 3. MAF has elected not
to do so and must now live with the consequences of that choice.”
underlining added)
provided their submissions on the nature and content of Figure 3, the Opponent
further develops their best method case by arguing:
not identified which camera provided the response curve in Figure 3
(OS, the section title before [68], original bold); (ii) that “
best method of implementing the invention described in the Application uses the
camera of Figure 3
” (OS, the section title before [69], original
bold); and (iii) how the present circumstances can be applied (OS in [75],
[75.1]-[75.6]) to “the five-stage analysis used by Bennett J in
] at [16] for determining whether there has been a failure to
disclose the best method” (OS in [60], references omitted). The
stages of this analysis are quoted above.
Opponent concludes that:
MAF could have identified
the camera it used to ascertain the Figure 3 response curve
. If it had done
so, the public would be able to put the invention into effect with the most
sensitive camera, leading to better imagery
and allowing for a broader range of
LEDs to be used. Per Burley J in
Pfizer Ireland Pharmaceuticals
Samsung Bioepis AU Pty Ltd (No 4)
[2024] FCA 678]
, the requirement to
disclose the best method is ‘a safeguard against a patent applicant
holding back information in its possession
with a view to getting the benefit of
a patent monopoly, without conferring on the public the full consideration for
grant of that
monopoly.’ That is the precise wrong in the present case:
MAF seeks to hold back information on the camera it used to make the
‘unexpected discovery’ that a colour camera has high
sensitivity in
with a view to getting a monopoly for a method utilising
CMOS camera.” (OS, original italic, underlining added, reference(s)
The Applicant’s original submissions
Applicant begins their arguments by stating that the Opponent has not discharged
their onus:
“51. In advancing this ground, the opponent
incorrectly asserts that the applicant bears an onus: see OS, para 67.
not the case that, having raised best method, the onus then shifts from the
opponent to the applicant
. The onus at all times rests with the
opponent” (AS, underlining added),
and emphasises that “there is no evidence that the applicant has
deliberately withheld anything” (AS in [52]).
Applicant also notes that:
“52. ... The present case stands
in stark contrast to the circumstances
], where in any
the best method attack failed
. In other words, what were said to be
the vices (deficiencies) residing in the specification in
were far more significant than the singular contention made in the present
the patentee
was not held to have
fallen foul of the requirement to disclose best method
underlining added)
agree that “[t]he present case stands in stark contrast to the
circumstances in [
]” insofar as the latter case was related
to an application pursuant to
Federal Court of Australia Act
; however, I do not share the Applicant’s views on the outcome of that
decision as evident from Bennett J’s conclusion:
It follows that Expo-Net has established that
of successfully defending the claim that the inventor failed to
disclose the best method known to him. It is
reasonably arguable
there was no failure to describe
the details of the choice of foaming agent,
or the exclusion of certain classes of foaming agent, to persons of skill in the
any more than it was necessary to describe the kind of machine components
in the apparatus of the claim.
57. It follows that Buono-Net’s application for judgment under s 31A of
the FC Act,
on the grounds that
there is no reasonable defence
ground of invalidity based upon a failure to describe the best method known to
the inventor of performing the invention as
required by s 40(2)(a) of the Act,
This does not predetermine the outcome of this ground of
at the substantive hearing of these
proceedings
, underlining, italic, and bold
addition, the Applicant submits that “for the reasons explained further
below, the opponent places a construction on Figure
3 which is not reflected in
the disclosure in the Application. That is,
the opponent construes Figure 3
as relating to a particular, undisclosed camera, when in fact a proper review of
the Application reveals
that is not what Figure 3 concerns
[52], underlining added). In that respect, the Applicant contends that:
“53. The starting point in the present case is to note that
there is nothing in the Application to suggest that Figure 3 relates
specific camera for use with the invention. It is simply held out as
that would be suitable. In this regard, as noted on page 16, lines
14–16, of the Application:
Figure 3 is
of a spectrum of sensitivity of a
colour camera sensitive to infrared and which can be used as a multispectral
camera in a method
and device for optical analysis in accordance with the
’”. (AS, original underlining and italic)
Applicant also refers to the PMPP as “confirm[ing] at [5.6.7.5] [that]:
...the description of the method does not need to refer
to a specific example (preferred embodiment) of the invention. If there are
adequate instructions for the skilled person to put the claimed invention into
effect, the best method requirement will
’” (AS in [54], original italic, underlining added)
to the Applicant, it follows that the best method requirements are met because:
there is clearly enough information for the
skilled person to perform the invention
, precisely for the reason that
they could use the information provided by Figure 3 to ensure they sourced a
suitable camera, providing a similar spectrum of sensitivity
. It should also
be noted that there is nothing in the specification that suggests that the
camera used must correspond (precisely)
with Figure 3.” (AS, underlining
must note that I find the Applicant’s interpretation of the PMPP somewhat
puzzling, as it appears to advocate for the absurd
proposition that the
requirements of s 40(2)(aa) will always be met as long as the requirements of s
40(2)(a) are met. The Applicant
seems to disregard the context in which the
quoted guidance in the PMPP is provided as well as the word
“generally”.
Such guidance is applicable to the process of patent
examination where,
, there will be no contravening circumstances
or evidence. Clearly, oppositions under s 59 are different.
Applicant then refers to
(a case also mentioned by the Opponent,
in paragraph [60] of OS, as confirming the
analysis), submitting
] the Full Federal Court stated
that the ‘best method’ requirement puts an obligation on an inventor
to disclose a method
at the time of filing the complete patent
application
taken the methodology to a more
satisfactory stage or provides more certainty so that the public may more
quickly and easily utilise
the invention for which a monopoly is
.’” (AS, original italic, reference(s) omitted)
I have reproduced the whole section of
that includes the text
quoted by the Applicant, but I am still unsure as to how this quotation helps
the Applicant’s case:
Provisional applications
and complete specifications
62. The Act distinguishes between the obligation to describe the invention
and the obligation to describe it fully, including the
best method known to the
patentee of performing the invention.
63. Different obligations of description of the invention exist for
provisional and complete specifications. By s 40(1), a provisional
application
must describe the invention, but a complete specification must describe the
invention fully including the best method
known to the applicant of performing
the invention (s 40(2)(a)). In a provisional application, the inventor discloses
of the invention in order to protect the invention, but is provided
with the opportunity to develop the invention before the date
64. The proposition underlying a separate and additional obligation on the
part of the inventor filing a complete specification is
inventor in fact knows of a method at the time of filing the complete patent
application, which has taken the methodology
to a more satisfactory stage or
provides more certainty so that the public may more quickly and easily utilise
the invention for
which a monopoly is granted, the inventor is under an
obligation to disclose that method
65. This statutory distinction has provided a basis for the consideration of
whether the patentee is under an obligation to provide
the best method over and
above an obligation to describe the invention.” (original italic and bold,
underlining added)
respect to the evidence, the Applicant quotes paragraphs [455]-[457] of Walsh,
directing attention to the following statements
by Professor Walsh:
I expect that out of the range of CMOS sensors
available, there will be some models that have lower sensitivity in the NIR
some models that have high sensitivity in the NIR range, compared to
the spectrum shown in Figure 3. A skilled person could identify
an appropriate
sensor to use in the method of the opposed specification based on the
sensitivity curve for a particular sensor
For example, the Basler camera described in paragraph 30 of the Berry
declaration has pretty good NIR sensitivity approaching the
sensitivity shown in
Figure 3. ...
This shows the sensor in the Basler camera is relatively
sensitive in the NIR range
Additionally,
I do not believe the sensitivity shown in Figure 3 is
critical to the present invention
. It is certainly beneficial to have a
higher sensitivity to provide better imaging, but it’s also possible to
increase the
signal if it is low. ... It is true that doing so will also
increase any noise associated with the signal and this noise will be
captured image.
It is therefore preferable to pick a sensor that has a high
sensitivity in the NIR, but I maintain that the invention does not depend
.” (AS in [57], original underlining and italic)
Applicant also refers to Berry-1 by reproducing the spectral response provided
at paragraph [30] and quoting paragraph [31], and
submits that Mr Berry
“presents a compelling case that different cameras with different spectral
responses would still provide
usable images for the purpose of
analysing an object for a machine vision system
[58], original underlining and italic).
Applicant further asserts that “[a]t the heart of the ‘best
method’ attack is the question whether the skilled
addressee could perform
the invention based on the spectral responses discloses in Figure 3” and,
referring to the Specification
on page 21, lines 2-4, concludes:
“60. Figure 3
provides a skilled addressee with clear
guidance of exemplary spectral responses they would be looking for when
selecting a camera
for use with the invention
, noting also that the
applicant directs the skilled addressee to one possible choice of
comprising a 1920 × 1200 pixel CMOS sensor
’. With the
information contained in the specification, it would be a mere case of selecting
a suitable camera — that
process would not require ingenuity or undue
experimentation.
61. It is submitted that this information, together with the other matters
referred to above,
establishes that the opponent’s best method attack
is without merit
.” (AS, original italic, underlining added,
reference(s) omitted)
The parties’ post-hearing submissions
my post-hearing correspondence, I asked the following question:
“It appears that Figures 1-3 illustrate a comparison between
the relative spectral sensitivities of cameras used in the prior
automatically sorting fruit or vegetables (Figures 1 and 2) and that of a camera
that can be used in the present invention
(Figure 3).
The description explains that Figure 1 represents ‘a monochrome camera
comprising a CMOS sensor conventionally used in the prior
art for optical
analysis for the purpose of automatically sorting fruit or vegetables by
infrared and/or ultraviolet imaging. As
shown, the sensitivity of the camera in
the infrared range is not zero but is relatively low’ (page 16, line 28
17, line 3). Hence, this is a camera with a CMOS sensor that was
‘conventionally used’ in the prior art for infrared
imaging, despite
its ‘relatively low’ sensitivity. The mere fact that such camera was
‘conventionally used’
for infrared imaging for ‘automatically
sorting fruit or vegetables’ means that this ‘relatively low’
sensitivity
in the infrared range was acceptable for that purpose.
The description further explains that Figure 2 represents ‘a colour
camera comprising a CMOS sensor and a Bayer filter matrix,
as well as an
infrared cut-off filter, conventionally used in the prior art for optical
analysis for the purpose of automatically
sorting fruit or vegetables by imaging
in the visible range. As shown, such a colour camera is totally insensitive in
the infrared
range’ (page 17, lines 4-7). The evidence appears to suggest
that such total insensitivity in the infrared range is due to
the presence of
the infrared cut-off filter, which is included so that the quality of the image
in the visible range is not affected
by the sensitivity in the infrared range
when the light source includes infrared spectral components.
Unfortunately, the explanations with respect to Figure 3 appear somewhat less
detailed. Below, I have quoted all instances, I was
able to find, where Figure 3
is mentioned (underlining added to all quotations):
‘figure 3 is an example of a
spectrum of sensitivity of a
colour camera
sensitive to infrared and
which can be used as a multispectral camera in a method an [
for optical analysis in accordance with the invention’ (page 16, lines
‘In contrast, the inventor has unexpectedly discovered that
colour camera without an infrared cut-off filter
is actually
particularly sensitive in the infrared range,
as shown in figure 3
can thus be used equally well in the visible range and in the infrared range,
making it possible to simplify considerably the
optical analysis stations in the
devices for automatically sorting fruit or vegetables’ (page 17, lines
as seen in figure 3, the different groups of
photosensitive elements in the different primary colours of the camera do not
the same infrared sensitivity
. It is thus advantageous to rebalance
these sensitivity differences and to do so simply by adjusting the white balance
of the camera
before capturing the corresponding infrared image. This adjustment
can be effected by previously
experimentally measuring these differences in
sensitivity for each infrared illumination wavelength, i.e. from the knowledge
spectrum as illustrated in figure 3
’ (page 24, line 23 –
page 25, line 1).
It is interesting to note that the specification does not appear to describe
the camera of Figure 3 as a CMOS sensor camera, despite
this camera of Figure 3
being, apparently, compared to the CMOS sensor cameras of Figures 1 and 2 as
well as despite the clear general
preference to CMOS sensor cameras in the
description and claim 1 being limited accordingly.
Hence, my question is: what, in your submissions, does Figure 3 actually
Arguably, it may be possible that Figure 3 represents a camera with the same
sensor as the camera of Figure 1 (which has acceptable
sensitivity in the
infrared range as noted above) with an added colour filter array, or represents
a camera with three sensors (one
for each primary colour) being the same as the
sensor in the camera of Figure 1. However, in such a case, it is difficult to
how the mere presence of the colour filters array or the prisms with
dichroic coatings, respectively, could result in the relative
sensitivity
spectrum of Figure 3, given the relative sensitivity spectrum of Figure 1. It
would appear that this could be possible
if, for example, the introduction of
the array or the prisms with coatings, respectively, would severely decrease the
quantum efficiency
(or absolute sensitivity) in the visible range (as the
quantum efficiency in the infrared range would not be increased), which does
seem to normally be the case. Another possibility could be that the quantum
efficiency in the visible range was deliberately
reduced to match the
‘relatively low’ sensitivity in the infrared range; however, this
does not appear to be a normal
practice either.
It may also be possible that Figure 3 represents the camera of Figure 2 with
the infrared cut-off filter removed. Indeed, there appears
similarities, in the visible range, between the respective curves in the two
figures. In addition, quotation (2) above
occurs in the description immediately
after the (also quoted above) explanation with respect to Figure 2. On the other
hand, if Figure
3 indeed represents the camera of Figure 2 with the infrared
cut-off filter removed, this might suggest that the prior art colour
CMOS sensor
cameras used for imaging in the
range, were significantly more
sensitive in the
range (obviously, with the infrared cut-off
filter removed) than the prior art monochrome CMOS sensor cameras (see Figure 1)
for imaging in the
range. Given that the CMOS sensors used
in the monochrome and colour cameras do not appear to be significantly different
the added filters, this does not seem to be normal. Furthermore, the
description does not appear to explicitly mention that Figure
3 represents the
camera of Figure 2 with the infrared cut-off filter removed.
It may also be possible that Figure 3 actually represents a camera with a
sensor that is different from the sensors of both cameras
represented by Figure
1 and Figure 2. During the hearing, if I have understood the submissions
correctly, the Applicant suggested
that Figure 3 could be representing a newer
camera. However, since no such newer camera appears to be described in the
specification,
it is reasonable to assume that it would still be a prior art
camera. It is not unreasonable to expect that, when discussing the
(e.g., with respect to Figures 1 and 2), the specification will refer to the
prior art technology as it was available immediately
before the priority date,
and not to some pieces of prior art technology that were already obsolete at the
priority date (e.g., old
cameras with low sensitivity sensors, etc.). Hence, one
would wonder, if such newer prior art camera existed, why it was not used
prior art for imaging in either the visible or the infrared range, instead of
the cameras of Figures 1 and 2.
Another possibility might be that Figure 3 does not actually represent any
particular camera or type of cameras. In such a case, Figure
3 might have not
been generated by actually measuring the spectral sensitivity, but instead it
might have been generated as a drawing
used to illustrate the inventive concept.
There are, however, some considerations going against such assumption. Firstly,
3 is presented as a graph having specific values for the wavelength and
the relative spectral sensitivity on X and Y axes, respectively.
Secondly, the
three curves are not perfectly smooth. Neither of these would be expected to be
generally present in a conceptual drawing,
which is not specifically described
as such. Finally, the underlined parts of quotations (1) to (3) above also seem
to suggest that
the graph of Figure 3 is not merely a drawing provided to
illustrate the concept of the invention.” (original underlining and
parties’ responses are relatively concise, and I have reproduced them in
full. The part of the Opponent’s Post-Hearing
Submissions, related to my
question above, is as follows:
“13. Figures 1 and 2 are
specifically described as examples of the spectrum of sensitivity of prior art
14. Figure 3 is not described as illustrative of the prior art but as
‘an example of a spectrum of sensitivity of
a colour camera
sensitive to infrared and
which can be used as a multispectral camera...in
accordance with the invention
’ (our emphasis).
15. It is clear that Figure 3
is more than an illustrative example
because it is held out as showing the ‘particular sensitivity’ (e.g.
over the prior art cameras of Figures 1 and 2) of
the multispectral camera of
the claimed invention. We also note
the reference on page 24 line 28 to
‘previously experimentally measuring’ differences in sensitivity
for each infrared illumination wavelength which differences are said to be shown
in Figure 3.
16. We agree with the final paragraph of your question 3 that Figure 3
not described as a drawing to illustrate the concept of the invention
includes detail which one would not expect to see in a conceptual drawing.
17. On the balance or probabilities Figure 3
shows the results of a
particular camera used by MAF to develop its alleged invention. It is common
ground between all experts that
the response shown in Figure 3 is better than
other identifiable cameras
. MAF has not disclosed which camera produced the
results shown in Figure 3 and hence has failed to disclose the best method known
to it of putting the claimed invention into practice – the multispectral
camera and its ‘particular sensitivity’
being at the heart of
MAF’s alleged invention.
18. During the hearing, MAF’s counsel made the surprising statement,
unsupported by any evidence, that
MAF’s ‘unexpected
discovery’ was due to a ‘new’ generation of CMOS cameras being
. This is not disclosed in the specification nor claimed. However,
if correct, this is a further reason why
the specification has not disclosed
the best method, why the claims lack support, and why there is a lack of clear
and complete enough
of the alleged invention.” (OPHS,
original bold, underlining added)
part of the Applicant’s Post-Hearing Submissions, related to my question
above, is as follows:
The applicant’s engineers
have confirmed that Figure 3 is a conceptual illustration—it does not
represent the sensitivity
spectrum of a particular camera
Figure 3 is intended to illustrate that a colour camera without an infrared
cut-off filter can be sensitive to infrared radiation.
It is not intended to
indicate a particular camera to be used for the invention
Respectfully, the fact that the curves in Figure 3 are not perfectly smooth,
or that the axes are marked with specific values, does
not preclude Figure 3
from being a conceptual illustration.
These features provide context to
facilitate the interpretation of Figure 3 and the comparison of Figure 3 with
Figures 1 and 2
.” (APHS on page 2, underlining added)
I mentioned earlier in this decision, uninvited submissions with respect to the
Applicant’s Post-Hearing Submissions were
received from the Opponent, and
this prompted my invitation to the Applicant to provide any additional
submissions they may wish.
These final submissions by both parties are also
reproduced in full, starting with the Opponent:
“1. ... we do
briefly observe:
importance of Figure 3, and whether it shows an actual spectral response curve,
has been at the heart of this opposition since
the Opponent’s initial
pleadings. The Applicant could have chosen to file evidence on the provenance of
Figure 3 either in
support of the application, or under regulation 5.23. It did
Applicant now seeks to assert in correspondence and without corroboration that
Figure 3 is only ‘a conceptual illustration’.
Respectfully,
the Applicant’s submissions on Figure 3 in its 16 January 2025 [i.e., the
Applicant’s Post-Hearing Submissions]
should be regarded with some
caution, coming as they do after hearing the Opponent’s case on best
method, clarity, and lack
of clear enough and complete enough disclosure of the
claimed invention.
2. However, in the event that the
Applicant’s submissions are accepted:
3 is at the heart of the Application’s self-described ‘unexpected
discovery’, i.e., that a colour CMOS camera
was ‘particularly
sensitive’ to infrared radiation following removal of the IR filter.
However the experts of both the
Applicant and the Opponent agree that this was
not only unexpected but was known by the skilled team at the priority date of
Application.
Figure 3, by the Applicant’s own submission, is
therefore nothing more than a conceptual illustration of the common general
3 is not clearly described as a conceptual illustration. There is evidence of
experts in the field who reviewed the specification
Figure 3 was showing the response curve of an actual camera; and
troubled by the strength of the curve and the inability to identify the camera
that produced it.
submit this issue goes to whether the specification describes the claimed
invention in a ‘clear enough’ manner as required
by s 40(2) of the
Act, since it may lead the skilled person on a path of research to reproduce a
result which is unobtainable.”
(OFS, underlining added, reference(s)
respect to the above, the Applicant notes:
“We want to
correct a misrepresentation in paragraph 2a of the opponent’s submissions
of 14 February 2025 [i.e., the Opponent’s
Final Submissions]. Contrary to
what the opponent asserted,
the applicant did not submit that Figure 3 is
‘a conceptual illustration of the common general knowledge
The applicant does not believe that the information provided by Figure 3
forms part of the common general knowledge, and has never
claimed otherwise.
As for the other representations in the opponent’s submissions, we do
not consider that these refute any of the submissions
made by the
applicant.” (AFS, underlining added)
Best method – consideration
first question I need to answer is whether or not Figure 3 represents a
real-world existing camera or type of cameras. In that
respect, I find it
difficult to disagree with the Opponent that it was open (and not at all onerous
or costly, I would add) to the
Applicant to provide clear evidence on what
exactly Figure 3 represents. The Applicant’s argument with regards to
the onus and the lack of evidence that the Applicant has deliberately
withheld anything does not appear to me very convincing. As
perhaps alluded to
in my question quoted above, the Application is not manifestly unambiguous on
whether Figure 3 represents an existing
camera or not. Because of that, the
Opponent argues that Figure 3 represents a real-world existing camera which is
better suited
to performing the invention but is not disclosed in the
Application. In my opinion, such an argument is not unreasonable, and
is not completely without merits in regard to the best method
requirement under s 40(2)(aa).
acknowledge the Applicant’s post-hearing submissions that “[t]he
applicant’s engineers have confirmed that Figure
conceptual illustration
—it does not
represent the sensitivity spectrum of a particular camera” (underlining
added). However, submissions referring
to the opinion of anonymous
“applicant’s engineers” with no clear and explicit connection
to the Application cannot
serve as proper evidence. Such evidence should,
instead, be provided by the inventor, or by someone else having a clear
association
with the Application and having direct knowledge of what exactly is
in the Specification. It follows that these submissions do not
carry enough
weight, so that they would be sufficient to resolve the issue of best method.
Therefore, I will need to consider them
in the context of the wording of the
Specification itself and the available evidence.
Figure 3 and the wording of the Specification
already noted the lack of an explicit indication in the Specification of whether
Figure 3 represents a real-world existing camera
as submitted by the Opponent,
or it is simply a conceptual illustration as submitted by the Applicant. In
what follows, I will discuss
all references in the description to Figure 3, in
an attempt to assess whether or not the Specification supports the
Applicant’s
submissions that this figure is a conceptual illustration. I
will also take into account the Applicant’s arguments on the
quoted earlier in this decision.
the outset, it is worth noting that a conceptual illustration (of the sort
presented in Figure 3), by its nature, is not a truthful
representation of any
scientific or engineering measurements. Hence, a conceptual illustration does
not reflect the real-world phenomena
with sufficient accuracy to serve as a
basis for scientific or engineering analyses or conclusions. This means that a
illustration could be no more than an illustration, perhaps even
simplified, that is used to facilitate the communication of such
phenomena to an
audience. The actual need for a conceptual illustration depends on the
phenomena to be communicated and the background
knowledge of the audience. In
that respect, it is important to note that a patent specification is addressed
to a person skilled
in the relevant art, not to a lay person.
my question quoted above, I observed that the description mentions Figure 3 on
three occasions. The first occasion is as follows:
an example of a spectrum of sensitivity of a colour camera
to infrared and which can be used as a multispectral camera in a method an
] device for optical analysis in accordance with the invention”
(page 16, lines 14-16, underlining added)
Applicant emphasises the use of the word “example”; however, I am
not sure how this assists their case. In my opinion,
“an example”
of something is quite distinct from “a conceptual illustration” of
something. It is not unreasonable
to expect that “an example” could
refer to a real-world entity, as this is often the case in patent
specifications.
Applicant also argues that “Figure 3 is intended to illustrate that a
colour camera without an infrared cut-off filter can
be sensitive to infrared
radiation” (APHS on page 2, quoted earlier). However, in light of the
CGK, I cannot see a real need
for a conceptual illustration of this relatively
simple to communicate and understand phenomenon, the illustration being
to the verbal statements to that effect that are already present in
the description.
on the basis of the evidence before me as it will be discussed in the next
section of this decision, I consider that the
PSA would be well aware that the
higher the sensitivity in the infrared, the easier it is to achieve a good
quality image in the
infrared. In light of this, the Applicant’s further
argument that “Figure 3 provides a skilled addressee with clear
of exemplary spectral responses they would be looking for when selecting a
camera for use with the invention” is not
particularly persuasive. In my
opinion, “a skilled addressee” will gain nothing from such graphical
guidance, unless
it is representative of a real-world existing camera or type of
second occasion, on which the description mentions Figure 3, is as follows:
“In contrast, the inventor
has unexpectedly discovered
that a colour camera without an infrared cut-off filter is
particularly sensitive in the infrared range, as shown in figure 3
thus be used equally well in the visible range and in the infrared range, making
it possible to simplify considerably the
optical analysis stations in the
devices for automatically sorting fruit or vegetables” (page 17, lines
8-12, underlining added)
I already discussed in the section “The common general knowledge”,
the evidence on file clearly demonstrates that the
PSA would know that “a
colour camera without an infrared cut-off filter” would have some
sensitivity in the infrared.
In light of this, what “the inventor has
unexpectedly discovered” could only be that the sensitivity in infrared is
unexpectedly high. The Specification is completely silent as to how the
inventor has made their discovery. While I acknowledge
that this is not a legal
requirement, some explanations about that could have been very helpful in
clarifying the issue with Figure
3 and, potentially, for supporting the
Applicant’s case. In the absence of any explanations or statements to the
prima facie
unlikely that such a discovery could
have been made on the basis of theoretical considerations alone, without
actually removing the
infrared cut-off filter from at least one colour camera
(or procuring at least one colour camera without such filter) and measuring
sensitivity in infrared. Hence, it could be expected that the inventor’s
discovery, which is “as shown in figure
3”, would be evidenced and
illustrated by the measurement results and not by a conceptual illustration.
third and final occasion, on which the description mentions Figure 3, is as
In fact, as seen in figure 3
, the different
groups of photosensitive elements in the different primary colours of the camera
do not all have the same infrared
sensitivity. It is thus advantageous to
rebalance these sensitivity differences and to do so simply by adjusting the
white balance
of the camera before capturing the corresponding infrared image.
This adjustment can be effected by previously experimentally measuring
differences in sensitivity for each infrared illumination wavelength, i.e. from
the knowledge of the spectrum
as illustrated in figure 3
24, line 23 – page 25, line 1, underlining added)
that the “photosensitive elements in the different primary colours of the
camera” have different colour filters
(and are otherwise likely to be the
same), I do not think that the concept that they could potentially have
different sensitivity
in the infrared would be completely surprising for the
PSA. Hence, in my view, the mere mentioning of this finding would be entirely
sufficient, and referring to a conceptual illustration adds nothing to that.
also consider that the teaching that “adjustment can be effected by
previously experimentally measuring these differences
in sensitivity for each
infrared illumination wavelength, i.e. from the knowledge of the spectrum”
would be perfectly understandable
to the PSA without any need to refer to a
conceptual illustration, which does not, in fact, illustrate the adjustment
respect to the comments, in my question, about the specific attributes of Figure
3, the Applicant replies (as quoted above):
“Respectfully,
the fact that the curves in Figure 3 are not perfectly smooth, or that the axes
are marked with specific values,
does not preclude Figure 3 from being a
conceptual illustration
. These features
provide context to facilitate
the interpretation of Figure 3
the comparison of Figure 3 with
Figures 1 and 2
.” (underlining added)
I agree with the Applicant that the existence of these attributes “does
not preclude Figure 3 from being a conceptual
illustration”, such
attributes, in the absence of any specific mention in the Specification that
Figure 3 is indeed a conceptual
illustration, create the impression that the
drawing represents a measurement result, rather than “provide context to
the interpretation of Figure 3”. In my opinion, the best way
“to facilitate the interpretation of Figure 3” would
have been to
provide in the description clear explanations about its nature and content.
said impression can only be reaffirmed by “the comparison of Figure 3 with
Figures 1 and 2”. Figures 1 and 2 are
described as representing cameras
“conventionally used in the prior art for optical analysis for the purpose
of automatically
sorting fruit or vegetables” (page 16, line 29 –
page 17, line 1, and page 17, lines 5-6, respectively). This strongly
that these figures depict the spectra of particular prior art cameras, or at
least the spectra typical of such cameras,
rather than mere conceptual
illustrations.
summarise, the description indeed does not provide clear explanations with
respect to the nature and content of Figure 3. In addition,
I do not consider
that the nature and content of this figure could be
unambiguously
from reading the Specification as a whole. If anything, it appears to me that,
reading the Specification creates an impression
that Figure 3 could be
representative of the measurement results that have led to the inventor’s
unexpected discovery. If
Figure 3 is indeed only a conceptual illustration, it
adds nothing. In my opinion, the PSA would be perfectly capable of
understanding
the communicated phenomena and concepts without it. The PSA,
reading the Specification with the (not completely unreasonable) assumption
Figure 3 should be providing some useful information to them, could easily
conclude that this figure indeed represents measurement
last point above will be convincingly illustrated in the next section of this
decision, when I consider the evidence provided
by the experts with respect to
The evidence related to Figure 3
discussing the comments with respect to Figure 3 provided by the experts having
read the Specification in light of the CGK,
I consider it convenient to
reproduce below the sensitivity spectra (or spectral responses) of some
real-world existing cameras found
in the experts’ declarations.
above is the spectral response of Basler acA1300-200uc camera, found in Exhibit
DB-3, reproduced in paragraph [30] of Berry-1,
and also reproduced in paragraph
[58] of the Applicant’s Summary as mentioned above (for brevity, I will
refer to this as “the
Berry-1 Example
may be worth noting that, in the same paragraph, Mr Berry also reproduces the
spectral response of a second Basler camera (i.e.,
acA640-750uc); however, since
I am unable to identify any substantial differences between the spectral
responses of the two Basler
cameras, I have not reproduced the spectral response
of the second Basler camera.
above is the spectral response of an example camera reproduced in paragraph
[454] of Walsh (I will refer to this as “the
Walsh Example
easier comparison, I have also reproduced Figure 3 of the Specification.
considering the evidence with respect to Figure 3, I will focus mostly on the
parts that could assist in answering the (already
mentioned) first question of
whether or not Figure 3 represents a real-world existing camera or type of
cameras, and a second question
of whether the camera of Figure 3 (existing or
hypothetical) would be better suited for performing the present invention than
existing cameras that the PSA would have been expected to be able to
identify and procure for the implementation of the invention.
McGlone comments:
“97. The Opposed Application itself teaches
that any colour camera is acceptable. However
I am surprised by Figure 3
Figure 3 shows a set of colour camera spectra over the visible and near-infrared
wavelength where there is no IR filtering. There
are spectra corresponding to
each of the RGB colour channels.
The surprising matter to me is the high
sensitivity in the near-infrared range compared to that in the visible
. For instance, the sensitivity of the red channel is higher in the 800
to 900 nm range compared to that in the visible range at 600
been able to independently verify these results from anything I know of colour
. Indeed, based on my knowledge and understanding the sensitivity
into the near-infrared should be much reduced compared to that in
the visible,
such as in the paper I referred to at paragraph [89] of my evidence.
98. Neither does the Opposed Application explain to me
how the inventors
of this patent arrived at this result shown in Figure 3
. I would not be able
to select a camera which was capable of producing these same results without
some further guidance, such as
what sensor was used to achieve the
. I therefore
do not think the skilled team would be able to
readily identify a camera which could produce the same sensitivity as shown in
204. The figures contained in D7 as to the spectral responses of these Manta
cameras are consistent with my own understanding as to
the spectral responses of
a typical colour CMOS camera in the infrared, i.e., that there is a reduction
from peak sensitivities once
you exceed 800nm. This stands in contrast to Figure
3 of the Opposed Application
which I still consider unexplained as to how
this result was arrived at
.” (McGlone-1, underlining and italic added)
my opinion, the above suggests that Dr McGlone, when he first read the
Specification, understood Figure 3 to represent an actual
camera sensor, and not
just a conceptual illustration. Based on his comments, the latter possibility
did not appear to come to his
mind, despite the fact that “[he was]
surprised by Figure 3”, and “[did] not think the skilled team would
to readily identify a camera which could produce the same sensitivity as
shown in Figure 3”.
does not appear to explicitly comment on whether the camera having the sensor of
Figure 3 will be better for performing
the invention, than the cameras he was
familiar with.
to Mr Berry, he considers that:
“64. ... Figure 1 of the
specification clearly shows the spectrum of sensitivity of a mono camera –
which is well into
the IR range (i.e. above 700nm). Figure 2 shows that a camera
fitted with a colour sensor (i.e. one which includes a Bayer filter)
response in the IR range, but that is because the camera is also fitted with an
Figure 3 shows the result of removing that filter, or of applying
a Bayer filter to the sensor shown in Figure 1
– which is that each
camera is sensitive in the IR range. There is nothing new or surprising in this.
65. The spectrum of sensitivity shown in Figure 3
is greater than I would
ordinarily expect from removing the IR filter and is greater than the responses
of the Basler cameras I discussed
in paragraph 30 above
[i.e., the Berry-1
Example]. For example, the sensitivity of red is better at 850nm (in the IR
range) than it is at 600nm (in the
visible range). Although response curves do
vary widely for different sensors,
if the results were to be replicated it
would be necessary to know
which specific sensor was used to produce the
curve in Figure 3
. For example, the document
annexed as Exhibit
covers sensors from several manufacturers and shows some with much
larger NIR response that are more similar to Figure 3
but none which is
that shown in Figure 3
. I think there are two ways of
approaching this:
65.1. If the invention turns on getting the same results as in Figure 3, then
an important piece of information is missing. There
are many hundreds of sensor
manufacturers making many thousands of
It would be an
extremely time consuming task to determine which of
delivered the
same result as shown in Figure 3
65.2. Alternatively, it is not necessary to achieve the same results in
Figure 3 to implement the invention, in which case any colour
camera with a
Bayer filter will do the job and the use of that camera is not surprising.
Given the various statements in the specification itself (for example on page
8) that any CMOS or CCD colour camera can be used, I
think the latter approach
is more likely.” (Berry-1, original bold, underlining and italic added)
Mr Berry concludes that it is “more likely” that “it is not
necessary to achieve the same results in Figure
3 to implement the
invention”, his evidence suggests that he treats the spectra on Figure 3
as being representative of a real
“specific sensor”, and not as just
a conceptual illustration. The latter possibility does not appear to come to
mind, despite the sensitivity in the infrared being “greater than [he]
would ordinarily expect”. Furthermore, he clearly
states that “[i]t
would be an extremely time consuming task to determine which of those [sensors]
delivered the same result
as shown in Figure 3”.
Berry also alludes to the spectral sensitivity of Figure 3 being better in the
infrared, since “none [of the sensors in Exhibit
DB-7] is as good as that
shown in Figure 3”.
I mentioned earlier, the Applicant appears to rely a great deal on Walsh.
Indeed, Professor Walsh provides a comprehensive discussion
of Figure 3:
“267. As at March 2017 it was known that a colour camera is
sensitive to light radiation in the infrared range. This was why
NIR cut-off
filters were and are used. However, in my working knowledge of the topic
considered that the NIR light passing R, G and B pixel filters would be strongly
, and thus it is common practice to use a monochrome camera with a
long pass filter when acquiring a NIR image. However
Figures 2 and
of the specification offer a different appreciation
268. Figure 2 shows the standard, known interpretation of the sensitivity of
a colour CMOS camera with pixel level red, green, and
blue filters and an
overall short-pass filter at around 670 nm as at March 2017 and as used in
colour cameras where an IR cut-off
filter is in place. All sensitivity to light
beyond about 670 nm is cut-off so that no signal is output from the camera at
any wavelength
above 680 nm. The red filter senses into the green region and the
green filter overlaps with both the blue and the red regions.
269. Figure 3 then shows the sensitivity of
the same red, green, and
blue filters
but without the presence of the IR cut-off filter
Each of the red, green, and blue filters demonstrate transparency in the NIR,
particularly at wavelengths above 800 nm so they show
significant sensitivity in
the IR region. Relative to the green and red filters, the blue is a little less
sensitive with a first
peak at around 460 nm of approx. 0.78 (on a 0 to 1 scale)
in intensity and a second peak at around 875 nm of 0.62 in intensity. The
filter blocks out most of the red light but then shows increased sensitivity
from above 780 nm and peaking at around 875 nm,
at which point the blue filter
pixel response is almost as high as it is in the visible. Similarly, the green
filter shows a peak
in sensitivity at around 525 nm, then blocks out most of the
red light but shows increased sensitivity from around 700 nm to 950
peak in the NIR at around 870 nm, with a response only a little lower than its
peak in the visible region. The red filter
blocks out all blue light and most of
the green light with a first peak in sensitivity in the visible at around 600
nm. It shows
increased sensitivity from around 725 to 950 nm with a peak at
around 870 nm that is greater in sensitivity than in the visible.
So it is more
responsive in the IR than it is in the visible.
270. ... As the unfiltered CMOS sensor sensitivity decreases with wavelengths
above approximately 600 nm, the increased response of
the R channel to NIR
wavelengths compared to red wavelengths indicated that the R filter is actually
more transparent to the NIR
wavelengths than it is to red light.
I was not aware just how transparent these filters can be in the NIR
and this is a key feature of the current application
. The concept is valid
even for R, G B filters with lower NIR transparency,
the application will be
by use of CMOS cameras with RGB filters showing
NIR sensitivity
. An online search reveals that CMOS sensor
providers sometimes do not provide NIR response curves, as their intended market
visible light imaging, but when provided
there is a large variation in
NIR sensitivity demonstrated between sensors
(of different models and
manufacturers).
274. In short, the inventors have made very good use of the NIR sensitivity
of a colour CMOS camera instead of a monochrome camera
for capturing images in
the NIR region.” (Walsh, underlining and italic added)
the above, Professor Walsh focuses mostly on the transparency of the RGB filters
in the infrared, as “[he] was not aware
just how transparent these filters
can be”. Apparently, he assumes that Figure 3 represents “the same
red, green, and
blue filters [as on Figure 2] but without the presence of the IR
cut-off filter”. Based on the spectral sensitivity of the
“unfiltered CMOS sensor”, he reaches the conclusion that “the
R filter is actually more transparent to the NIR
wavelengths than it is to red
light”. Importantly, however, Professor Walsh discusses Figure 3 in
a level of detail that I
consider would be warranted only if he believes that
this figure is a representation of a real-world sensor with a real-world RGB
filter (thus showing the properties of the real-world sensor-filter
combination), and not just a conceptual illustration which, as
I mentioned
earlier, cannot serve as a basis for any scientific or engineering analyses or
conclusions. As was the case with the
other two experts, he does not mention
anything about the latter possibility for Figure 3.
Walsh also considers that “the application
will be assisted
of CMOS cameras with RGB filters showing
NIR sensitivity”
(underlining added), but stops short of stating that the camera of Figure 3 will
be better than the other
known cameras, observing instead that “there is a
large variation in NIR sensitivity demonstrated between sensors (of different
models and manufacturers)”. It is perhaps worth noting that the latter
observation is based on “[a]n online search”,
i.e., not necessarily
based on prior knowledge regarding the cameras available at the priority date.
This could possibly be explained
by the fact that, as I discussed in the section
“The experts”, in the hypothetical team that Professor Walsh
he will not be the member who would be responsible for selecting the
particular cameras.
Berry-1, Professor Walsh notes that it “repetitively states that the
spectrum of sensitivity shown in Figure 3 of
the opposed specification is
different from the sensitivity of cameras he is aware of” (Walsh in
[454]). He then continues
by discussing that “[t]he ‘relative
response’ is ... a combination of spectral transmissivity of the RGB
(i.e. how much light each lets through)
the response of the
sensor” (Walsh in [454], original italic). Finally, he provides the Walsh
Example, reproduced above, and
comments that “
in this example, the
response of the R,G and b channels is quite strong in the NIR region
780 - 1000 nm” (Walsh in [454], underlining added).
Importantly,
the source of the Walsh Example is provided in Walsh at footnote 227 on page 179
<https://www.microcontrollertips.com/nir-cmos-image-sensors-work-in-low-to-no-ambient-light/>.
Below, I have reproduced the beginning of the article that is found at this URL
(I have highlighted some of the text in yellow).
The article is about the
Nyxel® 2 sensor, and it is the spectral sensitivity of this sensor that is
shown as the Walsh Example.
following observations can be made. Firstly, the article appears to be
published on 10 March 2020, which is after the priority
date. Secondly, as can
be seen from the highlighted text and the schematic illustration of the
“Nyxel® 2 Pixel”
compared with the “Standard Pixel”,
the article describes a specialised sensor with its pixels specifically designed
so that a higher infrared sensitivity can be achieved. The article notes that
the “competing mass-produced CMOS image sensors
are still failing to
achieve comparable NIR performance”.
Specification does not suggest the use of cameras with such specialised (and,
perhaps, more expensive) sensors, and I do not consider
that the high infrared
sensitivity of the Nyxel® 2 sensor could reasonably be described as an
unexpected discovery. Instead,
it appears that the present invention is about
selecting and using suitable sensors belonging to the group of the
mass-produced CMOS image sensors”.
acknowledge that Professor Walsh does not say that the camera of the Walsh
Example is something that the PSA could have used at
the priority date to
implement the invention. Nonetheless, he
provide the Walsh Example
note that “the response of the R,G and b channels is quite
strong in the NIR region”, which I find somewhat concerning.
Professor Walsh’s self-admitted lack of substantial experience in suitable
camera identification and procurement that
I discussed earlier, it appears to me
that the existence of the sensor of the Walsh Example has considerably
influenced his following
comments as quoted below and, in particular, his
summary in the last paragraph:
“455. I agree that RGB colour
cameras often have low sensitivity in the NIR range, with just a bit light
leaking through the
red filter.
But Figure 3 shows the potential sensitivity
of an RGB colour camera,
as does the figure above
[i.e., the Walsh
Example]. Further, every model of CMOS sensor has a different sensitivity curve.
that out of the range of CMOS sensors available,
there will be some models that have lower sensitivity in the NIR range
some models that have high sensitivity in the NIR range, compared to the
spectrum shown in Figure 3. A skilled person could identify
an appropriate
sensor to use in the method of the opposed specification based on the
sensitivity curve for a particular sensor
456. For example, the Basler camera described in paragraph 30 of the Berry
declaration [the Berry-1 Example]
has pretty good NIR sensitivity
approaching
the sensitivity shown in Figure 3
filter has a relative response of 1 at 650 nm. In the NIR range at 800 nm, the
sensitivity has dropped but it is still around
0.7. At around 470 nm, the blue
filter has a relative response of 0.65, which is about the same in the NIR range
at 800 nm. The response
of the green filter is also quite high in the NIR range.
the sensor in the Basler camera is relatively sensitive in the NIR
457. Additionally, I do not believe the sensitivity shown in Figure 3 is
critical to present invention.
certainly beneficial to have a higher
sensitivity to provide better imaging
, but it also possible to increase the
signal if it is low
. For example, and in the context of the invention, a
normal RGB camera in the visible is a multispectral camera with three channels
that lets through light at three different regions of the visible spectrum. In
the invention, they want to use this same camera in
the NIR region. As in the
visible, the response of each of the red, green, and blue filters differs in the
NIR. To get the same response
out of each filter, and therefore a high-quality
NIR image, the inventors adjust the response of the three channels so that they
are all the same. This might involve increasing the signal of one or two,
relative to the other(s). It is true that doing so will
also increase any noise
associated with the signal and this noise will be in the captured image.
is therefore
preferable to pick a sensor that has a high sensitivity in the
, but I maintain that the invention does not depend on it.
458. In summary, the example shown in Figure 3 has a high sensitivity in the
NIR range, but
it was a sensitivity that
could have been identified and
with the technology available as at March 2017
underlining, italic, and bold added)
Importantly,
if Professor Walsh was thinking of Figure 3 as a mere conceptual illustration, I
do not believe that he would have said
that it “shows the potential
sensitivity of an RGB colour camera” and that “Figure 3 shows a
spectral sensitivity
curve of a CMOS that is particularly responses [
in the Red channel at 850 nm” (Walsh in [462]).
Walsh’s lack of detailed knowledge about the properties of colour cameras
available on the market before the priority
date could also be the reason for
his opinion that:
“461. At paragraph 62, Berry asserts that
it was well-known that color sensors were sensitive to NIR light. This statement
not account for the transmissivity of the RGB filters (see my comments in
paragraphs 454 to 457). While it was technically known
that light could get
through the RGB filters in the NIR range,
in practice,
it was commonly
that colour sensors were not particularly sensitive in the NIR
. At the time,
I would have assumed
an NIR source
appearing in a RGB camera image was coming in through a tail on the red
.” (Walsh, underlining and italic added)
above appears somewhat contradictory to Professor Walsh’s own statements
(see Walsh in [456] as quoted earlier) that the
Berry-1 Example’s near
infrared sensitivity is “pretty good” and “
approaching
the sensitivity shown in Figure 3” (underlining added). It is vital to
emphasise that the Berry-1 Example is representative
of “the Basler
cameras that ControlVision was using and selling in New Zealand
before or at
the Relevant Date in 2017
” (Berry-1 in [29], underlining added), i.e.,
representative of cameras that were available for sale, hence likely to be
easy to identify when searching for a suitable camera, at the
priority date.
addition, while I agree with Professor Walsh that “every model of CMOS
sensor has a different sensitivity curve”, this
does not necessarily mean
that a camera with an infrared sensitivity as high as in Figure 3 could easily
be found. For example,
it is worth noting that the spectral sensitivity of the
Berry-1 Example in the 850-950 nm range is of completely different shape
shows a much faster decline toward longer wavelengths compared to Figure 3.
is also telling that Professor Walsh deliberately uses the word
“expect” (as opposed to, e.g., “know”).
It appears to
me that his expectation is based entirely on Figure 3 and the Walsh Example.
Professor Walsh attempted to identify
an example for a colour camera with a high
sensitivity in infrared, leading to the Walsh Example. However, he was unable
a more convincing example.
Importantly,
in addition to his statements (in italic) in the above-quoted paragraph [457] of
Walsh, Professor Walsh also notes that
“[t]he invention does not need this
responsivity, but generally
the more responsive in the NIR the RGB filtered
signal is, the better
” (Walsh in [462], underlining added).
his evidence in reply, Dr McGlone does not appear to comment on what camera
would be better suited for the invention. However,
in his evidence in reply,
Mr Berry clearly indicates that:
“44. As I have said
before, I do not think this means that the invention cannot be put into effect
because I believe many colour
cameras should be sufficiently sensitive in the
NIR range so as to make the claimed invention operable. However, it will likely
some level of compensation and adjustment to achieve imaging that is of
sufficient quality to allow for analysis of the fruit and
sensitive colour camera will require the reader to compensate with increased
illumination via higher powered LEDs or more LEDs
in the imaging
.” (Berry-2, underlining added);
thus, in essence, agreeing with Professor Walsh on camera suitability and
confirming the logical proposition that, given the expected
good sensitivity of
a colour camera in the visible, the higher the infrared sensitivity, the higher
the suitability of the colour
camera for the implementation of the invention.
Berry also comments that:
“43. The only aspect of Figure 3
that is unusual to someone like me with the appropriate level of expertise in
optics and camera
hardware is
the strength of the sensitivity shown by
used in that figure. It remains higher than all other spectral
responses I was able to locate and referred to in my first declaration
including the Manta cameras included in Exhibit DB-2 and the Basler cameras
included in DB-3, and also a number of sensors that
were shown in Exhibit DB-7.
Despite spending some time looking for this sensor,
I cannot tell you
which sensor
which camera
has been used in Figure 3
provide this particular spectral response.” (Berry-2, underlining and
italic added)
consider that the above discussion of the evidence (in combination with my
earlier discussion in the section “The experts”)
sufficient reasons for me to give less weight to the piece of evidence of
Professor Walsh stating that the infrared sensitivity
shown in Figure 3
“was a sensitivity that could have been identified and achieved with the
technology available as at March
2017” to the extent it contradicts the
evidence of Dr McGlone and Mr Berry. The same applies to Professor
Walsh’s other
evidence with respect to the availability and the
characteristics of the known colour cameras at the priority date.
is also important to note that, in my opinion, based on the experts’
comments with respect to Figure 3, none of the experts
considered this figure to
be a mere conceptual illustration.
Best method – conclusion
have considered the Specification and the evidence that could assist in
answering the two questions that I outlined earlier, i.e.,
whether or not Figure
3 represents a real-world existing camera or type of cameras, and whether the
camera of Figure 3 (existing
or hypothetical) would be better suited for
performing the present invention than the existing cameras that the PSA would
expected to be able to identify and procure for the implementation of
the invention.
relation to the first question, on the basis of the Specification, I concluded
that while the Specification as a whole does not
provide clear and unambiguous
explanations of the nature and content of Figure 3, the apparent impression is
that this figure is
likely to be representative of the measurement results that
have led to the inventor’s unexpected discovery. That the Specification
creates such an impression was convincingly confirmed as all three of the
experts that were shown the Application treated Figure
3 as if it was
representing a real-world existing camera. The possibility of Figure 3 being a
conceptual illustration did not appear
to cross the mind of any of the experts.
In my opinion, this is a clear indication that the PSA reading the Specification
consider that Figure 3 represents a real-world existing camera (or at
least type of cameras). Opposed to that is the Applicant’s
not evidence
) that “[t]he applicant’s engineers have
confirmed that Figure 3 is a conceptual illustration—it does not represent
the sensitivity spectrum of a particular camera”.
first question is a relatively simple, factual question. In the presence of
strong evidence, either by the inventor (or other
suitable person as I discussed
earlier), or by an expert identifying an existing camera with the spectral
sensitivity of Figure 3,
such a question could have been answered with a very
high degree of certainty. Unfortunately, no such evidence is before me. In
light of the Specification as a whole and the available evidence as it stands,
on the balance of probabilities
, I conclude that Figure 3 indeed
represents a real-world existing camera or type of cameras. I do not consider
the Applicant’s
submissions to be sufficient to shift the balance towards
Figure 3 being a conceptual illustration. In that respect, the
Applicant’s
choice to provide submissions instead of proper evidence is
something that, in my opinion, should also be taken into account.
relation to the second question, I consider that, while Dr McGlone did not
comment on the point, Mr Berry clearly suggests that
the spectral sensitivity of
Figure 3 is better than the spectral sensitivity of any other colour camera that
the PSA would have been
expected to be able to identify and procure for the
implementation of the invention. While Professor Walsh appears to be of
opinion (although he agrees that the higher the infrared sensitivity,
the better the colour camera for performing the invention),
he was not able to
substantiate his view with a suitable example despite his attempt to do so.
This leads to the conclusion that,
on the balance of probabilities
best method of performing the invention is the method which utilises the camera
or type of cameras of Figure 3.
camera or type of cameras of Figure 3 is not identified in the Specification,
and the evidence suggests (taking into account my
earlier conclusion about the
weight to be given to parts of the evidence of Professor Walsh) that this is an
unusual camera or type
of cameras that would not be easy for the PSA to identify
and procure. It is trivial that the Applicant knew about the camera or
cameras represented on Figure 3. In addition, as I already alluded to, it is
not unreasonable to expect that the Applicant
identified this camera or type of
cameras as a result of some experimental research. I consider it unlikely that
such research would
be limited to measurements performed on a single camera or
that the PSA would have been expected to be able
to identify and procure for the
implementation of the invention. With reference to the last stage of the
five-stage analysis quoted
on the balance of probabilities
consider that the Applicant also knew that, hence describing the performance of
this camera or type of cameras as unexpected discovery.
on the balance of probabilities
, I conclude that, by not identifying this
camera or type of cameras, the Specification does not disclose the best method
the Applicant of performing the invention.
The implications of my finding on best method
am of the view that my finding that the Specification does not disclose the best
method known to the Applicant of performing the
invention cannot be overcome by
an allowable amendment, i.e., without introducing new matter. It follows that
providing the Applicant
with an opportunity to amend would serve no useful
purpose, and the Application should be refused.
light of the above, I do not consider that it is necessary for me to decide on
the remaining grounds, as this will not affect the
outcome of the opposition.
Nonetheless, while I will not decide the issues conclusively, I will provide
certain observations in
the hope that they may be of some benefit to the
parties. As it will be seen below, the specific issue of clarity raised by the
Opponent is complicated and could have the potential to affect the reasoning
with respect to the other remaining grounds of opposition.
Hence, I will
provide relatively detailed and comprehensive observations on clarity, and will
limit myself to much briefer observations
with respect to the rest of the
remaining grounds. In the present circumstances, given the outcome of the
opposition, I will not
provide any observations or comments on the potential
ground of utility as it is not in the Amended SGP, and I do not see the reason
to invoke s 60(3).
40(3) stipulates that “[t]he claim or claims
must be clear
succinct and supported by matter disclosed in the specification”
(underlining added).
respect to clarity, the Opponent contends:
“140. We repeat
paragraphs [91]-[99] and [121]-[135] above as to deficiencies within the
specification and claims
141. According to MAF’s expert Dr Walsh, the object of the invention
described in the claims is
image registration
, i.e., that the plurality
of images taken are captured in illumination periods at such speed that the
fruit has essentially not moved
which Dr Walsh states is the ‘crux’
of the Application[.] However this interpretation is at odds with how Dr McGlone
and Mr Berry interpreted the teaching of the Application / alleged invention[.]
142. Because of this uncertainty,
the skilled person will not know if
their actions fall within the scope of the claims
if they use a device
and/or method that utilises a single CMOS colour camera in a standard packline
environment,
but not for the purposes of image registration
143. It is therefore submitted
the claims are invalid for lack of
under s 40(3) of the Act.” (OS, underlining added,
reference(s) omitted).
note that paragraphs [91]-[99] of OS contain the Opponent’s analysis with
respect to support, whereas paragraphs [121]-[135]
of OS relate to clear enough
and complete enough disclosure. In addition, paragraph [91] of OS, refers to
“paragraphs [49]-[54]
above in respect to the construction of the
claims”, whereas paragraph [121] of OS states that “[t]he
construction and
scope of the claims are addressed above at [49] to [54] and
[92]-[93] of these submissions”. Having reviewed all of the above
paragraphs, I am unable to identify any further issues that the Opponent
believes result in any of the claims being unclear, other
than the uncertainty
of whether the image registration is a limitation of the claims or not, as
expressed in the above quoted paragraphs
[141]-[142] of OS.
Does claim 1 require image registration?
the related question (reproduced below) included in my post-hearing
correspondence, I noted that “[a]s I understand it, the
‘image registration’ requirement is the requirement that the
‘plurality of images in different imaging
wavelength ranges’ (as per
the wording of claim 1) are produced with the multispectral camera such that
each one of the images
of the plurality is of substantially the same
surface/face of the object”. The question of whether image registration
limitation of claim 1 is an important area of disagreement between the
parties. It was also discussed at some length by the experts,
and, as noted by
the Opponent above, Professor Walsh considered that “the crux of the
current application [is] that multiple
illuminations and image capture at
different wavelengths can occur
without significant movement of the
” (Walsh in [257], underlining added), which “allows for
the multiple images, acquired under illumination at different
wavelengths,
be superimposed, as they effectively represent the same portion of
” (Walsh in [258], underlining added). Remarkably, the Applicant
disagrees with their own expert, Professor Walsh, on this
point and submitted at
the hearing that the expert misunderstood the invention.
consider that, in answering the question of whether the image registration is a
limitation of claim 1, it is important to start
by carefully analysing the
wording of the claim itself. When I quoted claim 1 in full earlier in this
decision, I underlined and
labelled in square brackets three expressions. For
convenience, I will reproduce these expressions below:
external surface portion of at least one object, named
illuminated object”;
external surface portion of at least one illuminated
object corresponding to the whole visible face of the external surface of the
object on the optical axis of the multispectral camera”; and
external surface portion of at least one illuminated
of the above expressions refer to an entity of the same type, namely, external
surface portion of illuminated object; however,
while expressions E1 and E2 use
an indefinite article before the respective entities, expression E3 uses the
word “said”.
The use of an indefinite article in expressions E1 and
E2 makes it clear that these two expressions may well define two different
entities, i.e., two different external surface portions. Notably, the
expressions E1, E2, and E3 appear in the claim in the order
of their consecutive
numbering; hence, notionally, the external surface portion defined in either of
expressions E1 and E2 could
serve as an antecedent basis for “
external surface portion” of expression E3. It could potentially be
argued that expression E2 is to be preferred as an antecedent
basis, because it
appears in the claim after expression E1; however, I do not consider that this,
on its own, should be determinative,
as one also needs to pay attention to the
context in which the references to “external surface portion”
that regard, expression E1 refers to an external surface portion where the
“plurality of light sources ... are arranged to
be able each to apply
light radiation to”, whereas expression E2 refers to an external surface
portion where “said at
least one multispectral camera [is] being
orientated towards”. Importantly, “the exposure of said at least
one multispectral
camera [is] being controlled ... so as to produce, with this
same multispectral camera, a plurality of images ... of
surface portion of at least one illuminated object [E3]”. While I am of
the view that, on purposive construction,
there must be at least some degree of
overlap between what is illuminated and what is imaged, I consider that, in
comparison to the
object illumination, the camera’s orientation is much
more directly related to the actual imaging. Indeed, it is not unreasonable
expect that the entity that will be imaged, will be the entity towards which the
camera is being orientated. Therefore, I consider
that, to the extent there may
be differences between the external surface portions defined in expressions E1
and E2, the proper antecedent
basis for the external surface portion in
expression E3 is provided by expression E2. It is, perhaps, worth noting that
this outcome
is the same as the one that could be reached on the basis of the
order of expressions E1 and E2 in the claim as mentioned above.
this in mind, in my post-hearing correspondence, I included the following
question, which in essence relates to the implications
of the use of the word
“said” in expression E3 (original bold and underlining):
“As I understand it, the so called ‘image
registration’ requirement is the requirement that the ‘plurality
images in different imaging wavelength ranges’ (as per the wording of
claim 1) are produced with the multispectral camera
such that each one of the
images of the plurality is of substantially the same surface/face of the object.
In your submissions, is
this a feature/limitation of claim 1 and why? For
example, does the expression ‘
external surface portion of at
least one illuminated object’ [i.e., as in E3] (claim 1 at page 28, line
26, underlining added)
substantially the same
‘external surface portion of
at least one illuminated object corresponding to the whole visible face of the
external surface
of the object on the optical axis of the multispectral
camera’ [i.e., E2], towards which is ‘said at least one
multispectral
camera being orientated’
at the beginning of the
, in which is ‘the exposure of said at least one multispectral
camera being controlled in synchronism with said illumination
sequence so as to
produce, with this same multispectral camera, a plurality of images ...’;
potentially different
, for each image of the plurality
of images, ‘external surface portion of at least one illuminated object
corresponding to the
whole visible face of the external surface of the object on
the optical axis of the multispectral camera’ [i.e., E2] towards
‘said at least one multispectral camera being orientated’
time of capturing the respective image of the plurality
, this being a result
of the movement of the object?
Considering the wording of claim 1, it is perhaps worth noting that the claim
does not appear to explicitly differentiate between
the surface portions of the
object captured in the different images of the plurality, i.e., the
‘plurality of images in different
imaging wavelength ranges’,
produced ‘with this same multispectral camera’, are ‘of said
external surface
portion’. In other words, all images of the plurality are
‘of said external surface portion’. Hence, a possible
interpretation
in line with option (i) would not appear entirely unreasonable. The fact that
‘the objects [are] being moved
on a conveyor’ may, or may not, be
sufficient to render this interpretation incorrect.
In that regard, it may be worth noting that the claim does not appear to
explicitly define, for example, that a plurality of images
in different imaging
wavelength ranges are produced with the same multispectral camera, each image of
the plurality being of
external surface portion
at least one illuminated object corresponding to the whole visible face of the
external surface of the object on the optical
axis of the multispectral camera.
In this case, it might have been clearer that this external surface portion
could be either substantially
the same or different for each image of the
plurality. It appears to me that if wording to that effect were used in claim 1,
question might have not arisen, and perhaps Professor Walsh’s apparent
misunderstanding of the invention (according to the
Applicant’s
submissions) might have not occurred.
Given the present wording on [
] the claim, if one needs to look in
the body of the specification for clarification, what interpretation, in your
submissions, should
be given to the following explanation: ‘The invention
thus makes possible an optical analysis of the objects using multispectral
colour cameras sensitive to infrared in burst mode, making it possible to
produce series of successive images at very high speed.
Each series of images
produced by a multispectral camera in accordance with the invention corresponds
to one image produced by a
prior art camera. However, instead of necessitating a
plurality of cameras to produce these different images, the invention makes
possible to use only one or two multispectral cameras for each conveying
line’ (page 27, lines 12-18)?
Finally, when discussing the interpretation of claim 1, it might be worth
bearing in mind that claim construction is a question of
law, and expert
evidence (beyond the special meaning of any terms) is of little
assistance.”
answering this question, the Opponent points to the claim language and some
related parts of the description, and concludes:
submitted that either interpretations (i) or (ii) are reasonable interpretations
and both are open for you to adopt.
Not only are the claims ambiguous as to
which interpretation should be adopted, and
therefore the claims lack
, but the specification itself is also ambiguous and/or inconsistent
as to the correct interpretation.” (OPHS, underlining added)
contrast, the Applicant submits:
“The ‘image
registration’ requirement is
a limitation of claim 1 for the
reasons discussed at length both in the hearing and in the applicant’s
written submissions
in answer (see, e.g., paragraphs 37 to 42 of the written
submissions).
The expression ‘said external surface portion of at least one
illuminated object’ [i.e., as in E3] in claim 1 (page 28,
line 26) refers
to a potentially different portion of the illuminated object, meaning that the
plurality of images could show (slightly)
different portions of the object or
the same portion of the object.” (APHS on page 1, original underlining)
reviewed the submissions in paragraphs [37] to [42] of the Applicant’s
Summary, I do not consider that they are of much
assistance, because they do not
sufficiently engage with the claim wording as a whole. The Applicant simply
states that “[t]his
limitation is not present in the language of claim
1” (AS in [37]) and that the claim “contains no language or claim
integer requiring the images to be taken so quickly or closely together that
they are substantially the same or overlapping”
(AS in [41]). The
Applicant also refers to the claimed feature that the objects are “being
moved on a conveyor” and
submits that “there are several variables
that can influence the positional variations between successive images”
in [38]). The remaining submissions involve certain assertions as to what
the PSA would understand with respect to the manner in
may operate
” (AS in [37] and similar in [42], underlining
added) as well as several references to the description that apparently
that the Application also envisages the scenario where successive
images do not overlap” (AS in [40]). I did not find the
oral submissions
provided by the Applicant at the hearing to be materially different, perhaps
with the only additional submission
that the image registration construction of
Professor Walsh (being the perceived cause for the clarity issue) was incorrect.
I agree with the Applicant that the claim does not appear to explicitly define
the requirement for image registration, it also
seems to me that a less
convoluted claim wording might have been easier to interpret. In that respect,
I can also understand the
Opponent’s position.
Brief preliminary considerations
the following, I will use the phrase “
image frame
” to denote
the entire image that will be produced by the camera each time one of the
“plurality of images” is produced.
Each image frame will include
all entities (and only those entities) that were within the field of view
) of the camera when the image was captured, and it will also contain
the respective one of the “plurality of images in different
wavelength ranges of said external surface portion of at least one illuminated
addition, if an object is on the optical axis of the camera, there may be
several points of intersection between the external surface
of the object and
the optical axis of the camera. I will refer to the point of intersection that
is closest to the camera as the
”. Obviously, the
axis point will be unobstructed by other parts of the object, and will appear in
the centre of the image
frame, because the camera’s FOV is generally
symmetric with respect to the camera’s optical axis. It may be
theoretically
arguable that the centre of the image frame may not correspond to
the axis point (e.g., by placing a mirror on the optical path between
and the object); however, I do not consider that this is a reasonable
interpretation when the object itself is on the
optical axis of the camera, and
not, e.g., a mirror, in which a reflected image of the object is produced.
direct my attention to the wording of what I consider
to be the two most
relevant features (which I will refer to as the
”) that work together in combination to define the content of
the “plurality of images”. These two key features
expressions E2 and E3, and I have already decided that the proper antecedent
basis for expression E3 is provided by expression
E2. I will refer to the two
key features as the
orientation feature
imaging feature
imaging feature (reproduced below) uses expression E3, and defines the entity
(or entities) that will appear on the “plurality
of images”:
“to produce, with this same multispectral camera, a
plurality of images
in different imaging wavelength ranges of
external surface portion of at least one illuminated object
imaging feature refers to the orientation feature. The orientation feature
(reproduced below) uses expression E2, and defines
the orientation of the
multispectral camera:
“said at least one multispectral camera
being orientated towards an external surface
portion of at least one illuminated
corresponding
to the whole visible face of the external surface of the object on the optical
axis of the multispectral camera”.
The imaging feature
interpretation of the imaging feature itself appears relatively straightforward
– the “plurality of images”
will be of “
external surface portion of at least one illuminated object”, i.e., of the
external surface portion that is defined in the
orientation feature by the
expression “said at least one multispectral camera being orientated
an external surface portion of at least one illuminated
”. However, this use of antecedents has the potential to be
confusing, as it could
prima facie
lead to a conclusion that all images
of the “plurality of images” must necessarily be of one and the same
“external surface portion ...”. Indeed, this is the
interpretation adopted by Professor Walsh, with whom the Applicant
order to resolve the issue, one needs to analyse what exactly is defined by the
combination of the two key features, focussing
mostly on the orientation
feature, because this is the feature which defines the crucial entity of
“an external surface portion
of at least one illuminated object”.
The orientation feature
consider that the main problem with the wording of the orientation feature comes
from the fact that, in general, it could be said
that a camera will always be
orientated towards the entity that is on the optical axis of the camera. If an
object is on the optical
axis of a camera, then it is not unreasonable to argue
that any external surface portion, corresponding to the whole visible (as
discussed at item (e) below) face of the external surface of the object, will
also be on the optical axis of the camera. Hence,
it is also not unreasonable
to argue that the camera will always be orientated towards an external surface
portion of at least one
illuminated object, the external surface portion
corresponding to the whole visible face of the external surface of the object on
the optical axis of the camera. Therefore, one could conclude that the only
purpose of the expression “
being orientated towards
an external
surface portion of at least one illuminated object” is to serve as an
explicit antecedent basis, and not actually
to define the camera’s
orientation, which could add to the potential confusion caused by the use of
antecedents that I mentioned
addition, I consider the wording of the orientation feature somewhat convoluted,
and I find it difficult to extract all meaningful
limitations from this wording
as it stands. Therefore, despite the potential dangers associated with such
approach, I will attempt,
via the following initial analysis, to re-organise and
somewhat simplify this wording without affecting its meaning. In doing so,
brevity, I will omit the word “multispectral” from the wording of
the orientation feature while discussing the camera’s
orientation, as the
camera being multispectral is a separate limitation, unrelated to what the
camera is “being orientated
towards”. This initial analysis
includes the following considerations:
(a) It is clear that the “at least one illuminated
itself cannot reasonably correspond to “the whole visible
face of the
external surface
”. Therefore, it must be the
“an external surface portion” (of the “at least one
illuminated object”)
that is “corresponding to the whole visible
face of the external surface of the object on the optical axis of the ...
(b) In my view, it is also clear that “
on the optical
axis of the ... camera” is a single object. In addition to the plain
interpretation of “the object”,
having several objects on the
optical axis will result in objects overlapping, which will interfere with the
proper imaging of the
individual objects and will not make much sense on
purposive construction.
external surface portion of
at least one
illuminated object” to be “
corresponding to
the whole visible
face of the external surface of
the [single] object
on the optical axis
of the ... camera”, this “an external surface portion” must
belong to only one of the (possibly
several) “illuminated
object[s]”.
(d) Because the “an external surface portion of ... one illuminated
object” is “corresponding to the whole visible
face of the external
surface of the [single] object
on the optical axis of the ...
”, it follows that the two expressions “... one
illuminated object” and “the [single] object on the optical
the ... camera” must both refer to the same object that is both
illuminated and on the optical axis of the camera.
(e) The expression “corresponding to
the whole visible face
external surface of the [single] object on the optical axis of the ...
camera” defines a specific portion of that external
surface. It is clear
that the whole face (of the external surface) that is “visible”
depends on the point in space,
from which that external surface is (notionally)
“viewed”. I will refer to this point in space as the
point of view
)”. Depending on the location of
the POV relative to the external surface, different portions of that external
surface will
form the whole visible face, hence the determination of the POV is
vital for the proper identification of the defined specific portion
external surface. Given the clear general emphasis on imaging, and the fact
that, in the context of the claim, the orientation
feature is used to define the
orientation of the camera for the purpose of imaging, on a purposive
construction I consider that the
POV must be the point in space where the camera
(i.e., its lens) is located, as opposed to, e.g., the location of the eyes of a
observer, if present. In other words, the orientation feature must refer
to “the whole ... face of the external surface of
the [single] object on
the optical axis”, as this face is “visible” from the
camera’s location. Indeed,
for practical purposes, it makes sense to
define the “whole visible face” with respect to what is
from the camera’s location (for brevity, I will use
from the camera
”), thus, what could
potentially be visible on the image.
the above considerations at items (a) to (e), it follows that the orientation
feature could be re-written, without changing what
it defines, as:
“said at least one ... camera being orientated towards
external surface portion
of ... one illuminated object
corresponding
the whole visible [from the camera] face of the external surface of the
[same] object [which is] on the optical axis of the ... camera”.
final consideration is that:
(f) From a geometrical point of view, it is clear that if two external surface
portions of the same object both correspond to the
same “whole visible
[from the camera] face of the external surface” of that object, then these
two external surface portions
must be the same. While the orientation feature
defines one such “an external surface portion”, it is trivial that
the whole visible-from-the-camera portion of the external surface
object will also
to “the whole visible [from the camera]
face of the external surface of” the object. Therefore, the defined
external surface portion” must be the whole
visible-from-the-camera portion of the external surface of the object.
follows that the orientation feature can be re-written, and its wording
re-arranged, to reach the final form of the feature (omitting,
as I explained
earlier, the limitation that the camera is multispectral):
at least one camera being orientated towards the whole visible-from-the-camera
external surface portion of an illuminated object
on the optical axis of the
my initial analysis did not resolve the main problem with the orientation
feature that I noted above, I consider that the final
form of that feature
represents a convenient starting point for interpretation, as its wording
appears more straightforward and easier
to extract meaningful limitations from.
It is also important to note that, in my view, the initial analysis, while
simplifying the
wording in question, did not change its meaning in any material
way, hence the limitations defined by the wording remain the same.
of the limitations defined by the orientation feature are manifestly clear,
: There is an object on the optical axis of the camera; and
: The object on the optical axis of the camera is illuminated.
this point, it is helpful to recall that the object on the optical axis of the
camera is not stationary – the claim explicitly
defines “the objects
being moved on a conveyor”. This means that the camera’s
orientation is not defined with
respect to a stationary entity, but with respect
to a moving entity. I find this somewhat unusual, and it immediately raises the
prima facie
not-unreasonable question of whether the camera itself is
stationary or not. For example, the camera may be somehow moving and/or
changing orientation to follow the moving object at least within some reasonably
limited part of the object’s trajectory on
the conveyer. However, I note
that such movement (or changing the orientation) of the camera is clearly not
supported by the body
of the Specification. Hence, if it is indeed defined, the
claim will be deficient with respect to s 40(3).
now on, it is necessary to expand the analysis to the limitations defined by the
combination of the key features, because, as
I discussed earlier, part of the
wording of the orientation feature provides an explicit antecedent basis for
external surface portion of at least one illuminated
object” in the imaging feature.
The combination of the orientation feature and the imaging
combination of the orientation feature (in its final form) and the imaging
feature (slightly re-worded as per item (c) of my initial
analysis above)
at least one camera being orientated towards the whole visible-from-the-camera
external surface portion of an illuminated object
on the optical axis of the
to produce, with this same camera, a plurality of images in different
imaging wavelength ranges of said external surface portion of
the illuminated
To avoid confusion in my further discussions, any in-text quotations from the
above, which include wording that is different from
the original wording of the
key features, will appear in italic and without quotation marks.
the “plurality of images” will be “of said external surface
portion”, a clear limitation imposed by
the combination of the key
features is:
: The whole visible-from-the-camera external surface portion is within the
camera’s FOV so that, when imaged, its image will
be within the image
frames of the plurality of images.
is worth noting that, in essence, Limitation C is defined by the imaging
feature, the orientation feature simply providing the
explicit antecedent basis
external surface portion ...”, the image of which
must be within the image frames.
existence of the image registration requirement will depend on whether
whole visible-from-the-camera external surface portion of an illuminated object
on the optical axis of the camera
will necessarily be the same particular
portion of the external surface of the object or not; however, the answer to
this question
is not immediately apparent to me. For example, I can see a
reasonable argument that the orientation feature does not define a particular
portion of the external surface of the object, but instead defines the whole
external surface portion that is visible from the camera
while the object is on
the optical axis of the camera. Because the object is moving on the conveyor
(and may or may not be rotating)
it is not unreasonable to expect that, in time,
the whole external surface portion that is visible from the camera will
to different particular portions of the external surface of the
the other hand, I can also see a reasonable argument (somewhat alluded to
earlier) that, in the absence of any explicit definitions
to the contrary,
said external surface portion of the illuminated object
must refer to a
single external surface portion that was defined earlier, i.e.,
visible-from-the-camera external surface portion of an illuminated object
(or, in terms of the original wording, “an external surface portion of at
least one illuminated object corresponding to ...”).
Hence, all images of
the plurality will be of substantially the same particular external surface
portion. Because the object is
moving, the “plurality of images”
must be produced fast enough so that the movement of the object can be neglected
practical purposes.
the following, I will endeavour to identify any additional limitation(s) that
may be imposed by the combination of key features,
in an attempt to find what
will appear on the “plurality of images”, and in this way
potentially answer the question
of registration requirement. In particular, I
will attempt to decide what does it mean for the camera to be
towards the whole visible-from-the-camera external surface portion of
object that is subject to Limitations A and B, also bearing in mind that, as I
already noted, it could be argued that a camera
will always be oriented towards
the entity on the optical axis of the camera. I also need to take into account
that the whole visible-from-the-camera
external surface portion will be within
the camera’s FOV to satisfy Limitation C.
is no suggestion that, in the context of the Specification, the “camera
being orientated towards” should be given
any special meaning that is
established in the art and is different from the ordinary plain English meaning.
Macquarie Dictionary
(online edition, © Pan Macmillan Australia 2025)
defines the words “orientate” and “towards” as follows
(original bold and italic, underlining added):
orientating
to place so as to face the east, especially
to build (a church) with the chief altar to the east and the chief entrance to
to place in any definite position with reference to
points of the compass or
other points
Get out your map, orientate it
and examine it carefully for clues as to where you are
–PADDY PALLIN,
to adjust with relation to, or bring into due relation to,
surroundings, circumstances, facts, etc.: *
this would have been the first
weekend of the school holidays and would have given people a good opportunity to
orientate themselves
with the new rail network
–AAP NEWS, 2000.
to turn a map or plane table sheet so that the
north direction on the map is parallel to the north direction on the ground.
towards the east or
in specified direction
[backformation from ORIENTATION]”;
preposition
in the direction of
with reference
either motion or
to walk towards the north
with respect to; as regards:
one’s attitude towards a
proposition
nearly as late as; shortly before:
towards two
as a help or contribution to:
to give money towards a
use of the expression “said at least one ... camera being orientated
towards [a particular entity]” implies physical
orientation of the camera
in space, the orientation being unrelated to the points of the compass. Taking
this into account, I consider
that the most relevant, in the present context,
parts of the above dictionary definitions are those that I underlined at items 2
and 5 for “orientate”, and at item 1 for “towards”. I
also consider that the orientation in space is based
primarily on geometrical
relations, and, in that regard, item 2 requires orientation to be with reference
to a point or points.
This may imply a somewhat stricter definition with
respect to the precision of the orientation, and to that extent, it is not
unreasonable
to postulate that, in the strict sense of orientation in space, it
is the optical axis of the camera that determines the camera’s
orientation. Item 5 mentions turning “in specified direction”,
whereas item 1 defines “towards” as “in
the direction of (with
reference to ... position)”. While the “specified direction”
may be specified strictly
by reference to a point in space, it may also be
specified by reference to an object or entity that is extended in space.
could be said for “position”, which may, or may not, be a
point in space.
above discussion appears to suggest that the phrase “oriented
towards”, in the orientation feature, could involve
a strict orientation
with respect to a particular point of the external surface portion; however, it
could also define a more relaxed
orientation requirement with reference to the
external surface portion as a whole. Hence, the orientation feature’s
requirement
camera being orientated towards the whole
visible-from-the-camera external surface portion...
, could potentially be
somewhat uncertain.
could attempt to resolve such an uncertainty by looking at the functional
requirements that, on purposive construction, may determine
the correct
interpretation. In that respect, it could be argued that the only functional
reason for orientating a camera towards
an entity is to produce an image of at
least part of the entity. Thus, one could reach the following possible
interpretation:
Interpretation 1
camera being
orientated towards the whole visible-from-the-camera external surface
simply means that the camera is oriented such that at least part
the whole visible-from-the-camera external surface portion...
within the FOV of the camera.
Interpretation 1 imposes a limitation that is broader than, and entirely
encompassing within its scope, the combination
of Limitations A, B, and C.
Hence, according to Interpretation 1, the combination of key features imposes no
further limitations
than Limitations A, B, and C. Due to the existence of
Limitation C, not much will change even if one argues that the functional
for orientating a camera towards an entity is to produce an image of the whole
entity, not just an image of at least part
of the entity. I consider that the
following clear hypothetical wording of the key features is reflective of
Interpretation 1:
said at least one
camera having an illuminated object on its optical axis,
to produce, with this same camera, a plurality of images in different
imaging wavelength ranges of the whole visible-from-the-camera
external surface
portion of said illuminated object
note that the above hypothetical wording still does not resolve the question of
image registration requirement. In order to do
that, more words need to be
added, for example:
said at least one camera having an
illuminated object on its optical axis,
to produce, with this same camera, a plurality of images in different
imaging wavelength ranges of the whole external surface portion,
as visible from
the camera when each image of the plurality is produced, of said illuminated
said at least one camera having an illuminated object on its optical axis,
to produce, with this same camera, a plurality of images in different
imaging wavelength ranges of substantially the same whole
visible-from-the-camera
external surface portion of said illuminated object
is worth noting that, in the paragraph immediately above, the former
hypothetical wording does not prevent the “plurality
of images” from
being of substantially the same particular external surface portion, however the
claim would not be limited
to that (i.e., as insisted on by the Applicant). As
it can be seen, none of the above hypothetical wording examples needs the
“said at least one ... camera
being oriented towards
...” as presently defined in the orientation feature.
Importantly,
it could be said that there are further functional reasons for more precisely
orientating a camera towards an entity.
In fact, since the object is on the
optical axis of the camera, it could be argued that the closer the axis point to
centre point
” of the whole external surface portion when
viewed from the camera as a 2-dimensional shape, the better the image quality.
Clearly, in the example of a spherical object (see, e.g., Figures 4 and 5 as
well as the description on page 12, lines 10-12), the
whole external surface
portion when viewed from the camera as a 2-dimensional shape will be a disc, and
the centre point will be
the centre of the disc. For more complicated shapes,
the centre point could be defined more or less rigorously by the practical
result that if the axis point is at the centre point, then the camera’s
FOV, necessary to fit the whole external surface portion
within the image frame,
would be the smallest. Using smaller FOV will, in turn, result in smaller
amount of empty space in the image
frame, thus achieving better utilisation of
the available sensor’s resolution. Here, by empty space, I mean the space
occupied by the image of the whole external surface portion.
if the FOV is larger, it is well known that, in general, the optical resolution
of camera lenses is best in the middle of the
FOV, hence more details can be
seen in the centre of the image frame. In practice, deliberately placing an (or
the main) object
off centre is only done for aesthetic, and not technical,
reasons. With the above in mind, one arrives at another possible
interpretation:
Interpretation 2
camera being
orientated towards the whole visible-from-the-camera external surface
means that the camera is oriented such that the axis point
coincides with the centre point of the whole external surface portion
viewed from the camera as a 2-dimensional shape.
Interpretation 2 provides a further limitation in addition to Limitations A, B,
and C. However, it could be said that the
scope of the limitation provided by
Interpretation 2 is narrower than, and entirely within, the scope of Limitation
A, thus rendering
Limitation A, in essence, redundant. Furthermore, I find it
unusual to define a limitation and then, later in the claim, to define
limitation including within its scope the already defined limitation. I
consider that the following clear hypothetical
wording of the key features is
reflective of Interpretation 2:
at least one camera being orientated towards the centre point of the whole
external surface portion, when viewed from the camera
as a 2-dimensional shape,
of an illuminated object, such that said centre point is on the optical axis of
the camera,
to produce, with this same camera, a plurality of images in different
imaging wavelength ranges of said external surface portion of
the illuminated
or slightly simplified:
said at least one camera being orientated such that the centre point of
the whole external surface portion, when viewed from the camera
2-dimensional shape, of an illuminated object is on the optical axis of the
to produce, with this same camera, a plurality of images in different
imaging wavelength ranges of said external surface portion of
the illuminated
it can be seen, the above hypothetical wording examples do not include an
explicit limitation that the object is on the optical
axis of the camera (i.e.,
Limitation A).
I have provided a set of drawings schematically illustrating an exemplary
process, in which the “plurality of images”
could be produced
according to Interpretation 1. The three drawings represent three consecutive
(from left to right) moments in
time, which could potentially be the beginning,
the mid-point, and the end of the process. While nothing prevents this process
being completed during a shorter movement of the object, the set of
drawings illustrates the longest possible movement of the object,
still allow the object to be on the optical axis of the camera, as per
Limitation A. The dash-dotted line represents the
optical axis of the camera;
the black dot represents the axis point; and the arrow represents the direction
of movement of the object
on the conveyer.
simplicity, in my illustrative drawings, the optical axis of the camera is
perpendicular to the movement direction of the object,
and the example object is
spherical (see, e.g., Figures 4 and 5 as well as the description on page 12,
lines 10-12), both of which
may not necessarily be strictly the case in
practice. I have also illustrated (using dashed lines) the camera’s
FOV, which must be sufficiently large to produce images of
whole visible-from-the-camera external surface portion of an illuminated object
on the optical axis of the camera
. In addition, I have also made the FOV as
small as possible in view of the practical consideration (mentioned earlier)
camera’s FOV should not be larger than necessary, thus maximising
the resolution/detail of the “plurality of images”
by making them
fill as large as possible portion of the image frame. However, it should be
emphasised that this is not a claim limitation.
corresponding set of drawings, schematically illustrating an exemplary process
in which the “plurality of images”
could be produced according to
Interpretation 2, is reproduced below in the same way as this was done when
illustrating Interpretation
1 to allow direct comparison.
appears from the above discussion that neither of the possible Interpretations 1
and 2 is without its problems, which I consider
to be an inevitable consequence
of the unusual wording of the combination of key features. Considering the rest
of claim 1, I am
unable to identify any features that could clearly and
unambiguously indicate that a particular one of Interpretations 1 and 2 must
preferred. Nonetheless, it is perhaps helpful to recall that claim 1 defines:
“- wherein at least one multispectral camera is
with a buffer memory
images of said plurality of images of said external
surface portion produced by a single multispectral camera
recorded in real time in the buffer memory
of this multispectral
am not sure that the word “different” tells much about the content
of the images of the plurality in terms of the particular
external surface
portion(s) appearing on these images. Since the images are all in different
wavelength ranges, they are, strictly
speaking, different.
buffer memory in a camera is a relatively small volume memory with fast
read/write speeds, adapted for temporary storage of a series
of images one after
the other. The buffer memory is cleared by transferring its contents to
another, more permanent memory –
for example the memory of the computer
system 10 of Figures 4 and 5 – where the images will be analysed. With
respect to the
operation and the advantages of the buffer memory, the experts
the only advantage
see with the use of a buffer memory is when using the so-called
‘burst’ mode on cameras
. ‘Burst’ mode is where a
quick succession of images are taken in a very short space of time
advantage of this is that it can lead to improved resolution, for example in
reducing motion blur between those images
. However once the camera has
taken its images in burst mode,
it is still necessary to send them to the
computer, and that is much slower
and set by the method of communication.
It also isn’t possible
to keep operating in
‘burst’ mode continuously since it would lead to the buffer memory
becoming full
and/or overwriting images before they can be downloaded to the
computer for processing.” (McGlone-1, underlining and italic
“39. Cameras, including visible spectrum colour cameras, were also
known at the Relevant Date to make use of buffer memories
to assist with
high-speed imaging
. Typically these cameras might buffer only one frame or
image, before it is transferred to the computer and while a second image
being acquired. This means that a camera can take an image, move that image to
its buffer memory and immediately take the next
image. Alternatively, the buffer
memory may be used to store multiple images to allow for a ‘burst’
of images to be taken
and stored in the camera, or to deal with potential
sporadic processing delays in the host computer. In that case
memory stores a number of frames (or images) which allows the camera to take
images faster than the method of transfer
to the computer
41. The ‘StreamHoldCapacity’ of the cameras discussed in Exhibit
DB-2 (which is another way of describing an ‘image
buffer’ or buffer
memory) falls anywhere
between 6 to 99 frames
, with most falling around
20-50 frames
42. ... in machine vision applications the image should be transferred to the
computer for processing as quickly as possible, so it
does not make sense to
store a substantial number of images in the camera’s buffer memory for any
significant period of time.”
(Berry-1, underlining added)
buffer memory is useful in situations where
where images can be cleared from the buffer
for writing or processing of the images to catch up). In situations
there is no downtime, buffer memory is not going to help
because the buffer
will simply fill up.
464. ... Without a buffer,
the data transfer cannot keep up with the image
. For the invention, the multispectral images are captured and
stored in the buffer, then when a full set of images is captured, e.g.
images at different wavelengths,
the images can be transferred from the
buffer in the camera downtime
.” (Walsh, underlining and italic added)
“15. ... While the buffer memory allows the camera to acquire images at
a very high frame rate, the speed of the system as a
whole is still dictated in
part by the bandwidth of the connection between the camera and the computer
insofar that
the system still requires periods of time where
the camera is
not acquiring images
to transfer those images to the computer
(McGlone-2, underlining and italic added)
“11. In the same paragraph 88, Dr Walsh refers to the concept of
‘downtime’ which is
the window in which images can be cleared
from the buffer memory for further processing
. He says that the
buffer memory is useful in situations where there is
“downtime” where images can be cleared from the buffer
where there is no downtime, buffer memory is not going to help
because the buffer will simply fill up
. A packline
for the optical analysis of fruit and vegetables is a continuous operation but
the camera cannot actually operate (acquire)
continuously at the speeds
described in the Application.
It will need time to empty its buffer memory
even as the conveyor itself continues to move
. This was commonly known at
the Relevant Date.” (Berry-2, original italic, underlining added)
above evidence clearly demonstrates that the real time recording in a buffer
memory, as defined in claim 1, is beneficial, and
thus makes sense on purposive
construction,
there is a gap in the process of producing and
recording of the images, the gap being sufficient to empty the buffer memory.
it could be seen from my illustrations, in light of Interpretation 1, such a
gap is most likely to be achieved by the objects not
following very closely one
after another on the conveyer, or alternatively, if the process of producing the
“plurality of images”
is performed during a shorter movement of the
object than the maximum shown in the drawings. On the other hand,
Interpretation 2
provides for a naturally occurring gap even if the objects on
the conveyer are closely following and possibly (if not rotating) even
each other.
rest of the claims do not appear to include any features that could clearly and
unambiguously indicate that a particular one of
Interpretations 1 and 2 must be
preferred, or suggest whether the individual images of the plurality will be of
the same particular
external surface portion, or not. The same could probably
be said for the body of the Specification, which places a lot of emphasis
speed of producing the “plurality of images”, but does not appear to
be very clear about what exactly will appear
on the individual images of the
plurality. For example, as mentioned earlier in this decision, the description
explains that:
“The invention thus makes possible an optical
analysis of the objects using multispectral colour cameras sensitive to infrared
in burst mode, making it possible to produce series of successive images at very
high speed.
Each series of images produced by a multispectral camera in
accordance with the invention corresponds to one image produced by a prior
However, instead of necessitating a plurality of cameras to
produce these different images, the invention makes it possible to use
or two multispectral cameras for each conveying line
.” (page 27, lines
12-18, underlining and italic added)
response to my invitation (included in my question as quoted earlier in this
decision) for submissions on the interpretation of
the above text in the
description, the Applicant states:
“Regarding the
interpretation of lines 12–18 on page 27 of the specification, the
applicant makes two observations.
First, the sentence ‘[e]ach series of images produced by a
multispectral camera in accordance with the invention corresponds
to one image
produced by a prior art camera’ supports the applicant’s position
that the plurality of images of the invention
may be captured
sufficiently high a rate to show substantially the same portion of the
illuminated object. However, claim 1 is not limited to
that scenario
Second, while claim 1 allows for the presence of multiple cameras, claim 1
does require the plurality of images to be produced by
a single camera: in lines
24–25 of pages [
] 28 claim 1 says that plurality of images are
produced ‘with this
multispectral camera’, and in lines
5–7 on page 29 claim 1 says, ‘the different images of said plurality
... produced by a
multispectral camera’ (emphasis
added).” (APHS on page 1, original underlining, italic added)
completely agree with the last paragraph quoted immediately above. I also agree
with the Applicant that the underlined sentence
in the above quotation from the
description could be interpreted to mean that each image in the “series of
images” will
be of substantially the same particular external surface
portion of the object, as otherwise it would not be possible that “[e]ach
series of images
produced by a multispectral camera in accordance with
the invention
corresponds to one image
produced by a prior art
camera” (underlining added). However, the said underlined sentence is on
the last page of the description,
and it does seem to provide explanations
“in accordance with the invention”, i.e., not just in accordance
with a particular
embodiment or “scenario”. Hence, it could be
interpreted as being somewhat supportive of the image registration.
the other hand, it could be argued that there is an error in the underlined
sentence. Indeed, it may be doubtful whether a series
of images in different
wavelength ranges could correspond to a single image in a single wavelength
range. Based on the italicised
sentence (and also supported by the body of the
Specification as a whole), the quoted text from the description should be about
comparison between the prior art arrangement with several non-multispectral
cameras, and the present invention where it is possible
to use a single
multispectral camera. Hence, “one image produced by a prior art
camera” should read instead “one
image produced by
prior art camera
i.e., one image produced by each one of the several prior art cameras to make up
a set of images. In this case, the “series
of images produced by a
multispectral camera” will correspond to the set of images produced by the
“plurality of [prior
art] cameras”. In addition, the italicised
sentence talks about “different images” being presumably produced by
both the “plurality of [prior art] cameras” and the “only one
... multispectral [camera]”. While it is not
abundantly clear whether the
difference between the individual images is limited to the different wavelength
ranges noted earlier,
it appears somewhat unlikely that a plurality of different
cameras will produce a set of images of substantially the same particular
external surface portion due to the different POVs of the different cameras.
Whether this also translates to the “series of
images produced by a
multispectral camera” is, in my view, open to debate. Hence, the possible
support for the image registration
in the above-quoted text from the description
and, in my view, the rest of the body of the Specification, is uncertain, as is
support for either of Interpretations 1 or 2.
is also worth noting that, as mentioned earlier, from the point of view of
purposive construction, the functional reasons for the
orientation, and for the level of precision of this orientation, do not appear
to be determinative either. Interpretation
1 allows for more flexibility in the
imaging speed and the object movement speed, and even includes within its scope
the process
of producing the “plurality of images” as per
Interpretation 2. However, on the other hand, Interpretation 2 allows
maximising the resolution and the detail of the external surface portion as it
appears on the “plurality of images”.
While it could possibly be
argued that because Interpretation 1 includes within its scope Interpretation 2,
preference should be
given to Interpretation 1, in my opinion, this is not a
sufficient reason.
The image registration requirement – conclusion
will now discuss how the possible interpretations affect the question of the
image registration requirement.
line with Interpretation 1, if the object does not rotate, and the distance from
the camera to the object is considerably larger
than the camera’s FOV over
the conveyor (which does not appear unreasonable or unusual), then all images of
the “plurality
of images” of
the whole visible-from-the-camera
external surface portion
would be of substantially the same particular
portion of the external surface of the object. In such case, image registration
be achieved in so far it concerns producing “a plurality of images in
different imaging wavelength ranges” of substantially
the same particular
external surface portion of the object. If desired, the so produced images
could be further “superimposed,
as they effectively represent the same
portion of fruit” (Walsh in [258]). However, this may require additional
image processing
(e.g., suitable cropping of the image frames), due to the fact
that these images of substantially the same particular portion will
different locations in different image frames as the object moves on the
conveyor during the process of producing the “plurality
of images”.
line with Interpretation 2, whether image registration will be achieved depends
on the movement speed of
the whole visible-from-the-camera external surface
the object as represented by, e.g., the movement speed of
a surface point corresponding to the axis point at a particular point in
during the process of producing the “plurality of images”. As per
my example illustrative drawings, at the moment
when the surface point
corresponds to the axis point, the movement direction of the surface point is in
substance perpendicular to
the camera’s optical axis. The same could be
said for the movement direction of the object as represented by the
particular importance is the comparison between the speed of the surface point
and the speed of the object’s centre. For
example, if the object does not
rotate, the speed of the surface point will be equal to the speed of the
object’s centre; hence,
according to Interpretation 2, image registration
will certainly be achieved. If the object does rotate (as, e.g., defined in
6), then simple kinematics principles suggest that the speed of the
surface point will be an algebraic sum of two components –
the speed of
the object’s centre and the relative speed of the surface point with
respect to the object’s centre; the
latter speed depending on the rotation
frequency of the object and the distance between the surface point and the
centre. Theoretically, the rotation frequency could be
sufficiently high to cause the speed of the surface point to be much higher
the speed of the object’s centre, thus producing consecutive images of
different portions of the object’s external
surface with no image
registration over the whole images possible. However, such a scenario appears
unlikely from a practical point
of view, as I am unable to identify (either by
reference to the evidence or by logical reasoning) the need for such a high
frequency, in addition to this being perhaps more difficult to achieve.
summary, I consider that even if, strictly speaking, image registration may not
be an explicit requirement of claim 1, in line
with Interpretation 2 (and in
some cases, even in line with Interpretation 1), in practice, image registration
is likely to be achieved.
I already noted, I do not need to decide conclusively on clarity, as this will
not affect the outcome of my decision. Nonetheless,
it is perhaps evident from
the above discussions that I have some concerns about the clarity of the claims.
In any event, even if
claim 1 could somehow ultimately be given some meaning, I
am of the opinion that the claim could have been written in a much clearer
language, so that it could unambiguously reflect the Applicant’s
intentions as expressed in their submissions.
Novelty and inventive step
relevant parts of s 18 stipulate:
“(1) Subject to subsection
(2), an invention is a patentable invention for the purposes of a standard
patent if the invention,
so far as claimed in any claim:
(b) when compared with the prior art base as it existed before the priority
date of that claim:
(i) is novel; and
(ii) involves an inventive step; ...”
is worth noting that the Opponent’s case on novelty and inventive step is
contingent on certain conditions:
“156. In the alternative
156.1 The Application is deemed to
provide a clear and complete enough
description
to put the invention into effect across the full scope of the
claims, i.e., the information gaps in the Application can be filled
common general knowledge of the skilled person; and/or
156.2 MAF resiles from the evidence of Dr Walsh and submits that
scope does not require image registration
it is submitted the Application is invalid under s 59(b) of the Act for
lack of novelty
lack of inventive step
underlining added)
the following, I will provide some relatively brief observations on both novelty
and inventive step.
well-established test for novelty can be found in
Meyers Taylor Pty Ltd v
Vicarr Industries Ltd
[1977] HCA 19
Meyers Taylor
[1977] HCA 19
(1977) 137 CLR 228
“The basic test for anticipation
or want of novelty is the same as that for infringement and generally one can
properly ask
oneself whether the alleged anticipation would, if the patent were
valid, constitute an infringement...”
test requires that all essential features of the claimed invention are disclosed
in the prior art document. The level of disclosure
in the prior art document
was considered in
The General Tire & Rubber Company v The Firestone Tyre
and Rubber Company Limited and Others
[1972] RPC 457
at 485-486:
“If the prior inventor’s publication contains a clear
description of, or clear instructions to do or make, something that
infringe the patentee’s claim if carried out after the grant of the
patentee’s patent, the patentee’s claim
will have been shown to lack
the necessary novelty, that is to say, it will have been anticipated. The prior
inventor, however, and
the patentee may have approached the same device from
different starting points and may for this reason, or it may be for other
have so described their devices that it cannot be immediately discerned
from a reading of the language which they have respectively
used that they have
discovered in truth the same device; but
if carrying out the directions
contained in the prior inventor’s publication will
result in something being made or done which, if the patentee’s patent
were valid, would constitute an infringement of the
patentee’s claim, this
circumstance demonstrates that the patentee’s claim has in fact been
anticipated
If, on the other hand,
the prior publication contains a direction which is
capable of being carried out in a manner which would infringe the
claim, but would be
at least as likely
to be carried out
in a way which would not do so, the patentee’s claim will not have been
anticipated
, although it may fail on the ground of obviousness. To
anticipate the patentee’s claim the prior publication must
clear and unmistakeable directions
to do what the patentee claims to have
invented ...
A signpost, however clear, upon the road to the patentee’s
invention will not suffice
. The prior inventor must be clearly shown to have
planted his flag at the precise destination before the patentee.”
(underlining
and italic added)
Opponent raises a single document for novelty: “the Application is not
novel in respect to the disclosure of WO2016/018157A1
[159], original bold). The Opponent argues that:
McGlone in his evidence-in-chief states that D1 does not
‘explicitly’ disclose the multispectral camera
claimed by the
Application in claim 1. However it is also his view that
in putting the
invention into effect, the skilled person ‘would end up with a method that
is the same as that described’
by the Application
underlining added, reference(s) omitted)
am not sure that I would agree with the Opponent’s interpretation of Dr
McGlone’s evidence. In fact, Dr McGlone observes
“144.1 This feature is not explicitly disclosed, however
that if the skilled team was to put
[i.e., D1] into
it was quite likely
they would end up with a method that is the
same as that described here.
Even if that was not the case, the feature is
obvious when considering what was common general knowledge to the team at the
.” (McGlone-1, underlining and bold added)
Opponent continues:
“163.1 At page 13, lines 7 to 9 D1
discloses the use of multiple light sources, at a number of different
wavelengths including
‘ultra-violet, infra-red, red, green, blue,
etc’. Dr McGlone notes this is consistent with the common general
that it was useful to image in different wavelengths for sorting and
grading fruit and vegetables.
163.2 Immediately after this disclosure, page 13, lines 18 to 28 of D1
discloses an arrangement of four cameras used across four lanes,
‘each path uses a single camera.’ Page 9, line 21 states that the
cameras used should be ‘digital cameras’.
As Dr McGlone notes, the
skilled person relying on their common general knowledge would understand that
the invention
put into effect either with a mono
camera or ‘a colour camera with a CMOS sensor
’ both of which are
forms of digital cameras used for optical analysis for fruit at the Relevant
163.3 As Dr McGlone explains, ‘if the skilled team was putting the
system disclosed by [D1] into effect, they would therefore
require a camera that
is sensitive to both light radiation in the visible wavelength range and the
infrared range.’ Dr McGlone
expects that the skilled team
consider as a viable choice
‘colour cameras, with the IR filter
removed’ to implement the teaching of D1
. Mr Berry agrees that it
‘was readily understood by customers and suppliers prior to the Relevant
Date’ that ‘visible
spectrum cameras could operate in the NIR
163.4 Dr McGlone further observes that by the Relevant Date, ‘CMOS
sensors were the most common sensors used in digital cameras’
these sensors would use ‘a matrix of colour filters, or three CMOS sensors
with one for each primary colour.’
Similarly, Mr Berry states that CMOS
cameras with either a matrix of colour filters or three CMOS sensors, one for
each primary colour,
were the ‘commonly available colour CMOS
cameras’ at the Relevant Date. Dr Reis states ‘the CMOS sensor was
particularly
common because they use less power and can transmit data faster
than a CCD sensor.’ Dr Walsh states that ‘CMOS technology
available in the late 1990s and displaced CCD use because of advantages in their
163.5 While D1 does not explicitly state the use of a single colour CMOS
there is implicit disclosure of the claimed feature
the skilled person would select such cameras ‘
as a matter of course and
without the application of inventive ingenuity or undue
experimentation
.’” (OS, underlining and italic added,
reference(s) omitted)
McGlone’s conclusion with respect to the disclosure of document D1 is as
“144.7. Therefore, while Moynihan may not explicitly
disclose the use of a single colour camera as a multispectral camera,
likely outcome
of the team putting its teaching into effect. In addition,
it is obvious based on the common general knowledge
that a single colour
camera could, and would, be useful in the system set out in Moynihan.”
(McGlone-1, underlining added)
the basis of the above, in my opinion, it is uncertain whether the disclosure in
document D1 raises to the level necessary for
the finding of lack of novelty as
per the quoted case law.
importantly, regardless of the outcome of claim interpretation, claim 1 clearly
defines that the object is on the optical axis
of the camera. The Opponent does
not appear to discuss the potential disclosure of this feature at all, nor does
Dr McGlone. The
relevant parts of document D1 appear to be as follows:
“The sorting system 10 further comprises light sources 14
positioned where they can illuminate articles travelling along the conveying
. Since the conveying paths are the space through which the articles
travel, the light sources 14 can also be said to illuminate the
conveying paths.
The light sources are positioned generally above conveyors 11 and
a particular part of the conveying path
. The region of illumination from
each light source, or from a plurality of light sources,
may be any size,
although in some embodiments it is big enough to illuminate a single article
being conveyed by the conveyer. The light sources are collectively able to
illuminate all of the conveying paths.
The sorting system 10 further comprises cameras 15
positioned to image the
when conveyed along the conveying paths by the conveyors 11. The
cameras 15 are also positioned generally above the conveyor to image
articles conveyed by the article receivers / carriers 13.
Any type of camera
may be used
in preferred embodiments of the invention the
cameras are digital cameras
that operate by generating image data indicative
of incident light received. The positioning of cameras 15 is such that the
are imaged by the cameras at the position the articles are illuminated
by the light sources 14. That is,
the cameras 15 are generally targeted at
the regions of illumination created by the light sources 14
page 9, lines 1-25, underlining added)
my mind, the above does not seem to disclose clearly enough that the object (or
the article) must be on the optical axis of the
there is no suggestion that the features not disclosed in document D1 are
inessential features.
Inventive step
test for inventive step was developed in
Wellcome Foundation Ltd v VR
Laboratories (Aust) Pty Ltd
[1981] HCA 12
(1981) 148 CLR 262
Wellcome Foundation
“The test is whether the hypothetical addressee
the same problem
would have taken
as a matter of routine
steps might have led from the prior art to the invention, whether they be the
steps of the inventor or not.” (in [45],
underlining added)
considering the question of what constitutes “a matter of routine”,
Aktiebolaget Hassle v Alphapharm Pty Ltd
[2002] HCA 59
(2002) 212 CLR
(2002) 194 ALR 485
(2002) 77 ALJR 398
, it was stated in [53]:
“That way of approaching the matter has an affinity with the
reformulation of the ‘Cripps question’ by Graham J
Mathieson Chemical Corporation v Biorex Laboratories Ltd
. This Court had
been referred to
in the argument in
Wellcome Foundation
Graham J had posed the question:
the notional research group at the relevant date, in all
the circumstances, which include a knowledge of all the relevant prior art
of the facts of the nature and success of chlorpromazine,
directly be led as
a matter of course to try
substitution in the
“2” position in place of the -Cl atom in chlorpromazine or in any
other body which, apart from the
substitution, has the other
characteristics of the formula of claim 1,
in the expectation that it might
produce a useful alternative to or better drug than chlorpromazine or a
body useful for any other purpose?’ (emphasis added)
That approach should be accepted.” (original italic, reference(s)
Lockwood Security Products Pty Ltd v Doric Products Pty Ltd (No 2)
(2007) 235 ALR 202
, it was stated:
, this Court reiterated that ‘obvious’ means
‘very plain’, as stated by the English Court of Appeal in
Tire & Rubber Co v Firestone Tyre and Rubber Co Ltd
. The majority in
also confirmed that
the question of whether an invention is
obvious is a question of fact
, that is, it is what was once a ‘jury
question’. Broadly speaking, the question is not a question of what is
to a court. As well as being a question of fact, the question of
determining whether a patent involves an inventive step is also
degree and often it is by no means easy’, because ingenuity is relative,
depending as it does on relevant states
of common general knowledge ...
Further, as recognised in
Beecham Group Ltd’s (Amoxycillin)
Application
, as a basic premise, obviousness and inventiveness are
antitheses and the question is always ‘is the step taken over the prior
art an “obvious step” or “an inventive step”’?
An inventive step is often an issue ‘borne out by the evidence of the
. There is no distinction between obviousness and a lack of
inventive step. A ‘scintilla of invention’ remains sufficient
Australian law to support the validity of a patent.
Lockhart J stated that there must be ‘some difficulty overcome, some
barrier crossed’. This is consonant with older authorities
in the United
Kingdom which recognised that some inventiveness was required to distinguish
patentable advances over the prior art
from advances which ‘any
fool’ could devise. It also accords with the requirement in the United
States that for an invention
to be ‘non-obvious’ it must be
‘beyond the skill of the calling’.” (in [51]-[52], underlining
reference(s) omitted)
is clear from the above that inventive step, or obviousness, is a question of
fact, and this fact is “often” established
by “the evidence of
the experts”.
note that the Opponent refers to
Wellcome Foundation
“Cripps question” (OS in [172]-[173]); however, it does not appear
to me that these formulations of the test
are appropriately followed in the
Opponent’s arguments on inventive step. It seems that all expert evidence
with respect to
obviousness was given in hindsight after reviewing the
Application (McGlone-1 in [20]-[22], [78], and [134]; Berry-1 in [19]-[20]
[55]-[56]; Walsh in [8] and [231]-[232]). Such an approach can affect the
weight attributed to the evidence. For example, in
Meyers Taylor
J observed:
“36. I have set out these answers in full because
they seem to me to state in relation to the present patent very clearly
application of the well-known principle that subsequent analysis of the
invention – ‘the dissection of the invention’
often helpful in resolving the question of obviousness
. It has been
criticized as being a mistaken approach, see Blanco White, Patents for
Inventions, 4th ed. (1974), at par. 4-214. This
matter was also discussed by
Menzies J in Commonwealth Industrial Gases Ltd. v. M.W.A. Holdings Pty. Ltd.
[1970] HCA 38
(1970) 44 ALJR 385
, at pp 386-387 where he commented on the
undesirability of analysis by hindsight because
once one sees an invention it
may very often appear very simple
and one may then wonder why no one
previously had thought of so simple an improvement or device.
I would add
that frequently the answer to that question will be that the device involved an
inventive step, though of course that
is not necessarily or always so
Menzies J. quoted from Lord Russell in Non-Drip Measure Co. Ltd. v. Strangers
Ltd. as follows
(1943) 60 RPC 135
, at p 142:
‘Whether there has or has not been an inventive step in constructing a
device for giving effect to an idea which when given
effect to seems a simple
idea which ought to or might have occurred to anyone, is often a matter of
dispute. More especially is this
the case when many integers of the new device
are already known.
Nothing is easier than to say, after the event, that the
thing was obvious and involved no invention
. ...’” (underlining
Opponent asserts that the claimed invention is obvious in light of the CGK alone
(OS in [180]-[185]), and also in light of the
CGK together with document D1 (OS
in [186]-[189]).
Inventive step in light of the common general knowledge alone
Opponent submits that:
The starting point of this
is Dr Walsh’s conclusory statements at paragraphs [428]-[429]
and at [436]:
180.1 ‘As at March 2017
each of the individual components of the
invention of the opposed application already existed
180.2 ‘It was likewise known that CMOS cameras are sensitive out into
180.3 ‘What the inventors have achieve is putting these known
components together and using them in such a way as to achieve
a new outcome not
achieved by anyone’. Dr Walsh identifies this new outcome as being to use
LED illumination with a standard
multispectral CMOS camera to capture a
plurality of images, ‘each image being of the
external portion
of the fruit or vegetable. So, in effect, the movement of the fruit or
vegetables on the packline is rendered inconsequential.’
reference to the Image Registration Construction.
180.4 ‘... The invention is not about the hardware or the component
methods (for example, buffer memory in a camera, fruit rotation
on the conveyor,
use of a light cabinet, synchronicity of camera and LED illumination) but is
together in a way that had not previously
been done to achieve a new capability.’
181. The effect of this evidence is that, if Dr Walsh is incorrect as to the
Image Registration Construction, or if MAF resiles from
this evidence, then
it is clear that the invention as claimed is obvious in light of the common
general knowledge
. The claimed invention is nothing more than a combination
of ‘known components’ which achieves no different or surprising
result. It is trite law that an invention is not inventive where it amounts to a
mere collocation, i.e., of
separate parts that do not interact to make up a
183. It is therefore submitted, with reference back to
Aktiebolaget
the above evidence demonstrates that the skilled
person, in the circumstances, would as a matter of course have tried the
combination
of components in claims
and claim 7 in the
expectation that it would be successful. Claims 1 and 7 are therefore obvious in
light of the common general knowledge
alone.” (OS, original italic,
underlining added, reference(s) omitted)
am not sure that I would agree with the Opponent’s statement in the last
paragraph above. Firstly, the whole argument is
based entirely on evidence
provided in hindsight which could have low weight. Secondly, the
above-mentioned clear requirement that
the object must be on the optical axis of
the camera does not appear to be addressed. As such, the argument does not seem
very persuasive. In addition, to my mind, the Applicant’s counter
argument has some force:
“158. If this invention had been
obvious at the priority date,
then it would surely have been practised in the
art, noting that all of the components were available
. However, this was not
the case, because the invention required a complete redesign of the conventional
systems at the priority date.
Furthermore, when commencing with the agreed CGK
at the priority date, the PSA is directed to adding more cameras and/or filters,
so the solution becomes less likely (and not obvious) the more the CGK is relied
on.” (AS, underlining added)
Inventive step in light of the common general knowledge
together with document D1
the RTB Act, the PSA is no longer required to have ascertained the prior art
document. However, it is still necessary for the
PSA to appreciate the
relevance of the document to the problem being faced:
“Importantly, the changes are not intended to substantially
change the operation of the existing tests for inventive step as
applied to the
prior art base or to permit hindsight analysis. While a skilled person is
essentially deemed to be aware of and to
have carefully read the publicly
available information, the inventive step tests are otherwise applied in the
context of what the
skilled person would have known and done before the priority
date of the claims in question. The tests will therefore continue to
account of factors such as
whether the skilled person would have understood
and appreciated the relevance of the prior art to the problem the invention was
and whether it would be considered a worthy starting point
for further investigation or development.” (Explanatory Memorandum,
Intellectual Property Laws Amendment (Raising the Bar) Bill 2011
on page 43)
requirement does not appear to be addressed by the Opponent. Earlier in this
decision, when discussing the described invention,
I concluded that the
identified problems with the prior art systems appear to relate to the large
number of pieces of expensive equipment
(such as cameras and filters) operating
in a harsh environment as well as the time taken to transmit the images from
cameras to the
processing equipment (i.e., computing devices) and to process the
images. Before being shown the Application, Dr McGlone reviewed
document D1,
and his comments (in their entirety) are reproduced below:
“71. Much of Moynihan discloses concepts or components that
were already well known to the industry. It is only the measurement
system that carries anything new when considering the common general knowledge
of the Relevant Field. However, I understand
that the integration of this new
measurement system into a sorting mechanism is a necessary part of any
apparatus, so I understand
why information relating to the wider sorting device
has been included.
72. The main teaching of Moynihan is towards a
computer-implemented method
for synchronised control of light illumination and article imaging across
multiple conveyor lanes
, for the purpose of article sorting.
claims to address the problem of illumination interferences between lanes,
basically preventing cross-over interference
between lanes by time sequencing
the illumination and imaging of the individual lanes
. In a preferred
orchestration, it teaches that the method comprises the generation of a
synchronising pulse to synchronise the illumination
and imaging operations
across multiple lanes. It teaches that multiple light sources and/or of
different light types (colour ranges,
brightness, directionality), may be used
and that any pattern of sequential lane illumination and imaging is possible
with the method.
There is a teaching that simultaneous illumination and imaging
of two lanes is possible, if positioned far enough apart that interference
eliminated, and that may have advantages in achieving higher sorting rates.
73. The approach taught by Moynihan is interesting to consider since such an
approach in a practical sense
would allow someone in the field to build, for
example, an open space cabinet of lights and cameras, above multiple conveyors,
capture good quality images off each individual lane. The cleverness is then
in the synchronisation, which prevents cross-lane interferences,
associated fast switching to make handling of multiple conveyor lanes
. That requires good technical knowledge about light sources and
sensors, detail around how they behave under fast switching regimes
they can be controlled by computers. The alternative is to house each line in
its own imaging cabinet as I have described
above.” (McGlone-1,
underlining added)
McGlone’s evidence appears to suggest that document D1 is concerned with
addressing a problem that is quite different from
the problems addressed by the
instant invention. In the absence of convincing evidence to the contrary, I
find it somewhat unlikely
that “the skilled person would have understood
and appreciated the relevance of the prior art [document D1] to the problem
invention was seeking to solve and whether it would be considered a worthy
starting point for further investigation or development”.
Hence, I am not
sure that document D1 could be used for the purpose of inventive step analysis
in the way this was done by the Opponent,
and this is in addition to the already
noted clear requirement that the object must be on the optical axis of the
camera, which does
not appear to be addressed.
on the above observations, I have my doubts that the evidence on file is
sufficient to establish that the claims lack an inventive
step in light of the
CGK, whether alone or together with document D1.
Clear enough and complete enough disclosure
40(2) stipulates:
“A complete specification must:
(a) disclose the invention in a manner which is clear enough and complete
enough for the invention to be performed by a person skilled
in the relevant
Cytec Industries Inc. v Nalco Company
[2021] FCA 970
, Burley J noted with
apparent approval that:
CSR Building Products Ltd
v United States Gypsum Company
[2015] APO 72
, Dr S D Barker considered at
[95] that it involved the following three steps:
(1) Construe the claims to determine the scope of the invention as claimed;
(2) Construe the description to determine what it discloses to the person
skilled in the art; and
(3) Decide whether the specification provides an enabling disclosure of all
the things that fall within the scope of the claims.
144. In the present case, the delegate (at [54]) added to these the further
questions to be considered, citing
[2017] APO 57
(1) Is it plausible that the invention can be worked across the full scope of
the invention?
(2) Can the invention be performed across the full scope of the claims
without undue experimentation?”
Opponent provides a relatively detailed overview of the case law (OS in
[101]-[120]) and equally detailed submissions (OS in [121]-[137],
including a
large number of subparagraphs) covering many aspects of the invention. A
detailed consideration of all aspects concerned
is well beyond the scope of
providing brief observations; hence, I have limited my comments to a couple of
issues, which appear to
be representative of the Opponent’s approach. For
example, the Opponent submits:
“125. As a starting point, we
submit that
the invention the subject of claim 1 is not plausible
particular:
125.1 Claim 1
does not place an upper limit on the number of images taken,
or the speed of the illumination periods for the capture of these images
125.2 The Application discloses that a single camera can produce a
‘plurality of series of successive images of a single object’
is possible to produce ‘between 5 and 50 series of images of each object,
typically of the order of 10 series of images
of each object during
transportation thereof in front of each camera, each image corresponding to a
different portion of the external
surface of the object, this object being
125.3 The Application earlier states that a
‘series of images’ comprises ‘between two and ten – in
from three to five – successive images.’ As Mr Berry
this disclosure means that the Application teaches that a single
camera may take anywhere between 10 to 500 images of a single fruit
item before
the next piece of the fruit comes before the detector
125.4 The Application also teaches that the multispectral camera used in the
claim should be ‘
preferably a high-definition camera
, i.e., of more
than 1 million pixels. For example, very good results have been obtained with
cameras comprising a 1920 × 1200
pixel CMOS sensor.’
combined teaching
passages is that
the alleged invention should be capable of capturing up to
500 images of single fruit item at 1920×1200 resolution before the
item comes before the detector
This is within the broad scope of claim
.” (OS, underlining and italic added, reference(s) omitted)
I agree with the Opponent that “capturing up to 500 images of single fruit
item at 1920×1200 resolution ... is within
the broad scope of claim
1”, so is capturing of, say, 100000 images with resolution of
6000×4000 pixels. It does not
appear to me that this is a problem, because
the invention is not specifically about devising a way of producing extremely
amount of high resolution images of the object. Instead, I consider that
it is about a specific way of employing a colour CMOS camera
with a buffer
memory and without an infrared cut-off filter, which involves
colour sensor(s)
of this camera for capturing a set of images in
visible and infrared in relatively high speed by utilising the buffer memory.
It is clear that the invention uses commercially available
cameras with their
specified speeds and resolutions, as it was already agreed that designing
sensors and cameras is beyond the abilities
of the PSA.
addition, I do not believe that combining different teachings as done by the
Opponent is a fair reading of the body of the Specification.
Perhaps relatedly,
the Opponent notes that:
“125.8 The Application provides no
guidance to the PSA how the resolution of a camera might be reduced to allow for
faster operation
or what the limits of that would be (e.g.
how far resolution
can be reduced until the fidelity of imaging compromises optical image analysis
and processing/sorting of the object
being imaged
). This failure is
particularly important when the camera taught in the Application as preferable
is one with a sensor operating with
1 million pixels.
126. For the Application to be sufficient, it must be ‘plausible that
the invention can be worked over the full scope of the
claim’, and an
application must also provide ‘some reason for expecting that it will
work’. However Mr Berry, as
an optics expert, views the teaching of the
Application, and resultingly the scope of claim 1, as being implausible.
camera is required to take too many images at differing wavelengths in too short
127. Claims 1 and 7 are therefore insufficiently enabled.” (OS,
underlining added, reference(s) omitted)
I am not sure that such guidance on “how far resolution can be
reduced” could be provided as this would appear
to depend on the purpose
of imaging and the type of analysis performed on the images. In addition, there
is no convincing evidence
that determining the suitable resolution will not be
within the capabilities of the PSA. Secondly, while the body of the
Specification
emphasises the speed of image acquisition, neither the claims nor
the description provides any specific values for the speed of the
“being moved on a conveyor”. It could be argued that assuming the
typical speed used in the art as a basis of
calculations, as done by some
experts, may, or may not, be appropriate in this case.
also appears to me that the experts are answering questions that are not
commensurate with the level of disclosure required in
the Specification. In
particular, a patent specification is not expected to provide comprehensive
technical specifications of the
described system, including, e.g., the exact
parameters of all components of the system. For example:
“128.5 The Application
does not teach the use of higher
powered LEDs which Dr Walsh considers are essential
does it teach
any other way to provide sufficient illumination
imaging purposes
. Mr Berry comments that he could ‘potentially’
work out which LEDs to use, ‘but it would require significant design
effort and/or further trial and error.’ The lack of information about the
LEDs is one of the factors which caused Mr Berry
to conclude ‘all of this
would need to be worked out by the skilled person at considerable time and
expense.’ Dr McGlone
similarly observes that the lack of disclosure around
LEDs ‘surprises’ him ‘given their apparent importance’,
and that he considers it only likely that the skilled person could identify an
appropriate camera sensor to use ‘if the skilled
person also knew which
LEDs to use’.” (OS, underlining and italic added, reference(s)
Professor Walsh notes that “particularly high intensity LEDs would be
required for this invention given the very short
illumination periods”
(Walsh in [261]); however, he also states earlier in his evidence that
“[t]he individual LED elements
emit light at relatively modest
illumination levels, so it is common to assemble banks of LED elements into a
single lamp”
(Walsh in [137j]). A similar statement is made by Dr
McGlone: “[i]t was my understanding that the provision of ‘more
illumination light’ can be achieved by using more LEDs” (McGlone-2
in [22]). The invention is not about the LED illumination,
“particularly high intensity LEDs” may be preferred and beneficial
(e.g., for reducing the number of individual
LEDs), I am unable to identify any
evidence or reasons that would make me conclude that the invention could not be
implemented without
the use of such LEDs.
it is worth noting that I have serious doubts that the evidence on file is
sufficient to establish that the effort required
by the PSA to put the invention
into practice involves more than the usual amount of routine uninventive work,
necessary to design
any system of this type, including
selection of the appropriate commercially available camera(s), and the design of
the illumination in different wavelength ranges
on the basis of the
camera’s sensitivity and the characteristics of the commercially available
40(3) stipulates that “[t]he claim or claims must be clear and succinct
supported by matter disclosed in the specification
(underlining added).
Merck Sharp & Dohme Corporation v Wyeth LLC
[2020] FCA 1477
, Burley J observed that:
CSR Building Products Ltd v United States Gypsum Company
[2015] APO 72
Dr S D Barker adopted the summary provided by Aldous J in
at 252 – 253, which has been often followed in the United
Kingdom (emphasis added):
... to decide whether the claims are supported by the description
necessary to ascertain what is the invention which is specified in the claims
and then compare that with the invention which
has been described in the
specification. Thereafter the court’s task is to decide whether the
invention in the claims is supported
by the description
. I do not believe
that the mere mention in the specification of features appearing in the claim
will necessarily be a sufficient
support. The word ‘support’ means
more than that and
requires the description to be the base which can fairly
entitle the patentee to a monopoly of the width claimed
That approach encapsulates broadly the claim support obligation under
To it may be added the requirement that the technical
contribution to the art must be ascertained. Where it is a product, it is that
which must be supported in the sense that
the technical contribution to the
art disclosed by the specification must justify the breath of the monopoly
.” (underlining added)
The Opponent’s case on support
Opponent relies heavily on
Jusand Nominees Pty Ltd v Rattlejack Innovations
[2022] FCA 540
and the related Full Court decision
Nominees Pty Ltd v Rattlejack Innovations Pty Ltd
[2023] FCAFC 178
), and states that:
“89. The Full
Federal Court on appeal upheld the Federal Court’s judgment and held that
‘if this patent were upheld
it would confer upon the Applicant a monopoly
over a range of safety systems which it has simply not invented. This would
the patentee for something it had not done’.
90. For the reasons expanded upon below
we consider the present case to be
on all fours with [the case in]
. At best MAFs technical
contribution is one specific way to implement the claimed invention but it seeks
to claim all such ways in
claims which are so broad in scope they do not even
contain the limitations necessary to make its alleged invention work.”
(OS, underlining added, reference(s) omitted)
the section titled “Construe the claims to determine the scope of the
invention as claimed” (OS in [91]-[93]), the
Opponent concludes that
“the scope of claim 1 is extremely broad. It extends between two
extremes” (OS in [93]), the
extremes being as follows:
“93.1 An arrangement where:
(a) Many CMOS cameras which are somewhat sensitive in the visible and
infrared wavelength ranges;
(b) and having sensors with any resolution, including low definition sensors;
(c) each capture two images, one in the visible and one in the infrared
(d) and these two images are captured in an illumination sequence at a speed
of up to 1 second between exposures; and
(e) these two images are stored in real time in a buffer memory on the
93.2 An arrangement where:
(a) a single CMOS camera with high sensitivity in the visible and infrared
wavelength ranges;
(b) with a high-definition resolution sensor;
(c) captures a number of images across a number of wavelength ranges, for
example five images across the visible and infrared ranges;
(d) where the images are captured at a sufficiently high speed, i.e., around
0.1ms, so that the illuminated object has not essentially
(e) these images are stored in real time in a buffer memory of sufficient
size to store a number of high definition images taken in
a burst.” (OS)
in the section “Construe the description to determine the technical
contribution to the art” (OS in [94]-[96]),
the Opponent discusses (in
eight subparagraphs) the “evaluation or explanation of the alleged
inventive concept” (OS
in [94]) provided in the body of the Specification,
refers to Professor Walsh’s evidence supposedly given “[w]hen
considering
the contribution that the Application has made to the art” (OS
in [95]), and concludes:
“96. Dr Walsh’s evidence is
therefore that the technical contribution is narrow, i.e.,
how to use a
standard RGB-CMOS camera for the purposes of sequential imaging in multiple
wavelengths so that the fruit is essentially
in the same position across a
sequence of images in those wavelengths
, for example five images at
different wavelengths. To achieve this there must be a very rapid sequence of
illumination wavelengths
from ultrafast LEDs. Further the operation of the
camera should be optimised in the NIR (which is presumably a reference to the so
called ‘white balance’). Finally, the images should be captured and
stored on the buffer memory in real time for subsequent
transmission and
processing.” (OS, underlining added, reference(s) omitted)
the last section on support, titled “Decide whether the claims are
supported by the technical contribution to the art”
(OS in [97]-[100]),
the Opponent begins by stating that “[b]ased on Dr Walsh’s
assessment of the Application’s
technical contribution, it is clear the
claims are not supported by, and exceed, that technical contribution” (OS
The reasons for this, as advanced by the Opponent, could be
summarised as follows (underlining added):
does not include any reference to
the speed of acquisition of the images
captured by the camera” (OS in [97.2]);
also does not include any requirement as to
the permitted level of movement
of the object
” (OS in [97.3]);
McGlone correctly notes that claim 1 makes
no mention of a ‘burst
, ... does not require anything more than two images, and
not specify the five images
envisaged in Dr Walsh’s evidence”
(OS in [97.5], reference(s) omitted);
it is not a requirement of claim 1 that
the operation of the camera is
optimised in the NIR
(which is presumably a reference to the so called
‘white balance’)” (OS in [97.7]).
Opponent then states that “[t]he fact that that [
] the claims
extend beyond the technical contribution is also clear from the evidence in
chief of Dr McGlone and Mr Berry which
did not recognise image registration
as a feature or result of the method of claim 1
” (OS in [98],
underlining added). In support, in paragraph [98] and subparagraphs
[98.1]-[98.4] of OS, the Opponent refers
to some parts of McGlone-2 which
address the evidence of Professor Walsh in the matter.
I have no issues with the Opponent’s approach reflected by the three
section titles in the Opponent’s Summary as
reproduced above, I note that
the Opponent, in essence, seems to be relying entirely on Professor
Walsh’s views about the invention
as described and claimed. It appears to
me that, even if Professor Walsh’s understanding of the invention and its
is correct, the technical contribution to the art should not be limited
to the combination of all aspects of the invention which
form part of this
understanding, as some of these aspects, on proper characterisation, may
represent an additional contribution.
Earlier in this decision, when briefly
discussing the ground of clear enough and complete enough disclosure, I
expressed my opinion
that the invention is about
a specific way of employing
a colour CMOS camera with a buffer memory and without an infrared cut-off
filter, which involves using
the colour sensor(s) of this camera for capturing a
set of images in both visible and infrared at relatively high speed by utilising
the buffer memory
. In light of my discussion in the section “The
invention as described”, and my brief comments towards the end of the
section “Clarity”, without deciding the issue conclusively, I
believe that the above italicised text is a better characterisation
technical contribution to the art.
on all these considerations, it does not appear to me that the Opponent’s
case on support is particularly strong, regardless
of the possible claim
interpretations that I considered in the section “Clarity”.
Other support issues
in this decision, towards the end of the section “Claim
interpretation”, I discussed whether colour cameras with
separate infrared
sensors are within the scope of claim 1. Having considered the submissions of
both parties on the issue, I concluded
that some cameras of this type, i.e.,
those using colour CMOS sensor(s) as defined in claim 1 and having no infrared
cut-off filter,
are within the scope of the claim. I also provided an example,
namely the 2CMOS Bayer colour and near infrared camera FS-1600D-10GE,
manufactured by JAI Ltd.
could be argued that including colour cameras with additional dedicated infrared
sensors within the scope of the claimed invention
results in the claims being
unduly wide, such that “the technical contribution to the art disclosed by
the specification”
(as I identified it above) does not “justify the
breath of the monopoly claimed”. In other words, with reference to
paragraph [222] of
(quoted in paragraph [89] of OS), the claimed
invention “would confer upon the [Applicant] a monopoly over a range of
and devices for optically analysing objects belonging to the fruit and
vegetable group] which it has simply not invented. This would
[Applicant] for something it has not done ...”.
addition, in
Calix Limited v Grenof Pty Ltd
[2023] FCA 378
, Nicholas J
commented on support issues which arise from an inconsistency between the claims
and the body of the specification, rather
than the breath of the claims:
“128. Although discussion of s 40(3) is often focused on the
breath of the claim, there may be some claims which lack support
not because
they are too broad, but because they define an invention that is materially
different to what is described in the body
of the specification. Hence,
includes a feature not disclosed in the specification, or
omits a feature that is disclosed, may lack support because the invention
claimed is materially different from the invention disclosed
. Whether or not
the claim will lack support in such circumstances will depend on the proper
characterisation of the invention disclosed
in the body of the specification and
the invention claimed. See, for example, the invention described in the relevant
priority document
and the invention claimed in
AstraZeneca
at [254]-[255]
which were characterised by the Full Court of the Federal Court as
‘fundamentally different’ inventions.
It is difficult to see how a
claim to an invention that is fundamentally different from that which is
disclosed in the specification
could be ‘supported by matter
disclosed’ in accordance with s 40(3) of the Act.” (underlining
believe that by omitting the feature that
the colour sensor(s) in the camera
is/are used to produce the images in both visible and infrared wavelength
, the claims define a method and a device for “optically
analysing objects belonging to the fruit and vegetable group”
that may as
well use cameras having separate sensor(s) for visible and separate sensor(s)
for infrared. It could be argued that
such methods and devices are
“fundamentally different from that which is disclosed in the
specification”.
follows that, without deciding conclusively, I am of the opinion that the claims
are not supported by matter disclosed in the Specification,
although not
necessarily for the reasons put forward by the Opponent.
Conclusion and costs
have found that the Specification does not disclose the best method known to the
Applicant of performing the invention. I have
also found that this cannot be
overcome by an allowable amendment. Because of this finding, I concluded that
giving the Applicant
an opportunity to amend would serve no useful purpose, and
the Application should be refused.
I will refuse the Application.
these circumstances, I have not decided conclusively on any of the remaining
grounds of opposition, instead I have provided some
observations.
is a normal practice that costs should follow the event. I note the
Opponent’s submission that:
“192. If Compac is
successful in pursuing the opposition, it seeks costs. It is submitted that
in the event that Compac is successful
further submissions should be
sought from the Parties in respect to whether increased or indemnity costs are
appropriate
This is due to
without prejudice save as to costs
correspondence that Compac provided to MAF prior to initiating its opposition
refusal to pursue claim amendments following receipt of the
expert evidence in this proceeding.” (OS, underlining and italic
reference(s) omitted)
it is my opinion that the Applicant’s case was not without reasonable
prospects of success. In fact, I believe that
the Opponent’s success on
the ground of best method was relatively finely balanced. In addition, given
the evidence on file,
I do not consider that the Applicant’s
“refusal to pursue claim amendments following receipt of the expert
was unjustified or unreasonable. Therefore, I am not convinced
that requesting further submissions “in respect to whether
increased or
indemnity costs are appropriate” is necessary or appropriate.
points, such as the Applicant’s approach to the evidence of Professor
Walsh and the Opponent ultimately not relying on
part of the documents they
filed, were also briefly mentioned during the hearing. Having carefully
reviewed the history of this
opposition, I do not consider that either
party’s behaviour warrants variation of the award of costs.
summary, in this particular case, I can see no reasons to deviate from the
normal practice or from the amounts mentioned in Schedule
8. Since the
opposition is successful, I will award costs according to Schedule 8 against the
Dr V. Z. Kolev
Delegate of the Commissioner of
RTF format (58.8 MB)
Signed PDF/A format