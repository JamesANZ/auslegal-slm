URL: https://www.austlii.edu.au/cgi-bin/viewdoc/au/journals/UNSWLawJlStuS/2025/20.html
Scraped: 2025-11-17 15:46:42
================================================================================

Cases & Legislation
Journals & Scholarship
Communities
New Zealand
Specific Year
Crnogorac, Mia --- "Gatekeeping or Censorship: Has Australia's Response to Misinformation and Disinformation on Digital Platforms Undermined the Implied Freedom of Political Communication?" [2025] UNSWLawJlStuS 20; (2025) UNSWLJ Student Series No 25-20
GATEKEEPING OR CENSORSHIP: HAS AUSTRALIA’S RESPONSE
TO MISINFORMATION AND DISINFORMATION ON DIGITAL PLATFORMS UNDERMINED THE
FREEDOM OF POLITICAL COMMUNICATION?
MIA CRNOGORAC
This article critically examines whether Australia's response to
misinformation and disinformation on digital platforms has infringed
the Implied
Freedom of Political Communication (‘IFPC’). It explores the tension
between safeguarding democratic discourse
and regulating harmful content in the
digital age. Central to this analysis is the
Communications Legislation
Amendment (Combatting Misinformation and Disinformation) Bill 2024
, which, if
enacted, would confer broad regulatory powers to the Australian Communications
and Media Authority. While the Bill purports
to serve a legitimate purpose,
namely the protection of public discourse from misleading and false content,
this article argues that
aspects of the proposed framework could
disproportionately encroach constitutionally protected political communication.
The distinction
between necessary gatekeeping and impermissible censorship is at
the heart of this inquiry. Through a legal, comparative, and normative
the article contends that Australia's approach does risk undermining the IFPC
and acknowledges alternative models that
better preserve democratic freedoms
while addressing the harms of digital misinformation. However, it nonetheless
concludes that
Australia’s proposed legal framework is better understood
as a good-faith attempt at responsible gatekeeping, rather than as
state-sanctioned censorship.
I INTRODUCTION
George Orwell once observed, ‘if liberty means anything at all, it
means the right to tell people what they do not want to
This encapsulates the
essence of free speech in a democratic society; an ideal that thrives on open
discourse even when such discourse
is uncomfortable or unpopular. However, in
the contemporary digital landscape, the mass and rapid dissemination of
information, particularly
through social media platforms, has created new and
complex challenges. The rise of
misinformation
(false information shared
without intent to deceive) and
disinformation
(deliberately deceptive
content) has disrupted public trust, polarised political debate and in some
cases undermined democratic institutions
by impeding the electorate’s
ability to make informed decisions.
In Australia, these concerns have prompted legislative intervention attempts,
most notably in the form of the Communications Legislation
Amendment (Combatting
Misinformation and Disinformation) Bill 2024
Although the Bill
purports to safeguard the public and uphold the
integrity of the digital information
environment,
if enacted, it has
provoked debate over whether it would unduly infringe upon the IFPC, a
constitutionally protected right. This
article acknowledges the scope of
regulatory powers may be too expansive, particularly when less intrusive legal
or technological
alternatives may exist. However, the critique that the Bill
is a covert mechanism for silencing dissent or suppressing political
opposition is unpersuasive. Rather than an act of censorship,
as defined in Part
I of this article, the Bill is more appropriately understood as a form of
regulatory gatekeeping; a genuine effort
to promote the reliability of
information in response to growing public concern over the unchecked spread of
misleading content online.
To examine this contention, Part I distinguishes between censorship and
gatekeeping and outlines the scope of the IFPC. Part II situates
proliferation of misinformation and disinformation within the digital era,
providing context for the regulatory impetus behind
recent legislative
proposals. Part III critically examines the provisions of the Bill
particular emphasis on its purpose and proportionality, to assess whether any
infringement of the IFPC is justified by a valid
and legally permissible
objective. Part IV considers alternative legal and technological frameworks,
including comparative international
models that may provide more balanced and
proportionate mechanisms for addressing the harms associated with online
misinformation
and disinformation.
II DEFINITIONS AND CONTEXT
A The Implied Freedom of Political Communication
Australia has consistently demonstrated a reluctance to adopt an absolute or
express right to freedom of speech. The failure of the
1944 referendum, which
proposed a prohibition on laws abridging freedom of speech, indicates both a
recognition that the
Constitution
lacked such protection and a clear
rejection by the electorate of its formal
The persistent failure
of subsequent reform efforts, including proposals advocating for an explicit
guarantee of free expression,
reflects a deeply rooted constitutional tradition
and a prevailing consensus that an express right to freedom of speech is not
as fundamental in Australia to the same extent as in other liberal
democracies, such as the United
Instead of an express right, the High Court has recognised an IFPC, first
articulated in the landmark case
Nationwide News Pty Ltd v
The Court unanimously
invalidated a provision of the
Industrial Relations Act 1988
criminalised statements that could damage the reputation of the Australian
Industrial Relations Commission or its members,
irrespective of their truth or
A majority of the judges
held that the provision was not reasonably connected to any constitutional head
of power, nor was it compatible
with the requirements of representative
Importantly, the freedom
is not a personal right of individuals, but rather a limitation on legislative
and executive power that
operates to protect political discourse from
unjustified governmental
interference.
This distinction is
central to the present discussion, as the IFPC does not shield all forms of
communication from regulation but
rather restricts laws that disproportionately
burden the free flow of political communication.
This principle was further developed in
Australian Capital Television Pty
Ltd v Commonwealth [No 2]
which concerned legislation that banned paid political advertising on radio and
television during election periods, while still permitting
political coverage
through news, talkback radio, print media, and limited unpaid airtime. The High
Court held that, although the
law was enacted under valid legislative power, it
unjustifiably restricted political communication and was therefore
The Court affirmed that
laws which infringe the IFPC, regardless of their legislative competence, may be
struck down if they fail
to meet the standard of proportionality or
a legal framework
explored in
Thus, while Australia does not recognise a general right to freedom of
speech, the
Constitution
does protect political communication through
implication.
This protection
limits governmental power where regulation obstructs the ability of individuals
or groups to participate meaningfully
in political discourse. Within the context
of this article, such governmental interference, where politically motivated or
disproportionate,
may constitute
, a term which here denotes
state-sanctioned suppression of speech to serve political or ideological ends.
Where this is the intent,
a law will almost certainly contravene the IFPC and be
rendered invalid.
However, the challenge becomes more complex when the government’s
intention is not to suppress dissent but to uphold the integrity
discourse. This is exemplified in the proposed Bill
discussed in Part
III. The Bill seeks to combat harmful online content and promote the
dissemination of accurate
information,
gatekeeping.
B Gatekeeping or Censorship
In evaluating the constitutional validity and normative implications of legal
measures regulating speech in Australia, this article
adopts a critical
distinction between gatekeeping
gatekeeping may be both legally permissible and morally defensible, censorship,
in the context of the IFPC, suggests the intentional
suppression of political
expression and warrants greater scrutiny.
Gatekeeping refers to the structured moderation and filtration of information
to uphold standards of accuracy, relevance, and public
It is frequently invoked
as a necessary mechanism to mitigate the harms associated with disinformation,
hate speech, or otherwise
injurious content. Unlike censorship, which seeks to
silence particular views, gatekeeping operates to facilitate informed public
discourse by ensuring that verifiable and credible information is
prioritised.
For instance, a
government initiative that mandates social media platforms to label or demote
unverified COVID-19 content, rather
than remove it entirely, illustrates a
gatekeeping function that enhances transparency without suppressing
As Shoemaker explains,
gatekeeping involves the ‘process of selection by which the billions of
messages available in the world
each day are transformed into the merely
hundreds of messages that might then reach a given
Gatekeepers,
whether state actors, media entities, or digital platforms, thus exercise
considerable influence in shaping the content
and contours of public
In the Australian legal context, several statutory provisions that inhibit
speech operate as gatekeeping mechanisms. These include
counter-terrorism
provisions and anti-discrimination provisions such as
section 18C
Racial Discrimination Act 1975
While these laws restrict
expressive conduct, they are generally upheld as valid under the
Constitution
owing to the absence of an express right to freedom of speech in Australia. More
importantly, these provisions are typically directed
at protecting vulnerable
groups or national interests, rather than at suppressing dissenting political
viewpoints. As such, they
exemplify permissible gatekeeping rather than
impermissible censorship.
By contrast, censorship refers to the deliberate suppression, prohibition, or
penalisation of speech or expression by an authority,
often to silence dissent,
maintain political control, or reinforce dominant
ideologies.
This form of state
action carries with it coercive overtones and is frequently enacted through
takedown orders, prior restraints,
legal sanctions, or technological
restrictions. In China, for instance, censorship practices are notoriously
extensive and politically
motivated. King, Pan, and Roberts conducted an
empirical analysis of the Chinese censorship system, concluding that online
is primarily removed based on its ‘collective action
potential’, that is its capacity to incite real-world public dissent
goes against the Chinese government’s political
ideologies.
The dichotomy between gatekeeping and censorship thus informs the central
question of this article: whether Australia’s regulatory
response to
misinformation and disinformation, most notably through the Bill, constitutes a
legitimate instance of democratic gatekeeping
or whether it impermissibly
crosses into censorship.
III MISINFORMATION AND DISINFORMATION
This section defines the concepts of misinformation
disinformation and considers the ways in which their spread has been
exacerbated by the digital age. An understanding of the scale
and seriousness of
this issue is key in assessing whether Australia’s regulatory response is
proportionate to a legitimate
objective (see Part III).
A Definition
While the terms misinformation
disinformation are often
used interchangeably, they refer to distinct phenomena. This distinction is
recognised in both academic literature
and legal frameworks, including in the
misinformation
refers to ‘false or misleading information that is
disseminated without an intent to deceive, often due to ignorance or human
In contrast,
disinformation
is defined as the ‘deliberate spread of falsehoods
with the intent to mislead, manipulate public opinion, or obscure the truth
malicious or deceptive
The defining characteristic that distinguishes disinformation from
misinformation is intent
However, despite this conceptual difference,
both forms of false information can produce comparable harms. Jurisdictions such
as Australia
have recognised the need to address both, regardless of intent, due
to their shared potential to disrupt critical democratic processes
serious harm. For instance, one of the most significant risks posed by
misinformation and disinformation is their ability
to interfere with electoral
integrity. The presence of false information can hinder the public’s
ability to make informed voting
decisions. As John Mill once observed,
uninformed voters were likely to ‘disadvantage themselves and damage the
interest of a
B Proliferation Due to Technology
False and misleading information is not a novel concern, despite the
contemporary attention it receives. Although the term ‘fake
was labelled the ‘word of the decade’ in 2021, the practice of
spreading falsehoods for political advantage
For instance,
Octavian famously used disinformation to discredit Mark Antony in Ancient Rome.
What distinguishes the current era
is the transformative role of technology,
which has made it easier to disseminate false information globally while
simultaneously
making it more difficult to distinguish fact from fiction.
Misinformation and disinformation today can significantly undermine ‘human
rights, social cohesion, and democratic
processes’.
notes, technology is increasingly exploited, whether intentional or not, to
spread falsehoods at scale which ‘triggers
an information war’ where
‘all that is needed are computers, smartphones, and an army of trolls and
overwhelmingly agree that social media platforms have exacerbated the
misinformation crisis and support a multifaceted regulatory
approach, including
content moderation, algorithmic and platform design changes and stronger
regulatory oversight.
instance, in Australia, Meta applied warning labels to approximately 9.2 million
pieces of content on Facebook and over 510,000
Similarly, Google
removed more than 140,000 YouTube videos for violating its community guidelines,
including over 20,000 that were
specifically taken down for breaching policies
related to misinformation, spam, or
While it is often argued that drawing lines around permissible content risks
infringing on political expression, such concerns must
be balanced against the
reality that free judgment requires access to
information.
Individuals, especially youth, often do not realise they are consuming false
content and thus do not engage their critical
faculties to assess the
reliability of information.
Without factual content, political opinions risk becoming uninformed,
undermining the very premise of a functioning democracy. The
seriousness of the
issue is also underscored by examples such as foreign interference in elections
through targeted disinformation
campaigns and the deployment of inauthentic
Additionally, the
dominance of concentrated media ownership, particularly by outlets such as News
Corp, has been linked to the dissemination
of COVID-19 misinformation in
unveiling how both
foreign and domestic forces can exploit the modern information environment to
the public’s detriment.
IV AUSTRALIA’S LEGAL RESPONSE
In recent years, Australia has made several attempts to address the growing
threat posed by misinformation and disinformation. Historically,
the Australian
Communications and Media Authority (‘ACMA’) played a supervisory
role under the voluntary industry Code
Its responsibilities
included monitoring and reporting on the adequacy of digital platforms' efforts
to combat the spread of false
or misleading content. The ACMA’s function
remained largely advisory and observational, more akin to a watchdog than a
with enforcement
However, in light of the escalating threat posed by misinformation,
particularly during the COVID-19 pandemic, the government has
implement stronger regulatory measures, exemplified by the introduction of the
Despite this initiative, the Bill
has faced significant
resistance in the Senate, and it is unlikely to pass in its current
particularly given the
availability of alternative approaches that may impose a lesser burden on the
implied freedom of political
communication (see Part IV). Nonetheless,
Australia’s response reflects a genuine attempt at gatekeeping rather than
censorship.
This section evaluates both the strengths and the potential
shortcomings of the Bill
by applying the constitutional framework used by
the High Court to assess legislation that burdens the IFPC. According to
established
precedent, such a law may be valid if it pursues a legitimate
objective and the measures it imposes are proportionate to achieving
A Legitimate Objective
The IFPC is a fundamental constitutional protection, but it is not absolute.
As the High Court has recognised, laws may impede this
freedom if they pursue a
legitimate purpose.
context of the Bill
the objective is to mitigate the harmful effects of
misinformation and disinformation, which pose significant risks to public
electoral integrity, and economic
These concerns are
substantiated by empirical evidence, as explored in Part II, which demonstrates
how false information can distort
public discourse and undermine democratic
processes. The Bill explicitly states its purpose as enabling users to
‘better understand
the accuracy and credibility of content’ and
empowering the ACMA to act ‘in a manner that respects the freedom of
expression’.
‘social costs’ associated with false information are too significant
to justify the absence of regulatory
intervention.
This framing
suggests a genuine intention to function as a safeguard rather than a tool of
suppression. After all, the Bill reflects
recommendations from past inquiries
calling for a stronger regulatory framework, or an ACMA ‘with
Thus, while the
Bill may burden political communication in effect, its purpose appears to be
legitimate in the constitutional sense.
B ACMA’s Authority to Determine Misinformation and
Disinformation
One of the core concerns raised by legal scholars and human rights advocates
relates to the definitional scope of the Bill
As Jenner points out, the
Bill may function clearly in cases such as crypto scams or health hoaxes, but
its application becomes problematic
in ‘grey’ areas, such as
comments regarding lockdowns or vaccine mandates, which may straddle political,
medical, and
categories.
In such instances,
the line between misinformation and legitimate political expression becomes
This ambiguity raises the risk of regulatory overreach, where it is argued
vague definitions could be weaponised by governments to
purports to empower the ACMA to issue public notices, shame, and issue civil
penalties to platforms deemed non-compliant, which could
be used to promote
political agendas under the guise of regulating
falsehoods.
infringement on IFPC is likely to manifest in more complex and incidental ways.
For instance, consider a scenario in which
a social media post contains
demonstrably false information regarding a public health issue but also includes
elements of political
commentary. In seeking to remove the health-related
misinformation, the government may inadvertently restrict the political
embedded in the post. This would not amount to censorship, as defined
in Part I, given the absence of an intention to suppress dissenting
views. Rather, such action reflects a genuine gatekeeping effort aimed at
safeguarding the accuracy of public discourse
and protecting public
Even if, in extreme circumstances, there was a deliberate suppression of
political viewpoints, the Bill itself does not permit such
conduct. Under its
provisions, the ACMA is required by virtue of the directive language 'must', to
consider a range of prescribed
factors when assessing whether regulatory action
is ‘reasonable’.
Section 12(3) of the Bill mandates that the ACMA must have regard to, among
other things: ‘(a) the context in which the content
is disseminated; (b)
the subject matter of the information that is reasonably verifiable as false,
misleading, or deceptive; and
(c) the potential speed and breadth of its
dissemination’.
mandatory considerations constrain the ACMA’s discretion and prevent
arbitrary or ideologically motivated decision-making.
C Proportionality
According to legal precedent, the existence of a legitimate purpose is not in
itself sufficient to validate legislation that burdens
the IFPC. Rather,
proportionality remains a necessary criterion for constitutional
Applying this legal
test may explain the considerable scrutiny the Bill has faced and its difficulty
in progressing through the legislative
process. The core issue becomes whether
the powers the government seeks to confer upon the ACMA are proportionate to the
goal of combating the spread of misinformation and disinformation on
digital platforms.
The Bill proposes that the ACMA be granted a ‘graduated set of
misinformation and disinformation on specific categories of ‘digital
communication’ platforms.
These include connective media services, media sharing services, content
aggregation services, and internet search engine
This targeted approach
underscores that the Bill is not intended to apply broadly to all parties, but
rather to those digital platforms
most susceptible to the spread of false or
misleading information.
The ACMA’s role, as outlined in the Bill’s schedule, is primarily
regulatory and advisory. Specifically, it may develop
digital platform rules
requiring providers to retain records, report on matters relating to
misinformation and disinformation, and
supply relevant information or documents
upon request.
These functions
reflect a monitoring and reporting role, rather than a direct enforcement
mechanism. However, where digital platforms
fail to comply after multiple
requests, the Bill
authorises the ACMA to impose civil
These penalties are
capped at 5,000 penalty units for bodies
Importantly, the
regulatory framework provides ample opportunity for digital platforms to
cooperate before such penalties are imposed.
Further, platforms retain the right
to challenge any penalty through judicial review, thereby preserving the role of
the judiciary
as a critical check on executive power and reinforcing the
constitutional principle of separation of powers. Within this context,
penalties function as both a deterrent and an incentive, encouraging platform
providers to participate in efforts to curb misinformation
and promote the
dissemination of accurate information to the
In the absence of such
mechanisms, reliance on voluntary compliance alone would likely prove inadequate
to address the scale and
complexity of the problem. Accordingly, arguments that
the imposition of civil penalties renders the scheme disproportionate, such
those advanced by Jenner,
ultimately unconvincing.
It is also important to recognise how the current iteration of the Bill
represents a more measured approach than previous versions.
Notably, earlier
drafts proposed significantly harsher sanctions, including a fine of up to 5% of
a media company’s global
revenue for
non-compliance.
Such punitive
measures would likely be considered disproportionate to the legitimate end
pursued, and legally unsound for lacking
proportional balance. This concern
finds support in
High Court invalidated a provision of the
Industrial Relations Act 1988
(Cth) that criminalised statements potentially damaging to the reputation of
the Australian Industrial Relations Commission, even
if truthful or
In contrast, the present
by abandoning the 5% revenue fine and favouring civil over criminal
penalties, demonstrates a more proportionate approach to regulating
misinformation, thus far.
V COMPARATIVE ANALYSIS
Continuing the analysis from the previous section, the principle of
proportionality also requires an assessment of
, namely whether
there are ‘other, equally effective, means of achieving the purpose which
has a less restrictive effect of
As previously
noted, striking the right balance between safeguarding IFPC and regulating the
spread of misinformation and disinformation
is inherently complex. While
Australia’s primary response has been the introduction of the Bill, this
section considers whether
more effective or less intrusive alternatives exist.
A Legal Alternatives
Across jurisdictions, states have adopted diverse legal strategies to
regulate the spread of information online. In some cases, these
reflect a more authoritarian model, exemplifying the concept of censorship as
defined in Part I. For instance, in several
African nations, governments have
consolidated control over traditional media to purposefully control political
discourse and silence
These regimes frequently
manipulate the flow of information by promoting government-sanctioned narratives
and withholding content
that may expose incompetence and
corruption.
In contrast to censorship-based models, a gatekeeping approach refers to the
structured management and moderation of information to
uphold standards of
accuracy, relevance, and reliability. A prominent example of this model is
Singapore’s
Protection from Online Falsehoods and Manipulation Act
prohibits the deliberate
communication of false statements of fact, particularly when such communication
is likely to cause harm,
including public panic, damage to public health or
safety, or harm to international
Notably, the Act also
prohibits the creation or dissemination of tools (such as bots) or services
(such as troll networks) that facilitate
the spread of
misinformation.
distinguishes
from many legislative counterparts is its suite of
regulatory measures known as ‘Directions’, particularly the
Directions and Targeted Correction Directions. These require
individuals or digital platforms to publish corrections alongside content
false by the relevant
authorities.
Importantly, the
original content is not necessarily removed but rather it is accompanied by an
official correction or rebuttal.
This mechanism has been framed by
Singapore’s Minister for Law as one that does not infringe upon freedom of
expression but
rather enhances it by allowing readers access to multiple
viewpoints and the opportunity to assess competing narratives for
themselves.
When the COVID-19
pandemic reached Singapore in early 2020,
emerged as a critical
mechanism in countering the spread of online misinformation that had the
potential to incite ‘public
panic, hysteria, or social
Acting through
office, the Minister for Health issued directives targeting
several false claims circulating online, including assertions that the
government was concealing the true number of COVID-19
Other jurisdictions have adopted different but similarly targeted approaches
to regulating misinformation and disinformation. France
passed a Law on the
Manipulation of Information
in 2018, aimed primarily at addressing
disinformation during election
It allows judges to
order the immediate removal of demonstrably false content during the three
months leading up to an election,
provided the misinformation is likely to alter
the integrity of the vote.
also requires online platforms to disclose funding for sponsored content and to
increase transparency regarding algorithms used
to curate content.
Moreover, another notable concern is the Bill’s explicit exemption of
content produced by professional news organisations. As
Jenner denotes, this
exclusion is ‘curious’ given that news organisations, by virtue of
their perceived legitimacy and
adherence to professional standards, wield
significant influence.
Accordingly, any dissemination of false or misleading information by these
entities can be particularly harmful, given the public's
tendency to trust their
reporting. It could therefore be argued that such organisations should be held
to a higher, not lower, standard
accountability.
Australia may
benefit from considering international examples where professional news outlets
are subject to regulatory oversight
in the context of misinformation. For
instance, Singapore’s
applies broadly to all individuals and
entities, including private citizens, social media users, digital platforms, and
notably, professional
organisations.
This stands in
contrast to Australia’s proposed Bill, which, if enacted in its current
form, would regulate only digital platforms
such as Meta and Google, while
excluding both individuals and news organisations.
However, while
reflects a robust model of gatekeeping by
allowing for governmental correction directions and content flagging, it has
drawn criticism
for its severity for non-compliance which may attract criminal
Conversely,
Australia’s approach does not involve criminal sanctions, signalling a
more measured, though arguably less comprehensive,
form of gatekeeping.
Ultimately, there is no definitive solution to the complex task of balancing the
imperative to combat misinformation
and disinformation with the need to
safeguard freedom of expression. Striking this balance remains a nuanced and
context-dependent
challenge. However, as demonstrated by regulatory approaches
in other jurisdictions such as Singapore, more proportionate responses
available, that is, responses that achieve the legitimate objective and do not
burden IFPC as much.
B Technological Alternatives
In assessing the necessity of extensive legal regulation in the Australian
context, it is important to consider whether technological
interventions may
provide a sufficiently robust alternative to legislative measures in addressing
the proliferation of misinformation
and disinformation. There is significant
support for various technological interventions such as platform design
modifications, algorithmic
adjustments, content moderation, de-platforming of
repeat offenders, and crowdsourcing misinformation detection and
Among these, platform
design changes received the highest level of expert approval (89%), followed by
algorithmic changes (84%) and
content moderation practices
These interventions, if
systematically and consistently applied, offer promising alternatives to blanket
legal regulation.
The potential efficacy of such platform-based regulation is illustrated by
actions already taken in practice. A pertinent example
occurred in July 2021
when YouTube suspended Sky News Australia’s channel for breaching its
content policies.
While YouTube
did not identify the specific content in violation, it clarified that content
denying the existence of COVID-19 or
promoting unproven treatments such as
hydroxychloroquine or ivermectin would not be tolerated. With a subscriber base
of 1.8 million,
the suspension prevented Sky News from uploading or streaming
content for a period of seven days, thereby limiting the reach of potentially
harmful misinformation.
However, there are notable limitations to relying on digital platforms to act
in the public interest. While many social media companies
purport to uphold a
‘digital duty of care,’ there is little assurance that this duty
will be consistently honoured, particularly
when commercial or ideological
pressures intervene.
recently exemplified by Meta’s announcement that it would discontinue the
use of independent fact-checkers across
Facebook, Instagram, and
This move followed the
outcome of recent United States elections and was framed by company leadership
as part of a broader cultural
shift toward the prioritisation of free
Given this hesitancy and the inherent risks associated with relying solely on
platform cooperation, there is a need to consider additional
alternatives that
complement or even substitute legal regulation. One such alternative is the
implementation of preventative strategies
aimed at enhancing public resilience
to misinformation by way of public education and digital literacy initiatives.
Improving individuals’
capacity to critically evaluate content is an
indispensable tool for minimising the harm caused by disinformation. Singapore
a useful model in this respect, having integrated media literacy
education into its national approach alongside legal measures such
Australia may
similarly benefit from a dual-pronged strategy that balances legislative
enforcement with broader educational reform
to ensure a more informed and
discerning public.
VI CONCLUSION
Australia’s proposed regulatory framework addressing misinformation and
disinformation has drawn considerable criticism, primarily
due to concerns
regarding its potential infringement of the IPFC. The Bill’s failure to
secure Senate approval underscores
the gravity of these concerns. This article
has assessed the validity of such critiques, ultimately concluding that the
definitions employed by the ACMA may capture legitimate political
discourse, thereby posing a threat to the IFPC. Applying the established
tests of legitimate purpose and proportionality, this article finds that,
although the Bill
pursues a lawful objective- protecting the integrity of
public discourse- it risks doing so in a manner that lacks proportionality.
While the ACMA’s authority is circumscribed by standards of reasonableness
and the Bill
imposes civil rather than criminal penalties, Australia has
yet to consider less restrictive alternatives. Comparative evaluation
, indicates that
alternative models may achieve a more appropriate balance. Moreover,
non-legislative, technological measures could
reduce dependency on statutory
intervention, though their success hinges significantly on digital platforms
fulfilling their ‘digital
duty of care’, a responsibility many have
increasingly neglected. Ultimately, although the proposed Bill and associated
may endanger the IFPC, such risks should not be construed as an
intention to silence dissent or restrict political speech. Rather,
Australia’s initiative should be interpreted as a prudent attempt to
address the complexities of a deteriorating online information
landscape and the
regulatory gap left by digital intermediaries. Though flawed, the response thus
far reflects a protective rather
than censorial approach aimed at preserving
democratic integrity and ensuring the public remains reliably informed.
George Orwell,
The Freedom
of the Press
(Times Literary Supplement
Communications Legislation
Amendment (Combatting Misinformation and Disinformation) Bill 2024
Communications Legislation
Amendment (Combatting Misinformation and Disinformation) Bill 2024
(Cth) cl 11
(‘Communications Legislation Amendment Bill’).
Peter Creighton, ‘The
Implied Guarantee of Free Political Communication’ (1993) 23(1)
Australian Law Review
Nationwide News Pty Ltd v
[1992] HCA 46
(1992) 177 CLR 1
Australian Capital
Television Pty Ltd v Commonwealth
(1992) 177 CLR 106.
Ibid [6] (Brennan J).
Communications Legislation
Amendment Bill (n 3) cl 1.
Kalev Leetaru,
‘Gatekeeping is Not the Same as Censorship’,
22 August 2019)
<https://www.forbes.com/sites/kalevleetaru/2019/08/22/gatekeeping-is-not-the-same-as-censorship/>.
Olli Seuri,
‘Gatekeeping in the Digital Age’,
(online, 25 November
<https://www.sitra.fi/en/publications/gatekeeping-in-the-digital-age/>.
Leetaru (n 15).
Gary King, Jennifer Pan and
Margaret Roberts, ‘How Censorship in China Allows Government Criticism but
Silences Collective
Expression’
(2013) 107(2)
American Political
Science Review
Communications Legislation
Amendment Bill (n 3) cl 2.
Australian Electoral
Commission, ‘Disinformation and Misinformation’,
Integrity Assurance Taskforce
<https://www.aec.gov.au/About_AEC/files/eiat/eiat-disinformation-factsheet.pdf>.
Paul Kildea and Rodney
Smith, ‘The Challenge of Informed Voting at Constitutional
Referendums’
[2016] UNSWLawJl 14
(2016) 39(1)
University of New South Wales Law Journal
Lorraine Finely, ‘Why
Misinformation Bill Risks Freedoms It Aims to Protect’,
Human Rights Commission
(online, 24 August 2023)
<https://humanrights.gov.au/about/news/opinions/why-misinformation-bill-risks-freedoms-it-aims-protect>.
Karen Santos D’Amorim
and Majory Fernandes de Olivera Miranda, ‘Misinformation, Disinformation
and Malinformation: Clarifying
the Definitions and Examples in Disinfodemic
Times’ (2021) 26
Federal University of Santa Catarina
Sacha Altay et al ,
‘A Survey of Expert Views on Misinformation: Definitions, Determinants,
Solutions and Future of the Field’
(2023) 4(4)
Harvard Kennedy School
Misinformation Review
Department of
Infrastructure, Transport, Regional Development, Communications and the Arts,
Online Misinformation and Disinformation Reform
(Impact Analysis Report,
September 2024), 13 (‘
Misinformation Reform Report
Bharat Dhiman, ‘The
Rise and Impact of Misinformation and Fake News on Digital Youth: A Critical
Review’ (2023) 12(3)
Journal of Socialomics
Australian Electoral
Commission, ‘Disinformation and Misinformation’,
Integrity Assurance Taskforce
<https://www.aec.gov.au/About_AEC/files/eiat/eiat-disinformation-factsheet.pdf>.
Benedetta Brevini and
Michael Ward,
GetUp Briefing Paper 2: How Media Concentration Led to News
Corp’s COVID-19 Misinformation and Regulatory Inaction
(Briefing Paper
No 2, 2021) 4.
Australian Electoral
Commission, ‘Disinformation and Misinformation’,
Integrity Assurance Taskforce
<https://www.aec.gov.au/About_AEC/files/eiat/eiat-disinformation-factsheet.pdf>.
Minister for
Communications, ‘Communications Legislation Amendment (Combatting
Misinformation and Disinformation) Bill 2024’
(Media Release, 26 June
https://minister.infrastructure.gov.au/rowland/media-release/communications-legislation-amendment-combatting-misinformation-and-disinformation-bill-2024
Lange v Australian
Broadcasting Corporation
[1997] HCA 25
(1997) 189 CLR 520.
Australian Capital
Television Pty Ltd v Commonwealth
(1992) 177 CLR 106.
Communications Legislation
Amendment Bill (n 3) cl 1.
Misinformation Reform
Brevini and Ward (n 33)
Mark Humphrey-Jenner,
‘Submission on the Communications Legislation Amendment (Combatting
Misinformation and Disinformation)
(2024) 45(2)
Statute Law
Finely (n 25).
Communications Legislation
Amendment Bill (n 3) cl 11.
Ibid cl 13(3).
Lange v Australian
Broadcasting Corporation
[1997] HCA 25
(1997) 189 CLR 520.
Communications Legislation
Amendment Bill (n 3) cl 1.
Ibid, Schedule 2 cl 20.
Minister for
Communications, ‘Communications Legislation Amendment (Combatting
Misinformation and Disinformation) Bill 2024’
(Media Release, 26 June
https://minister.infrastructure.gov.au/rowland/media-release/communications-legislation-amendment-combatting-misinformation-and-disinformation-bill-2024
Humphrey-Jenner (n 43).
Sam McKeith,
‘Australia dumps plan for fines for social media giants enabling
misinformation’,
(Online 24 November 2024)
<https://www.reuters.com/technology/australia-dumps-plan-fines-social-media-giants-enabling-misinformation-2024-11-23/
Nationwide,
(Mason CJ).
McCloy v New South Wales
[2015] HCA 34
(2015) 257 CLR 178
, 193–4 (French CJ, Kiefel, Bell and Keane JJ).
William Gumede, ‘Rise
in Censorship of the Internet and Social Media in Africa’ (2016) 8(3)
Journal of African Media Studies
Protection from Online
Falsehoods and Manipulation Act 2019
(Singapore) s 5
Shashi Jayakumar, Benjamin
Ang and Nur Diyanah Anwar,
Disinformation and Fake News
Macmillan, 2021), 145.
Amelie Blocman Legipresse,
‘Laws to Combat Manipulation of Information Finally Adopted’,
Iris Merlin
(Web Page) <https://merlin.obs.coe.int/article/8446>.
Humphrey-Jenner (n 43).
‘Singapore:
“Fake News” Law Curtails Speech’,
Human Rights Watch
(online, 13 January 2021) <
https://www.hrw.org/news/2021/01/13/singapore-fake-news-law-curtails-speech>.
Altay et al (n 28) 2.
Brevini and Ward (n 33) 1.
Lisa Given, ‘Do Big
Tech Companies Have a “Duty of Care” for Users? A New Report Says
They Do: But Leaves Out
Key Details’,
The Conversation
February 2025)
<https://theconversation.com/do-big-tech-companies-have-a-duty-of-care-for-users-a-new-report-says-they-do-but-leaves-out-key-details-248995>.
Jayakumar, Ang and Anwar (n
Print (pretty)
Print (eco-friendly)
RTF format (82 KB)
PDF format (332 KB)
LawCite records
NoteUp references
Join the discussion
Tweet this page
Follow @AustLII on Twitter