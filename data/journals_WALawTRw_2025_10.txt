URL: https://www.austlii.edu.au/cgi-bin/viewdoc/au/journals/WALawTRw/2025/10.html
Scraped: 2025-11-17 15:58:29
================================================================================

Cases & Legislation
Journals & Scholarship
Communities
New Zealand
Specific Year
Withnall Howe, Sarah --- "The Carrot and Stick Approach: Promoting Student Learning Engagement Through Assessment" [2025] WALawTRw 10; (2025) 3 The Western Australian Law Teachers' Review 118
THE CARROT AND STICK APPROACH:
PROMOTING STUDENT LEARNING ENGAGEMENT THROUGH ASSESSMENT
SARAH WITHNALL HOWE
This piece is published as a
‘teaching note’
rather than a scholarly article. WALTR publishes teaching notes to provide
space for reflective, practice-based contributions that
sit outside the scope of
traditional peer-reviewed articles but are nonetheless of value to the community
of legal educators. They
may include reflections on teaching and assessment,
contextualised lesson plans (including for secondary legal studies), or opinion
and commentary on broader issues in legal education.
I INTRODUCTION
The following scene is probably all too familiar
for law teachers: You are sitting at your desk surrounded by numerous exam
To your right, a small pile of marked scripts; to your left, a daunting
pile of unmarked ones (scattered in between are several empty
coffee cups and
various chocolate bar wrappers). With a sigh of exasperation, you throw your pen
down, frustrated by how often you
have written the same advice on your
students’ scripts. And it’s too late to tell them that if they had
actively engaged
in the unit and its learning activities, they could have gained
a better understanding of the law, and the skills needed to study
and practice
it (thereby minimising exam answer ‘mistakes’, which would have been
immensely beneficial when it came time
to produce sound exam answers)!
The frustration described above is common, and there is always going to be
some level of disengagement among students in each cohort,
for a variety of
reasons beyond our control. However, for me this recurring frustration was
significantly exacerbated during the
pandemic, where I observed greater and more
troubling levels of student disengagement in two first-year law units I usually
I decided to see what I could do to address the issue. This teaching note
reflects on the approaches implemented to deepen student
engagement in my two
first-year law units: one, a ‘blackletter’ law unit and the other a
skills-based unit. In Part II,
I outline the types and levels of the
disengagement observed in what I will refer to as the ‘troubling
cohort’ and my
belief as to what was the likely cause of this. In Part
III, I outline the modifications made to subsequent iterations of these units
try and address these trends. In Part IV, I reflect on the success of these
modifications.
II THE TROUBLING ITERATION
It was while teaching during the pandemic, but after Western
Australia’s strict lockdown period, that I observed both a troubling
and troubling types of disengagement in one particular cohort. The top five most
concerning signs of disengagement within the
‘troubling cohort’
Assignment submission:
Over one-third of the cohort sought an
extension for their main assignment – an 800-word legal problem-solving
or simply submitted it late.
Teacher-student meetings:
Half of the students who scheduled
meetings to discuss their marked assignment did not attend without explanation.
Workshop non-attendance:
One tutor reported zero attendance for a
particular workshop timeslot on two consecutive weeks.
Late exam preparation:
In this unit the exam factual scenario is
released to the cohort around four weeks prior to the
and nearly half of the
cohort had not viewed the exam’s factual scenario one week before the
Virtually no exam preparation:
more than a tenth of the cohort had
not accessed the exam scenario one day before the exam.
These were not the only signs of disengagement, but from my experience of
teaching this unit, they were the most dispiriting.
Another concern was that the ‘troubling cohort’ had been run
similarly to the previous iteration, which I’ll refer
‘lockdown cohort’, delivered during Western Australia’s
lockdown period. The lockdown cohort’s
informal – was generally positive, with many reporting good learning
experiences and no significant
barriers to engagement. However, the troubling
cohort showed minimal engagement with feedback opportunities, leaving me to
the reasons for the significant decline in engagement and whether this
trend would continue.
I posited the troubling cohort’s experiences immediately prior to their
first-year law studies, during the height of the pandemic,
were likely
significant factors in their low engagement levels. The troubling cohort
included many school leavers who completed their
final years of secondary
schooling in an unfamiliar and isolated online environment. Additionally, many
non-school leavers began
their law studies after experiencing significant
upheaval in employment, other studies and life in general. Against this
background,
it is perhaps unsurprising that the bulk of the cohort did not know
how to engage in their university studies in a way which would
maximise their
learning experiences. Furthermore, I posited that the significant and likely
long-lasting changes in teaching, learning
and living, brought about by the
pandemic would have a major impact. These changes included the shift to online
learning, reduced
face-to-face interactions between teachers and learners as
well as between learners and learners, and the increased reliance on digital
resources. As a result, students would likely arrive at university with less
experience and fewer effective study skills, since these
changes disrupted their
ability to develop essential skills like time management, critical thinking, and
collaborative learning.
As such, I felt it imperative to implement strategies in
my first-year law units to deepen and embed practices of student learning
through engagement in the unit and its learning activities.
III THE CARROT AND STICK APPROACH
To engage my students in the unit’s learning activities, I implemented
a ‘carrot and stick’ approach. I used the
aspect of the unit that
always has the highest levels of engagement – assessments – as the
carrot to dangle from my stick.
I developed a low-stakes ‘Student Learning
Engagement Assessment Item’ (SLEAI), worth 10–15% of the
total marks, requiring engagement in key learning activities to
complete the assessment.
considered key learning activities to be those designed to help students learn
unit content, develop skills needed for practicing
law and establish good study
A General ‘Carrot and Stick’ Design
Considerations
Before outlining the specifics of the SLEAIs I implemented in my first-year
units, I’ll highlight a few considerations I had
to keep in mind during
their development.
First, any modifications in, or development of, assessment had to align with
my institution’s assessment policies and procedures.
For example, commonly
assessment policies do not allow student attendance to be the sole criterion, or
part of the criteria, of an
assessment item. As such I could not simply award
marks for attendance.
any changes to the unit need to take into account the role of the unit and its
assessment within the structure of the school’s
law degree. For example,
if a law degree is structured so that the particular skill of client letter
writing is taught and assessed
in unit X, this must be accounted for when
modifying assessments within unit X.
Second, any modification to my units – whether to assessment items or
other aspects, like the unit’s learning activities
– had to be
achievable within my allocated teaching workload. Therefore, the redesigned
aspects of the unit, including the
time and complexity of marking this SLEAI,
could not be the straw to break the camel’s back.
Third, the workload for students undertaking the redesigned aspects of the
unit must be appropriate. For example, the time students
are expected to study
outside of the classroom must align with the relevant institutional policies.
Requiring extensive reading,
such as hundreds of High Court cases, for a unit
with a low course weighting would likely not be appropriate. In my units, since
I chose assessment as my approach for deepening and improving engagement, the
number, weighting and complexity of the assessments
required careful
consideration in light of the relevant assessment policies and procedures.
B Specific ‘Carrot and Stick’ SLEAI
In this section, I’ll outline the design of the carrot and stick SLEAIs
implemented in my first-year law units. The first,
Workshop SLEAI
to encourage student engagement in the unit’s existing workshop
activities.
The second,
Introductory Recording SLEAI
, focuses on student engagement with unit
content helping students keep up and practice applying it.
1 Workshop SLEAIs
Used in both my blackletter law and skills-based unit, this SLEAI required
students to submit a brief written response to specific
questions arising from
each of the unit’s scheduled workshops. These are administered via the
online Learning Management System
(‘LMS’) as quizzes with short
answer questions. Take, for example, a workshop activity requiring discussion of
of action ‘Y’ that has four elements, and discussion of any
relevant defences. The SLEAI quiz question might be: ‘Discuss
whether the
plaintiff will be able to make out the first element of X in a cause of action
of Y against the defendant.’
To ensure manageable student workload, to cater for equity, diversity, and
inclusion considerations, to provide maximum flexibility
in order to promote
engagement and also to mitigate the risk of academic integrity violations,
several steps were taken. These included:
• Opening all Workshop SLEAI quizzes at the start of the teaching
period (with unlimited attempts allowed) and having each close
around three
weeks after its associated workshop
• Informing students of the relative ease of undertaking the Workshop
SLEAIs and of the expectations for doing well in the assessment.
For example,
instructions suggested a small maximum word count for responses and the
assessment criteria emphasised only engagement
with the workshop material was
being evaluated, not the accuracy of responses or quality of the writing.
• Making students aware that the quiz questions arose from issues
directly discussed in workshops, incentivising preparation,
attendance and
active engagement in workshop classes.
• Advising students of the usefulness of properly completing the SLEAI
assessment to their understanding of the unit content,
and legal skills in
• Clearly communicating academic integrity expectations specific to
this assessment and discussing these expectations with them.
For example,
acceptable and non-acceptable use of AI was made clear to
These measures collectively created an assessment regime which was manageable
for students and facilitated integrity-focused practices
as much as possible.
To ensure manageable marking, only a subset of responses to Workshop SLEAI
quizzes were assessable. Rather than marking every response
for every Workshop
SLEAI quiz, the assessment scheme specified only a quarter of the Workshop SLEAI
quizzes were assessable. To incentivise
completion of all Workshop SLEAI
quizzes, and not just the assessable quizzes, the identity of the assessable
quizzes was not disclosed
to students until the completion date for the quiz had
closed. Several examples of assessment schemes are given in Appendix 1 below.
Using Scheme A as an example, which was essentially the scheme used in my
blackletter law unit, the unit might contain a total for
12 Workshop SLEAI
quizzes to be completed throughout the unit, with the SLEAI instructions
specifying that:
• The Unit Coordinator will randomly choose the same three Workshop
SLEAI quizzes for all students to be assessed on, and the
selected quizzes will
not be disclosed until marks have been
• Each of the three selected assessment quizzes will be worth 3% of the
unit marks, making the Workshop SLEAI quiz worth a total
of 9% for the unit.
This approach ensures fairness and encourages consistent engagement with all
Workshop SLEAI quizzes throughout the unit.
Additionally, since the focus was on evaluating engagement rather than the
accuracy or quality of the responses, the marking process
was much more
straightforward than, say, marking responses to a legal problem-solving
assignment. That is, the marker would not need
to critically assess the quality
of the arguments made, the adequacy of the authorities cited, or the quality of
the written expression.
The marker needed only to be satisfied that the student
had attempted to address the quiz question in some way, to award full marks.
example, consider a Workshop SLEAI quiz asking students to ‘discuss
whether the element of “so as to cause”
in the statutory offence
contained in s 5 of the
Fictitious Act
is likely to be established by X
against Y in the factual scenario from workshop Z’. A response might
Y will establish the element of ‘so as to cause’ from the
statutory offence of whacking from s 5 of the
Fictitious Act
there is a direct link (
Case) between the X’s action of
throwing a bottle, and the harm suffered to Y of a head wound. In
the court held that a direct link will establish a statutory ‘so
as to cause’ element through an unbroken chain of factual
events. That is,
the ‘facts of the occurrence are so closely connected that they can only
sensibly be considered all part of
the same event’. On the facts of our
case, X was standing approximately one metre away from Y and Y was visible to X.
in control of the glass bottle as X meant to pick the bottle up and meant
to intimidate Y through the threats made. In particular,
X spoke the words
‘cop this’ and deliberately swung the bottle in the direction of Y.
The bottle was out of X’s
hand for approximately one second before hitting
Y’s head. This chain of events were closely connected temporally, by
proximity and via the apparent intent behind X’s actions. As such
is it likely a court will find there is a direct link between
letting go of the bottle and Y’s head injury, to make out ‘so as to
cause’ in s 5.
Alternatively, a response might be:
• s 5 FA element = ‘so as to cause’.
• Relevant case law =
Made Up v Case
where ‘so as to
cause’ described as ‘direct link’ .
• Evidence of a direct link here through X’s close physical
proximity to Y, knowledge of presence of Y, words spoken to
Y, one second
temporal immediacy between X letting go of bottle and contact with Y’s
• Element likely to be established.
Both of these responses contain evidence of a student’s engagement with
the unit content. They both identify the relevant issue,
some relevant law and
some relevant facts. Even a response which incorrectly states the law pertaining
to ‘so as to cause’
or suggests that the day of the week is a fact
relevant to the chain of events will still show evidence of student engagement
unit content. All such responses would receive full marks. A response which
merely says ‘element likely established’,
or sets out the elements
of a contract law in a criminal law unit question on assault will not evidence
engagement in the unit content.
2 Introductory Recording SLEAIs
Used only in my blackletter law unit, this SLEAI leveraged existing recorded
lecture content. During lockdown teaching in the pandemic,
I created 20–30
minute videos for each of the unit’s lecture topics, which introduced the
topic and discussed basic content.
To lighten student cognitive load during
synchronous online lectures, the lockdown cohort was encouraged to view these
‘Introductory
Recording’ videos before the synchronous
Given the lockdown cohort’s positive feedback on the utility of these
Introductory Recordings to their learning, I decided
to make them into a
Using the multimedia polling functionality within EchoVideo, I inserted
3–6 multiple-choice questions throughout each of the
9 or 10 (depending on
the iteration) Introductory Recordings. These questions were simple and based on
video content covered immediately
prior to the question being asked. For
example, let’s consider an Introductory Recording on the topic of
defences. Such a recording
might typically start with a discussion covering the
following points:
• The specific defences to be discussed in the unit/topic;
• That defences, like the causes of action, have elements that need to
be proven and that this will be the focus of our discussions
• The effect of proving a defence is that a defendant will escape all
or some legal liability; and
• That a defendant who wishes to rely on a defence will need to raise
and prove it.
Importantly, these points will be
in the Introductory
Recording rather than simply listed. For example, I like to highlight the shift
in perspective that occurs when
discussing defences. I specifically warn
students that, unlike our previous discussions which focused on what a plaintiff
must prove,
our discussions of defences will focus on what a defendant must
prove. I advise students to be cognisant of this shift in language
discussions and their reading. Additionally, I counsel students of usefulness of
identifying whether the appellant and respondent,
in an appeal case, had the
role of plaintiff/prosecution and defendant/accused in the first instance
decision as a way of avoiding
conflation that comes with this perspective shift.
I might also couch discussion of these points by reference to a case or factual
example students are already familiar with.
After some discussion, the Introductory Recording will pause, and a
multiple-choice question will appear for students to answer. Students
answer the question before the video will continue playing and immediate
example, a question relating
to defences, appearing after the initial discussion noted above, could be:
At common law, who bears the onus of proving a defence in
this area of law and to what standard?
A. The plaintiff, beyond reasonable doubt
B. The plaintiff, on the balance of probabilities
C. The defendant, beyond reasonable doubt
D. The defendant, on the balance of probabilities.
As can be seen, the Introductory Recording’s initial discussion covers
the answer to this question, but not in a format where
a statement like
‘the defendant bears the onus of proving the elements of the defence to X
standard’ is expressly made.
Instead, students need to reflect on, or
relisten to, the Introductory Recording’s discussion to determine the
correct answer.
In terms of assessment, similar to the Workshop SLEAI, the Unit Coordinator
would select one question from each of the Introductory
Recordings for
assessment. If the selected question had been attempted, 0.5 marks were awarded
and if the answer was correct, another
0.5 marks were
Therefore, by simply answering all questions, students could earn half the
available marks, even if their answers were not correct.
To earn the remainder,
students needed to demonstrate engagement with the video content through active
listening, analysis and
application.
C Added Bonuses
Both the Workshop and Introductory Recording SLEAIs provided bonus learning
benefits that were not present when these learning activities
were not assessed.
First, by progressively marking and releasing SLEAI results throughout the
teaching period, both students and teachers received feedback
progress. Students could gauge their understanding of unit content in addition
to practicing typical unit assessment tasks.
As a teacher and marker, I had
access to writing samples and multiple-choice response statistics, providing
insight into an individual’s
and the cohort’s overall understanding.
This allowed me to quickly address any problematic trend or offer support to
students who showed signs of struggling with the content or
university life in general. For example, if I noted a student had not
any SLEAIs at all, or seemed not to have basic typing skills, I could reach out
to the student or ask university support
services to reach out to the student.
If noticed a high percentage of the cohort answered an Introductory Recording
SLEAI question
incorrectly, I could expressly address this issue in the lecture
on that topic.
Second, the SLEAIs required students to keep up with unit content, promoting
the benefits of continuous engagement in learning activities.
Similarly, the
SLEAI schedule modelled effective study habits – that is, it encouraged
students to do small bits regularly
– but at the same time, still allowed
students to undertake larger chunks less frequently if required or desired. This
scheduling of SLEAIs enabled students to steadily build their
understanding of the unit content as the unit
progressed.
Additionally, the
Workshop SLEAIs demonstrated the value of timely reflection and review of
workshop content.
Finally, in my experience, a student’s first attempt at legal writing
is typically when drafting their assignment and their
second attempt is when
writing their exam. Instead, the Workshop SLEAIs facilitated writing small parts
of a legal problem-solving
answer (even though writing in note form was
permissible) continuously throughout the unit. This exposed students to the
involved in legal writing early, via low-stakes continuous
assessment, and facilitated a first attempt at legal writing before the
unit’s high-stakes assessments.
IV HAS THERE BEEN MUCH MOVEMENT?
I have implemented my carrot and stick SLEAI approach over several iterations
of my first-year units and feel it has achieved my teaching
goals. That is, my
stubborn mules have moved forward towards more effective engagement in their
learning. I now outline my observations
from these SLEAI iterations that have
led me to conclude that this approach is effective.
Returning to item 3 on my ‘top five most concerning signs of
disengagement’ from Part II, concerning workshop attendance:
attendance rates for workshops or lectures changed during SLEAI iterations?
Maintaining comprehensive and accurate records of
in-person attendance has its
challenges. It’s impractical in a lecture setting, and for workshops while
tutors are asked to
take attendance, and more recently students have been asked
to electronically record their attendance, there is naturally room for
inaccuracies. However, during SLEAI iterations, tutors did not report any
instances of zero attendance, as was reported twice during
the troubling cohort.
Nor did I note from the attendance records any unexplained or concerningly low
attendance rates. Furthermore,
as the lecturer, I did not observe any
troublingly low attendance at face-to-face lectures for SLEAI iterations, unlike
the troubling
iteration where by the end of the teaching period lecture
attendance dropped to around 10%. In terms of the completion rates for
skills-based unit’s Workshop SLEAI, both SLEAI iterations had weekly
completion rates ranging from about 85% to 60%, with
the lower completion rates
occurring towards the end of the teaching period.
I return to items 1, 4 and 5 of my ‘top five’ from Part II, which
concerned aspects of study related to assessment preparation.
I have tracked
data relating to assignment and exam preparation in my blackletter law unit, and
observed pleasing results. The proportion
of the cohort who submitted their main
assignment late, or sought an extension, has roughly halved. Meanwhile, the
proportion of
students viewing the exam scenario at least a week in advance of
the exam has roughly doubled, with almost none waiting until the
day before to
view the scenario for the first time – down from more than a tenth of
the cohort in the troubling iteration.
Overall, it is clear to me that the SLEAI
iterations had better success when it came to helping students keep up with unit
and enabling to them to prepare in advance for assessments more
effectively. It seems reasonable to conclude that the SLEAIs, which
students to engage in learning activities directly related to the unit content
and assessment skills, encouraged earlier
preparation for assignments and
Finally, I also observed encouraging trends in the assignment and exam
results in SLEAI cohorts. In my blackletter law unit, unsurprisingly,
who engaged with the Introductory Recording SLEAI were much more likely to
‘do well’ in their other assessments
for that unit (namely the main
assignment and exam). Students who achieved a perfect score in the Introductory
Reading SLEAI achieved
a combined assignment and exam mark in the
‘pass’ range or better, with around a third in the
‘distinction’
or above range. Further, very few students who made a
diligent attempt at the Introductory Recording
had a combined exam and assignment mark in the ‘fail’
range. Conversely, in each iteration, about half the students who
non-attempt at the Introductory Recording
obtained a combined exam and assignment mark falling within the
‘fail’ range. Therefore, it seems reasonable to conclude
SLEAIs, which required students to engage in learning activities directly
related to unit content and required legal skills,
equipped or assisted students
to achieve success in the unit’s assessments.
V CONCLUSION
The implementation of the carrot and stick SLEAI approach in my first-year
units has proven effective in promoting student engagement
and improving
learning outcomes. By integrating low-stakes assessments that require active
participation in key learning activities,
students are encouraged to stay
engaged with the unit content and progressively develop essential skills. The
observed improvements
in attendance, assignment submission and exam preparation,
along with positive anecdotal and formal feedback from students, support
effectiveness of this approach. Moving forward, this model can be adapted and
applied to other law units for other key learning
activities to further enhance
student engagement and success.
Annexure A: Possible Assessment Schemes
Assessment Name
Assessment Description
Student Learning Engagement, comprised of:
• Workshop Quizzes (12 total for the unit).
The following will be randomly selected for assessment:
• 3 quizzes worth 3% each
Assessment Name
Assessment Description
Student Learning Engagement, comprised of:
• Workshop Quizzes (10 total for the unit).
The following will be randomly selected for assessment:
• 2 quizzes worth 5% each
Assessment Name
Assessment Description
Student Learning Engagement, comprised of:
• Workshop Quizzes (12 total for the unit); and
• Introductory Recording (9 total for the unit).
The following will be randomly selected for assessment:
• 3 quizzes worth 2% each
• 1 question per recording worth 1% each (0.5% for attempting and
0.5% for a correct answer).
Assessment Name
Assessment Description
Student Learning Engagement, comprised of:
• Workshop Quizzes (10 total for the unit); and
• Introductory Recording (10 total for the unit).
The following will be randomly selected for assessment:
• 2 quizzes worth 2.5% each
• 1 question per recording worth 1% each (0.5% for attempting and
0.5% for a correct answer).
Sarah Withnall Howe is a Senior
Lecturer at the School of Law and Criminology, Murdoch University.
This is a closed book
restricted exam where students can only bring one A4 page with notes back and
front into the exam. The factual
scenario is complex with around two dozen
possible questions the cohort could be asked, with only four of these ultimately
asked in the exam paper itself.
Of course, the
alternative analogy is the carrot
stick approach. The carrot is the
reward of attaining marks through simply engaging in the unit, while the stick
is the threat of
losing marks for failing to engage in the unit’s learning
activities. This is a double punishment because, as discussed in
Part Three,
undertaking the engagement assessment generally gave students a better
opportunity to do well in other unit assessments.
While I’m not
suggesting that mandatory attendance would result in students undertaking a
unit’s key learning activities,
being aware of the prohibitions and
requirements prescribed in institutional assessment policies and procedures is a
must at the
outset of any assessment redesign.
I was confident, from
experience and continuous improvement, the existing workshop activities were
effective ways for students to
learn the required skills and content.
This very large
open period meant there were few valid grounds for extensions.
In fact, in this
unit we spent an hour of lecture time experimenting with AI and expressly
discussing its advantages and disadvantages
and ethical uses.
Again, thereby
incentivising ongoing engagement in all workshops.
Therefore, essentially
quizzes were marked on a pass/fail basis. Further, as the ‘correct
answer’ had already been discussed
in the workshops, and was not being
assessed, individualised feedback was not required.
reviewing the synchronous lecture’s recording.
Annexure 1, Schemes C and D, for examples of how marks could be broken down.
Workshop SLEAIs, and for the same reasons, the Introductory Recording SLEAI: (1)
Were open and available for completion from
the start of the teaching period
(although only one attempt was allowed) until about three weeks after
corresponding lecture topic
was scheduled for conclusion; (2) Question chosen
for assessment was selected and disclosed after the close of each Introductory
Recording; and (3) Results were compiled and released progressively throughout
the teaching period.
See Part IV for discussion
of the observed benefit of this.
regarded a ‘diligent attempt’ to be when a student achieved 80% or
more for the Introductory Recording SLEAI. This
indicated the student likely
completed all questions in all Introductory Recordings and got half of the
questions chosen for assessment
regarded a score of below 60% for the Introductory Recording SLEAI a
‘non-attempt’, as this mark indicated that, at
best only half the
assessment had been attempted.
Print (pretty)
Print (eco-friendly)
RTF format (154 KB)
PDF format (576 KB)
LawCite records
NoteUp references
Join the discussion
Tweet this page
Follow @AustLII on Twitter